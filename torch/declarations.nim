# Automatically generated, to update run again the generator from the torch root path
# nim c -r torch/generator.nim
template storage_offset*(self: Tensor): int64 = self.dynamicCppCall("storage_offset").to(int64)
template resize_u*(self: Tensor, size: IntList): Tensor = self.dynamicCppCall("resize_", size).to(Tensor)
template set_u*(self: Tensor, source: AStorage): Tensor = self.dynamicCppCall("set_", source).to(Tensor)
template set_u*(self: Tensor, source: AStorage, storage_offset: int64, size: IntList, stride: IntList): Tensor = self.dynamicCppCall("set_", source, storage_offset, size, stride).to(Tensor)
template set_u*(self: Tensor, source: Tensor): Tensor = self.dynamicCppCall("set_", source).to(Tensor)
template set_u*(self: Tensor): Tensor = self.dynamicCppCall("set_").to(Tensor)
template u_fill_u*(self: Tensor, value: float): Tensor = self.dynamicCppCall("_fill_", value).to(Tensor)
template u_fill_u*(self: Tensor, value: Tensor): Tensor = self.dynamicCppCall("_fill_", value).to(Tensor)
template is_contiguous*(self: Tensor): bool = self.dynamicCppCall("is_contiguous").to(bool)
template is_set_to*(self: Tensor, tensor: Tensor): bool = self.dynamicCppCall("is_set_to", tensor).to(bool)
template masked_fill_u*(self: Tensor, mask: Tensor, value: float): Tensor = self.dynamicCppCall("masked_fill_", mask, value).to(Tensor)
template masked_fill_u*(self: Tensor, mask: Tensor, value: Tensor): Tensor = self.dynamicCppCall("masked_fill_", mask, value).to(Tensor)
template masked_scatter_u*(self: Tensor, mask: Tensor, source: Tensor): Tensor = self.dynamicCppCall("masked_scatter_", mask, source).to(Tensor)
template masked_select_out*(aresult: Tensor, self: Tensor, mask: Tensor): Tensor = dynamicCCall("at::masked_select_out", aresult, self, mask).to(Tensor)
template masked_select*(self: Tensor, mask: Tensor): Tensor = self.dynamicCppCall("masked_select", mask).to(Tensor)
template nonzero_out*(aresult: Tensor, self: Tensor): Tensor = dynamicCCall("at::nonzero_out", aresult, self).to(Tensor)
template nonzero*(self: Tensor): Tensor = self.dynamicCppCall("nonzero").to(Tensor)
template contiguous*(self: Tensor): Tensor = self.dynamicCppCall("contiguous").to(Tensor)
template th_clone*(self: Tensor): Tensor = dynamicCCall("at::th_clone", self).to(Tensor)
template view*(self: Tensor, size: IntList): Tensor = self.dynamicCppCall("view", size).to(Tensor)
template th_resize_as_u*(self: Tensor, the_template: Tensor): Tensor = dynamicCCall("at::th_resize_as_", self, the_template).to(Tensor)
template index_select_out*(aresult: Tensor, self: Tensor, dim: int64, index: Tensor): Tensor = dynamicCCall("at::index_select_out", aresult, self, dim, index).to(Tensor)
template index_select*(self: Tensor, dim: int64, index: Tensor): Tensor = self.dynamicCppCall("index_select", dim, index).to(Tensor)
template u_indexCopy_u*(self: Tensor, dim: int64, index: Tensor, source: Tensor): Tensor = self.dynamicCppCall("_indexCopy_", dim, index, source).to(Tensor)
template take_out*(aresult: Tensor, self: Tensor, index: Tensor): Tensor = dynamicCCall("at::take_out", aresult, self, index).to(Tensor)
template take*(self: Tensor, index: Tensor): Tensor = self.dynamicCppCall("take", index).to(Tensor)
template put_u*(self: Tensor, index: Tensor, source: Tensor, accumulate: bool = false): Tensor = self.dynamicCppCall("put_", index, source, accumulate).to(Tensor)
template index_add_u*(self: Tensor, dim: int64, index: Tensor, source: Tensor): Tensor = self.dynamicCppCall("index_add_", dim, index, source).to(Tensor)
template index_fill_u*(self: Tensor, dim: int64, index: Tensor, value: float): Tensor = self.dynamicCppCall("index_fill_", dim, index, value).to(Tensor)
template index_fill_u*(self: Tensor, dim: int64, index: Tensor, value: Tensor): Tensor = self.dynamicCppCall("index_fill_", dim, index, value).to(Tensor)
template unfold*(self: Tensor, dimension: int64, size: int64, step: int64): Tensor = self.dynamicCppCall("unfold", dimension, size, step).to(Tensor)
template u_range_out*(aresult: Tensor, start: float, aend: float, step: float = 1): Tensor = dynamicCCall("at::_range_out", aresult, start, aend, step).to(Tensor)
template u_arange_out*(aresult: Tensor, start: float, aend: float, step: float = 1): Tensor = dynamicCCall("at::_arange_out", aresult, start, aend, step).to(Tensor)
template u_arange_out*(aresult: Tensor, aend: float): Tensor = dynamicCCall("at::_arange_out", aresult, aend).to(Tensor)
template scatter_u*(self: Tensor, dim: int64, index: Tensor, src: Tensor): Tensor = self.dynamicCppCall("scatter_", dim, index, src).to(Tensor)
template scatter_u*(self: Tensor, dim: int64, index: Tensor, value: float): Tensor = self.dynamicCppCall("scatter_", dim, index, value).to(Tensor)
template scatter_add_u*(self: Tensor, dim: int64, index: Tensor, src: Tensor): Tensor = self.dynamicCppCall("scatter_add_", dim, index, src).to(Tensor)
template gather_out*(aresult: Tensor, self: Tensor, dim: int64, index: Tensor): Tensor = dynamicCCall("at::gather_out", aresult, self, dim, index).to(Tensor)
template gather*(self: Tensor, dim: int64, index: Tensor): Tensor = self.dynamicCppCall("gather", dim, index).to(Tensor)
template data_ptr*(self: Tensor): pointer = self.dynamicCppCall("data_ptr").to(pointer)
template equal*(self: Tensor, other: Tensor): bool = self.dynamicCppCall("equal", other).to(bool)
template u_u_uand_u_u_out*(aresult: Tensor, self: Tensor, other: float): Tensor = dynamicCCall("at::__and___out", aresult, self, other).to(Tensor)
template u_u_uand_u_uu*(self: Tensor, other: float): Tensor = self.dynamicCppCall("__and__", other).to(Tensor)
template u_u_uand_u_u_out*(aresult: Tensor, self: Tensor, other: Tensor): Tensor = dynamicCCall("at::__and___out", aresult, self, other).to(Tensor)
template u_u_uand_u_uu*(self: Tensor, other: Tensor): Tensor = self.dynamicCppCall("__and__", other).to(Tensor)
template u_u_uiand_u_uu*(self: Tensor, other: float): Tensor = self.dynamicCppCall("__iand__", other).to(Tensor)
template u_u_uiand_u_uu*(self: Tensor, other: Tensor): Tensor = self.dynamicCppCall("__iand__", other).to(Tensor)
template u_u_uor_u_u_out*(aresult: Tensor, self: Tensor, other: float): Tensor = dynamicCCall("at::__or___out", aresult, self, other).to(Tensor)
template u_u_uor_u_uu*(self: Tensor, other: float): Tensor = self.dynamicCppCall("__or__", other).to(Tensor)
template u_u_uor_u_u_out*(aresult: Tensor, self: Tensor, other: Tensor): Tensor = dynamicCCall("at::__or___out", aresult, self, other).to(Tensor)
template u_u_uor_u_uu*(self: Tensor, other: Tensor): Tensor = self.dynamicCppCall("__or__", other).to(Tensor)
template u_u_uior_u_uu*(self: Tensor, other: float): Tensor = self.dynamicCppCall("__ior__", other).to(Tensor)
template u_u_uior_u_uu*(self: Tensor, other: Tensor): Tensor = self.dynamicCppCall("__ior__", other).to(Tensor)
template u_u_uxor_u_u_out*(aresult: Tensor, self: Tensor, other: float): Tensor = dynamicCCall("at::__xor___out", aresult, self, other).to(Tensor)
template u_u_uxor_u_uu*(self: Tensor, other: float): Tensor = self.dynamicCppCall("__xor__", other).to(Tensor)
template u_u_uxor_u_u_out*(aresult: Tensor, self: Tensor, other: Tensor): Tensor = dynamicCCall("at::__xor___out", aresult, self, other).to(Tensor)
template u_u_uxor_u_uu*(self: Tensor, other: Tensor): Tensor = self.dynamicCppCall("__xor__", other).to(Tensor)
template u_u_uixor_u_uu*(self: Tensor, other: float): Tensor = self.dynamicCppCall("__ixor__", other).to(Tensor)
template u_u_uixor_u_uu*(self: Tensor, other: Tensor): Tensor = self.dynamicCppCall("__ixor__", other).to(Tensor)
template u_u_ulshift_u_u_out*(aresult: Tensor, self: Tensor, other: float): Tensor = dynamicCCall("at::__lshift___out", aresult, self, other).to(Tensor)
template u_u_ulshift_u_uu*(self: Tensor, other: float): Tensor = self.dynamicCppCall("__lshift__", other).to(Tensor)
template u_u_ulshift_u_u_out*(aresult: Tensor, self: Tensor, other: Tensor): Tensor = dynamicCCall("at::__lshift___out", aresult, self, other).to(Tensor)
template u_u_ulshift_u_uu*(self: Tensor, other: Tensor): Tensor = self.dynamicCppCall("__lshift__", other).to(Tensor)
template u_u_uilshift_u_uu*(self: Tensor, other: float): Tensor = self.dynamicCppCall("__ilshift__", other).to(Tensor)
template u_u_uilshift_u_uu*(self: Tensor, other: Tensor): Tensor = self.dynamicCppCall("__ilshift__", other).to(Tensor)
template u_u_urshift_u_u_out*(aresult: Tensor, self: Tensor, other: float): Tensor = dynamicCCall("at::__rshift___out", aresult, self, other).to(Tensor)
template u_u_urshift_u_uu*(self: Tensor, other: float): Tensor = self.dynamicCppCall("__rshift__", other).to(Tensor)
template u_u_urshift_u_u_out*(aresult: Tensor, self: Tensor, other: Tensor): Tensor = dynamicCCall("at::__rshift___out", aresult, self, other).to(Tensor)
template u_u_urshift_u_uu*(self: Tensor, other: Tensor): Tensor = self.dynamicCppCall("__rshift__", other).to(Tensor)
template u_u_uirshift_u_uu*(self: Tensor, other: float): Tensor = self.dynamicCppCall("__irshift__", other).to(Tensor)
template u_u_uirshift_u_uu*(self: Tensor, other: Tensor): Tensor = self.dynamicCppCall("__irshift__", other).to(Tensor)
template lt_out*(aresult: Tensor, self: Tensor, other: float): Tensor = dynamicCCall("at::lt_out", aresult, self, other).to(Tensor)
template lt*(self: Tensor, other: float): Tensor = self.dynamicCppCall("lt", other).to(Tensor)
template lt_out*(aresult: Tensor, self: Tensor, other: Tensor): Tensor = dynamicCCall("at::lt_out", aresult, self, other).to(Tensor)
template lt*(self: Tensor, other: Tensor): Tensor = self.dynamicCppCall("lt", other).to(Tensor)
template lt_u*(self: Tensor, other: float): Tensor = self.dynamicCppCall("lt_", other).to(Tensor)
template lt_u*(self: Tensor, other: Tensor): Tensor = self.dynamicCppCall("lt_", other).to(Tensor)
template gt_out*(aresult: Tensor, self: Tensor, other: float): Tensor = dynamicCCall("at::gt_out", aresult, self, other).to(Tensor)
template gt*(self: Tensor, other: float): Tensor = self.dynamicCppCall("gt", other).to(Tensor)
template gt_out*(aresult: Tensor, self: Tensor, other: Tensor): Tensor = dynamicCCall("at::gt_out", aresult, self, other).to(Tensor)
template gt*(self: Tensor, other: Tensor): Tensor = self.dynamicCppCall("gt", other).to(Tensor)
template gt_u*(self: Tensor, other: float): Tensor = self.dynamicCppCall("gt_", other).to(Tensor)
template gt_u*(self: Tensor, other: Tensor): Tensor = self.dynamicCppCall("gt_", other).to(Tensor)
template le_out*(aresult: Tensor, self: Tensor, other: float): Tensor = dynamicCCall("at::le_out", aresult, self, other).to(Tensor)
template le*(self: Tensor, other: float): Tensor = self.dynamicCppCall("le", other).to(Tensor)
template le_out*(aresult: Tensor, self: Tensor, other: Tensor): Tensor = dynamicCCall("at::le_out", aresult, self, other).to(Tensor)
template le*(self: Tensor, other: Tensor): Tensor = self.dynamicCppCall("le", other).to(Tensor)
template le_u*(self: Tensor, other: float): Tensor = self.dynamicCppCall("le_", other).to(Tensor)
template le_u*(self: Tensor, other: Tensor): Tensor = self.dynamicCppCall("le_", other).to(Tensor)
template ge_out*(aresult: Tensor, self: Tensor, other: float): Tensor = dynamicCCall("at::ge_out", aresult, self, other).to(Tensor)
template ge*(self: Tensor, other: float): Tensor = self.dynamicCppCall("ge", other).to(Tensor)
template ge_out*(aresult: Tensor, self: Tensor, other: Tensor): Tensor = dynamicCCall("at::ge_out", aresult, self, other).to(Tensor)
template ge*(self: Tensor, other: Tensor): Tensor = self.dynamicCppCall("ge", other).to(Tensor)
template ge_u*(self: Tensor, other: float): Tensor = self.dynamicCppCall("ge_", other).to(Tensor)
template ge_u*(self: Tensor, other: Tensor): Tensor = self.dynamicCppCall("ge_", other).to(Tensor)
template eq_out*(aresult: Tensor, self: Tensor, other: float): Tensor = dynamicCCall("at::eq_out", aresult, self, other).to(Tensor)
template eq*(self: Tensor, other: float): Tensor = self.dynamicCppCall("eq", other).to(Tensor)
template eq_out*(aresult: Tensor, self: Tensor, other: Tensor): Tensor = dynamicCCall("at::eq_out", aresult, self, other).to(Tensor)
template eq*(self: Tensor, other: Tensor): Tensor = self.dynamicCppCall("eq", other).to(Tensor)
template eq_u*(self: Tensor, other: float): Tensor = self.dynamicCppCall("eq_", other).to(Tensor)
template eq_u*(self: Tensor, other: Tensor): Tensor = self.dynamicCppCall("eq_", other).to(Tensor)
template ne_out*(aresult: Tensor, self: Tensor, other: float): Tensor = dynamicCCall("at::ne_out", aresult, self, other).to(Tensor)
template ne*(self: Tensor, other: float): Tensor = self.dynamicCppCall("ne", other).to(Tensor)
template ne_out*(aresult: Tensor, self: Tensor, other: Tensor): Tensor = dynamicCCall("at::ne_out", aresult, self, other).to(Tensor)
template ne*(self: Tensor, other: Tensor): Tensor = self.dynamicCppCall("ne", other).to(Tensor)
template ne_u*(self: Tensor, other: float): Tensor = self.dynamicCppCall("ne_", other).to(Tensor)
template ne_u*(self: Tensor, other: Tensor): Tensor = self.dynamicCppCall("ne_", other).to(Tensor)
template min_out*(aresult: Tensor, self: Tensor, other: Tensor): Tensor = dynamicCCall("at::min_out", aresult, self, other).to(Tensor)
template min*(self: Tensor, other: Tensor): Tensor = self.dynamicCppCall("min", other).to(Tensor)
template min*(self: Tensor): float = self.dynamicCppCall("min").to(float)
template u_th_min_out*(min: Tensor, min_indices: Tensor, self: Tensor, dim: int64, keepdim: bool = false): (Tensor, Tensor) = dynamicCCall("at::_th_min_out", min, min_indices, self, dim, keepdim).to(ATensorRTuple2).toNimTensorTuple()
template u_th_min*(self: Tensor, dim: int64, keepdim: bool = false): (Tensor, Tensor) = self.dynamicCppCall("_th_min", dim, keepdim).to(ATensorTuple2).toNimTensorTuple()
template max_out*(aresult: Tensor, self: Tensor, other: Tensor): Tensor = dynamicCCall("at::max_out", aresult, self, other).to(Tensor)
template max*(self: Tensor, other: Tensor): Tensor = self.dynamicCppCall("max", other).to(Tensor)
template max*(self: Tensor): float = self.dynamicCppCall("max").to(float)
template u_th_max_out*(max: Tensor, max_indices: Tensor, self: Tensor, dim: int64, keepdim: bool = false): (Tensor, Tensor) = dynamicCCall("at::_th_max_out", max, max_indices, self, dim, keepdim).to(ATensorRTuple2).toNimTensorTuple()
template u_th_max*(self: Tensor, dim: int64, keepdim: bool = false): (Tensor, Tensor) = self.dynamicCppCall("_th_max", dim, keepdim).to(ATensorTuple2).toNimTensorTuple()
template u_th_kthvalue_out*(values: Tensor, indices: Tensor, self: Tensor, k: int64, dim: int64 = -1, keepdim: bool = false): (Tensor, Tensor) = dynamicCCall("at::_th_kthvalue_out", values, indices, self, k, dim, keepdim).to(ATensorRTuple2).toNimTensorTuple()
template u_th_kthvalue*(self: Tensor, k: int64, dim: int64 = -1, keepdim: bool = false): (Tensor, Tensor) = self.dynamicCppCall("_th_kthvalue", k, dim, keepdim).to(ATensorTuple2).toNimTensorTuple()
template u_th_mode_out*(values: Tensor, indices: Tensor, self: Tensor, dim: int64 = -1, keepdim: bool = false): (Tensor, Tensor) = dynamicCCall("at::_th_mode_out", values, indices, self, dim, keepdim).to(ATensorRTuple2).toNimTensorTuple()
template u_th_mode*(self: Tensor, dim: int64 = -1, keepdim: bool = false): (Tensor, Tensor) = self.dynamicCppCall("_th_mode", dim, keepdim).to(ATensorTuple2).toNimTensorTuple()
template median*(self: Tensor): float = self.dynamicCppCall("median").to(float)
template u_th_median_out*(values: Tensor, indices: Tensor, self: Tensor, dim: int64, keepdim: bool = false): (Tensor, Tensor) = dynamicCCall("at::_th_median_out", values, indices, self, dim, keepdim).to(ATensorRTuple2).toNimTensorTuple()
template u_th_median*(self: Tensor, dim: int64, keepdim: bool = false): (Tensor, Tensor) = self.dynamicCppCall("_th_median", dim, keepdim).to(ATensorTuple2).toNimTensorTuple()
template sort_out*(values: Tensor, indices: Tensor, self: Tensor, dim: int64 = -1, descending: bool = false): (Tensor, Tensor) = dynamicCCall("at::sort_out", values, indices, self, dim, descending).to(ATensorRTuple2).toNimTensorTuple()
template sort*(self: Tensor, dim: int64 = -1, descending: bool = false): (Tensor, Tensor) = self.dynamicCppCall("sort", dim, descending).to(ATensorTuple2).toNimTensorTuple()
template topk_out*(values: Tensor, indices: Tensor, self: Tensor, k: int64, dim: int64 = -1, largest: bool = true, sorted: bool = true): (Tensor, Tensor) = dynamicCCall("at::topk_out", values, indices, self, k, dim, largest, sorted).to(ATensorRTuple2).toNimTensorTuple()
template topk*(self: Tensor, k: int64, dim: int64 = -1, largest: bool = true, sorted: bool = true): (Tensor, Tensor) = self.dynamicCppCall("topk", k, dim, largest, sorted).to(ATensorTuple2).toNimTensorTuple()
template all*(self: Tensor): float = self.dynamicCppCall("all").to(float)
template u_th_all_out*(aresult: Tensor, self: Tensor, dim: int64, keepdim: bool = false): Tensor = dynamicCCall("at::_th_all_out", aresult, self, dim, keepdim).to(Tensor)
template u_th_all*(self: Tensor, dim: int64, keepdim: bool = false): Tensor = self.dynamicCppCall("_th_all", dim, keepdim).to(Tensor)
template any*(self: Tensor): float = self.dynamicCppCall("any").to(float)
template u_th_any_out*(aresult: Tensor, self: Tensor, dim: int64, keepdim: bool = false): Tensor = dynamicCCall("at::_th_any_out", aresult, self, dim, keepdim).to(Tensor)
template u_th_any*(self: Tensor, dim: int64, keepdim: bool = false): Tensor = self.dynamicCppCall("_th_any", dim, keepdim).to(Tensor)
template u_th_get_device*(self: Tensor): int64 = dynamicCCall("at::_th_get_device", self).to(int64)
template u_abs_out*(aresult: Tensor, self: Tensor): Tensor = dynamicCCall("at::_abs_out", aresult, self).to(Tensor)
template u_abs*(self: Tensor): Tensor = self.dynamicCppCall("_abs").to(Tensor)
template u_th_sigmoid_out*(aresult: Tensor, self: Tensor): Tensor = dynamicCCall("at::_th_sigmoid_out", aresult, self).to(Tensor)
template u_th_sigmoid*(self: Tensor): Tensor = self.dynamicCppCall("_th_sigmoid").to(Tensor)
template u_log_out*(aresult: Tensor, self: Tensor): Tensor = dynamicCCall("at::_log_out", aresult, self).to(Tensor)
template u_log*(self: Tensor): Tensor = self.dynamicCppCall("_log").to(Tensor)
template u_log10_out*(aresult: Tensor, self: Tensor): Tensor = dynamicCCall("at::_log10_out", aresult, self).to(Tensor)
template u_log10*(self: Tensor): Tensor = self.dynamicCppCall("_log10").to(Tensor)
template u_log1p_out*(aresult: Tensor, self: Tensor): Tensor = dynamicCCall("at::_log1p_out", aresult, self).to(Tensor)
template u_log1p*(self: Tensor): Tensor = self.dynamicCppCall("_log1p").to(Tensor)
template u_log2_out*(aresult: Tensor, self: Tensor): Tensor = dynamicCCall("at::_log2_out", aresult, self).to(Tensor)
template u_log2*(self: Tensor): Tensor = self.dynamicCppCall("_log2").to(Tensor)
template lgamma_out*(aresult: Tensor, self: Tensor): Tensor = dynamicCCall("at::lgamma_out", aresult, self).to(Tensor)
template lgamma*(self: Tensor): Tensor = self.dynamicCppCall("lgamma").to(Tensor)
template lgamma_u*(self: Tensor): Tensor = self.dynamicCppCall("lgamma_").to(Tensor)
template digamma_out*(aresult: Tensor, self: Tensor): Tensor = dynamicCCall("at::digamma_out", aresult, self).to(Tensor)
template digamma*(self: Tensor): Tensor = self.dynamicCppCall("digamma").to(Tensor)
template digamma_u*(self: Tensor): Tensor = self.dynamicCppCall("digamma_").to(Tensor)
template polygamma_out*(aresult: Tensor, n: int64, self: Tensor): Tensor = dynamicCCall("at::polygamma_out", aresult, n, self).to(Tensor)
template polygamma*(self: Tensor, n: int64): Tensor = self.dynamicCppCall("polygamma", n).to(Tensor)
template polygamma_u*(self: Tensor, n: int64): Tensor = self.dynamicCppCall("polygamma_", n).to(Tensor)
template u_exp_out*(aresult: Tensor, self: Tensor): Tensor = dynamicCCall("at::_exp_out", aresult, self).to(Tensor)
template u_exp*(self: Tensor): Tensor = self.dynamicCppCall("_exp").to(Tensor)
template u_expm1_out*(aresult: Tensor, self: Tensor): Tensor = dynamicCCall("at::_expm1_out", aresult, self).to(Tensor)
template u_expm1*(self: Tensor): Tensor = self.dynamicCppCall("_expm1").to(Tensor)
template u_cos_out*(aresult: Tensor, self: Tensor): Tensor = dynamicCCall("at::_cos_out", aresult, self).to(Tensor)
template u_cos*(self: Tensor): Tensor = self.dynamicCppCall("_cos").to(Tensor)
template u_acos_out*(aresult: Tensor, self: Tensor): Tensor = dynamicCCall("at::_acos_out", aresult, self).to(Tensor)
template u_acos*(self: Tensor): Tensor = self.dynamicCppCall("_acos").to(Tensor)
template u_cosh_out*(aresult: Tensor, self: Tensor): Tensor = dynamicCCall("at::_cosh_out", aresult, self).to(Tensor)
template u_cosh*(self: Tensor): Tensor = self.dynamicCppCall("_cosh").to(Tensor)
template u_sin_out*(aresult: Tensor, self: Tensor): Tensor = dynamicCCall("at::_sin_out", aresult, self).to(Tensor)
template u_sin*(self: Tensor): Tensor = self.dynamicCppCall("_sin").to(Tensor)
template u_asin_out*(aresult: Tensor, self: Tensor): Tensor = dynamicCCall("at::_asin_out", aresult, self).to(Tensor)
template u_asin*(self: Tensor): Tensor = self.dynamicCppCall("_asin").to(Tensor)
template u_sinh_out*(aresult: Tensor, self: Tensor): Tensor = dynamicCCall("at::_sinh_out", aresult, self).to(Tensor)
template u_sinh*(self: Tensor): Tensor = self.dynamicCppCall("_sinh").to(Tensor)
template u_tan_out*(aresult: Tensor, self: Tensor): Tensor = dynamicCCall("at::_tan_out", aresult, self).to(Tensor)
template u_tan*(self: Tensor): Tensor = self.dynamicCppCall("_tan").to(Tensor)
template u_atan_out*(aresult: Tensor, self: Tensor): Tensor = dynamicCCall("at::_atan_out", aresult, self).to(Tensor)
template u_atan*(self: Tensor): Tensor = self.dynamicCppCall("_atan").to(Tensor)
template u_th_tanh_out*(aresult: Tensor, self: Tensor): Tensor = dynamicCCall("at::_th_tanh_out", aresult, self).to(Tensor)
template u_th_tanh*(self: Tensor): Tensor = self.dynamicCppCall("_th_tanh").to(Tensor)
template u_erf_out*(aresult: Tensor, self: Tensor): Tensor = dynamicCCall("at::_erf_out", aresult, self).to(Tensor)
template u_erf*(self: Tensor): Tensor = self.dynamicCppCall("_erf").to(Tensor)
template u_erfc_out*(aresult: Tensor, self: Tensor): Tensor = dynamicCCall("at::_erfc_out", aresult, self).to(Tensor)
template u_erfc*(self: Tensor): Tensor = self.dynamicCppCall("_erfc").to(Tensor)
template erfinv_u*(self: Tensor): Tensor = self.dynamicCppCall("erfinv_").to(Tensor)
template erfinv_out*(aresult: Tensor, self: Tensor): Tensor = dynamicCCall("at::erfinv_out", aresult, self).to(Tensor)
template erfinv*(self: Tensor): Tensor = self.dynamicCppCall("erfinv").to(Tensor)
template u_sqrt_out*(aresult: Tensor, self: Tensor): Tensor = dynamicCCall("at::_sqrt_out", aresult, self).to(Tensor)
template u_sqrt*(self: Tensor): Tensor = self.dynamicCppCall("_sqrt").to(Tensor)
template u_rsqrt_out*(aresult: Tensor, self: Tensor): Tensor = dynamicCCall("at::_rsqrt_out", aresult, self).to(Tensor)
template u_rsqrt*(self: Tensor): Tensor = self.dynamicCppCall("_rsqrt").to(Tensor)
template u_ceil_out*(aresult: Tensor, self: Tensor): Tensor = dynamicCCall("at::_ceil_out", aresult, self).to(Tensor)
template u_ceil*(self: Tensor): Tensor = self.dynamicCppCall("_ceil").to(Tensor)
template u_floor_out*(aresult: Tensor, self: Tensor): Tensor = dynamicCCall("at::_floor_out", aresult, self).to(Tensor)
template u_floor*(self: Tensor): Tensor = self.dynamicCppCall("_floor").to(Tensor)
template u_round_out*(aresult: Tensor, self: Tensor): Tensor = dynamicCCall("at::_round_out", aresult, self).to(Tensor)
template u_round*(self: Tensor): Tensor = self.dynamicCppCall("_round").to(Tensor)
template u_trunc_out*(aresult: Tensor, self: Tensor): Tensor = dynamicCCall("at::_trunc_out", aresult, self).to(Tensor)
template u_trunc*(self: Tensor): Tensor = self.dynamicCppCall("_trunc").to(Tensor)
template frac_u*(self: Tensor): Tensor = self.dynamicCppCall("frac_").to(Tensor)
template frac_out*(aresult: Tensor, self: Tensor): Tensor = dynamicCCall("at::frac_out", aresult, self).to(Tensor)
template frac*(self: Tensor): Tensor = self.dynamicCppCall("frac").to(Tensor)
template u_th_var_out*(aresult: Tensor, self: Tensor, dim: int64, unbiased: bool = true, keepdim: bool = false): Tensor = dynamicCCall("at::_th_var_out", aresult, self, dim, unbiased, keepdim).to(Tensor)
template u_th_var*(self: Tensor, dim: int64, unbiased: bool = true, keepdim: bool = false): Tensor = self.dynamicCppCall("_th_var", dim, unbiased, keepdim).to(Tensor)
template u_th_var*(self: Tensor, unbiased: bool = true): float = self.dynamicCppCall("_th_var", unbiased).to(float)
template u_th_std_out*(aresult: Tensor, self: Tensor, dim: int64, unbiased: bool = true, keepdim: bool = false): Tensor = dynamicCCall("at::_th_std_out", aresult, self, dim, unbiased, keepdim).to(Tensor)
template u_th_std*(self: Tensor, dim: int64, unbiased: bool = true, keepdim: bool = false): Tensor = self.dynamicCppCall("_th_std", dim, unbiased, keepdim).to(Tensor)
template u_th_std*(self: Tensor, unbiased: bool = true): float = self.dynamicCppCall("_th_std", unbiased).to(float)
template th_norm*(self: Tensor, p: float = 2): float = dynamicCCall("at::th_norm", self, p).to(float)
template u_th_norm_out*(aresult: Tensor, self: Tensor, p: float, dim: int64, keepdim: bool = false): Tensor = dynamicCCall("at::_th_norm_out", aresult, self, p, dim, keepdim).to(Tensor)
template u_th_norm*(self: Tensor, p: float, dim: int64, keepdim: bool = false): Tensor = self.dynamicCppCall("_th_norm", p, dim, keepdim).to(Tensor)
template renorm_out*(aresult: Tensor, self: Tensor, p: float, dim: int64, maxnorm: float): Tensor = dynamicCCall("at::renorm_out", aresult, self, p, dim, maxnorm).to(Tensor)
template renorm*(self: Tensor, p: float, dim: int64, maxnorm: float): Tensor = self.dynamicCppCall("renorm", p, dim, maxnorm).to(Tensor)
template renorm_u*(self: Tensor, p: float, dim: int64, maxnorm: float): Tensor = self.dynamicCppCall("renorm_", p, dim, maxnorm).to(Tensor)
template dist*(self: Tensor, other: Tensor, p: float = 2): float = self.dynamicCppCall("dist", other, p).to(float)
template reciprocal_out*(aresult: Tensor, self: Tensor): Tensor = dynamicCCall("at::reciprocal_out", aresult, self).to(Tensor)
template reciprocal*(self: Tensor): Tensor = self.dynamicCppCall("reciprocal").to(Tensor)
template reciprocal_u*(self: Tensor): Tensor = self.dynamicCppCall("reciprocal_").to(Tensor)
template neg_out*(aresult: Tensor, self: Tensor): Tensor = dynamicCCall("at::neg_out", aresult, self).to(Tensor)
template neg*(self: Tensor): Tensor = self.dynamicCppCall("neg").to(Tensor)
template neg_u*(self: Tensor): Tensor = self.dynamicCppCall("neg_").to(Tensor)
template atan2_out*(aresult: Tensor, self: Tensor, other: Tensor): Tensor = dynamicCCall("at::atan2_out", aresult, self, other).to(Tensor)
template atan2*(self: Tensor, other: Tensor): Tensor = self.dynamicCppCall("atan2", other).to(Tensor)
template atan2_u*(self: Tensor, other: Tensor): Tensor = self.dynamicCppCall("atan2_", other).to(Tensor)
template th_pow_out*(aresult: Tensor, self: Tensor, exponent: float): Tensor = dynamicCCall("at::th_pow_out", aresult, self, exponent).to(Tensor)
template th_pow*(self: Tensor, exponent: float): Tensor = dynamicCCall("at::th_pow", self, exponent).to(Tensor)
template pow_out*(aresult: Tensor, self: Tensor, exponent: Tensor): Tensor = dynamicCCall("at::pow_out", aresult, self, exponent).to(Tensor)
template pow*(self: Tensor, exponent: Tensor): Tensor = self.dynamicCppCall("pow", exponent).to(Tensor)
template pow_out*(aresult: Tensor, base: float, self: Tensor): Tensor = dynamicCCall("at::pow_out", aresult, base, self).to(Tensor)
template pow*(base: float, self: Tensor): Tensor = dynamicCCall("at::pow", base, self).to(Tensor)
template pow_u*(self: Tensor, exponent: float): Tensor = self.dynamicCppCall("pow_", exponent).to(Tensor)
template pow_u*(self: Tensor, exponent: Tensor): Tensor = self.dynamicCppCall("pow_", exponent).to(Tensor)
template lerp_out*(aresult: Tensor, self: Tensor, aend: Tensor, weight: float): Tensor = dynamicCCall("at::lerp_out", aresult, self, aend, weight).to(Tensor)
template lerp*(self: Tensor, aend: Tensor, weight: float): Tensor = self.dynamicCppCall("lerp", aend, weight).to(Tensor)
template lerp_u*(self: Tensor, aend: Tensor, weight: float): Tensor = self.dynamicCppCall("lerp_", aend, weight).to(Tensor)
template u_linspace_out*(aresult: Tensor, start: float, aend: float, steps: int64 = 100): Tensor = dynamicCCall("at::_linspace_out", aresult, start, aend, steps).to(Tensor)
template u_logspace_out*(aresult: Tensor, start: float, aend: float, steps: int64 = 100): Tensor = dynamicCCall("at::_logspace_out", aresult, start, aend, steps).to(Tensor)
template histc_out*(aresult: Tensor, self: Tensor, bins: int64 = 100, min: float = 0, max: float = 0): Tensor = dynamicCCall("at::histc_out", aresult, self, bins, min, max).to(Tensor)
template histc*(self: Tensor, bins: int64 = 100, min: float = 0, max: float = 0): Tensor = self.dynamicCppCall("histc", bins, min, max).to(Tensor)
template th_zero_u*(self: Tensor): Tensor = dynamicCCall("at::th_zero_", self).to(Tensor)
template u_sumall*(self: Tensor): float = self.dynamicCppCall("_sumall").to(float)
template u_th_sum_out*(aresult: Tensor, self: Tensor, dim: int64, keepdim: bool = false): Tensor = dynamicCCall("at::_th_sum_out", aresult, self, dim, keepdim).to(Tensor)
template u_th_sum*(self: Tensor, dim: int64, keepdim: bool = false): Tensor = self.dynamicCppCall("_th_sum", dim, keepdim).to(Tensor)
template u_prodall*(self: Tensor): float = self.dynamicCppCall("_prodall").to(float)
template u_th_prod_out*(aresult: Tensor, self: Tensor, dim: int64, keepdim: bool = false): Tensor = dynamicCCall("at::_th_prod_out", aresult, self, dim, keepdim).to(Tensor)
template u_th_prod*(self: Tensor, dim: int64, keepdim: bool = false): Tensor = self.dynamicCppCall("_th_prod", dim, keepdim).to(Tensor)
template u_cumsum_out*(aresult: Tensor, self: Tensor, dim: int64): Tensor = dynamicCCall("at::_cumsum_out", aresult, self, dim).to(Tensor)
template u_cumsum*(self: Tensor, dim: int64): Tensor = self.dynamicCppCall("_cumsum", dim).to(Tensor)
template u_cumprod_out*(aresult: Tensor, self: Tensor, dim: int64): Tensor = dynamicCCall("at::_cumprod_out", aresult, self, dim).to(Tensor)
template u_cumprod*(self: Tensor, dim: int64): Tensor = self.dynamicCppCall("_cumprod", dim).to(Tensor)
template sign_out*(aresult: Tensor, self: Tensor): Tensor = dynamicCCall("at::sign_out", aresult, self).to(Tensor)
template sign*(self: Tensor): Tensor = self.dynamicCppCall("sign").to(Tensor)
template sign_u*(self: Tensor): Tensor = self.dynamicCppCall("sign_").to(Tensor)
template trace*(self: Tensor): float = self.dynamicCppCall("trace").to(float)
template fmod_out*(aresult: Tensor, self: Tensor, other: float): Tensor = dynamicCCall("at::fmod_out", aresult, self, other).to(Tensor)
template fmod*(self: Tensor, other: float): Tensor = self.dynamicCppCall("fmod", other).to(Tensor)
template fmod_out*(aresult: Tensor, self: Tensor, other: Tensor): Tensor = dynamicCCall("at::fmod_out", aresult, self, other).to(Tensor)
template fmod*(self: Tensor, other: Tensor): Tensor = self.dynamicCppCall("fmod", other).to(Tensor)
template fmod_u*(self: Tensor, other: float): Tensor = self.dynamicCppCall("fmod_", other).to(Tensor)
template fmod_u*(self: Tensor, other: Tensor): Tensor = self.dynamicCppCall("fmod_", other).to(Tensor)
template remainder_out*(aresult: Tensor, self: Tensor, other: float): Tensor = dynamicCCall("at::remainder_out", aresult, self, other).to(Tensor)
template remainder*(self: Tensor, other: float): Tensor = self.dynamicCppCall("remainder", other).to(Tensor)
template remainder_out*(aresult: Tensor, self: Tensor, other: Tensor): Tensor = dynamicCCall("at::remainder_out", aresult, self, other).to(Tensor)
template remainder*(self: Tensor, other: Tensor): Tensor = self.dynamicCppCall("remainder", other).to(Tensor)
template remainder_u*(self: Tensor, other: float): Tensor = self.dynamicCppCall("remainder_", other).to(Tensor)
template remainder_u*(self: Tensor, other: Tensor): Tensor = self.dynamicCppCall("remainder_", other).to(Tensor)
template u_th_clamp_u*(self: Tensor, min: float, max: float): Tensor = self.dynamicCppCall("_th_clamp_", min, max).to(Tensor)
template u_th_clamp_min_u*(self: Tensor, min: float): Tensor = self.dynamicCppCall("_th_clamp_min_", min).to(Tensor)
template u_th_clamp_max_u*(self: Tensor, max: float): Tensor = self.dynamicCppCall("_th_clamp_max_", max).to(Tensor)
template u_dot*(self: Tensor, tensor: Tensor): float = self.dynamicCppCall("_dot", tensor).to(float)
template tril_out*(aresult: Tensor, self: Tensor, diagonal: int64 = 0): Tensor = dynamicCCall("at::tril_out", aresult, self, diagonal).to(Tensor)
template tril*(self: Tensor, diagonal: int64 = 0): Tensor = self.dynamicCppCall("tril", diagonal).to(Tensor)
template tril_u*(self: Tensor, diagonal: int64 = 0): Tensor = self.dynamicCppCall("tril_", diagonal).to(Tensor)
template triu_out*(aresult: Tensor, self: Tensor, diagonal: int64 = 0): Tensor = dynamicCCall("at::triu_out", aresult, self, diagonal).to(Tensor)
template triu*(self: Tensor, diagonal: int64 = 0): Tensor = self.dynamicCppCall("triu", diagonal).to(Tensor)
template triu_u*(self: Tensor, diagonal: int64 = 0): Tensor = self.dynamicCppCall("triu_", diagonal).to(Tensor)
template cross_out*(aresult: Tensor, self: Tensor, other: Tensor, dim: int64 = -1): Tensor = dynamicCCall("at::cross_out", aresult, self, other, dim).to(Tensor)
template cross*(self: Tensor, other: Tensor, dim: int64 = -1): Tensor = self.dynamicCppCall("cross", other, dim).to(Tensor)
template diag_out*(aresult: Tensor, self: Tensor, diagonal: int64 = 0): Tensor = dynamicCCall("at::diag_out", aresult, self, diagonal).to(Tensor)
template diag*(self: Tensor, diagonal: int64 = 0): Tensor = self.dynamicCppCall("diag", diagonal).to(Tensor)
template th_addmm_out*(aresult: Tensor, self: Tensor, mat1: Tensor, mat2: Tensor, beta: float = 1, alpha: float = 1): Tensor = dynamicCCall("at::th_addmm_out", aresult, self, mat1, mat2, beta, alpha).to(Tensor)
template th_addmm*(self: Tensor, mat1: Tensor, mat2: Tensor, beta: float = 1, alpha: float = 1): Tensor = dynamicCCall("at::th_addmm", self, mat1, mat2, beta, alpha).to(Tensor)
template th_addmm_u*(self: Tensor, mat1: Tensor, mat2: Tensor, beta: float = 1, alpha: float = 1): Tensor = dynamicCCall("at::th_addmm_", self, mat1, mat2, beta, alpha).to(Tensor)
template u_addmv_out*(aresult: Tensor, self: Tensor, mat: Tensor, vec: Tensor, beta: float = 1, alpha: float = 1): Tensor = dynamicCCall("at::_addmv_out", aresult, self, mat, vec, beta, alpha).to(Tensor)
template u_addmv*(self: Tensor, mat: Tensor, vec: Tensor, beta: float = 1, alpha: float = 1): Tensor = self.dynamicCppCall("_addmv", mat, vec, beta, alpha).to(Tensor)
template u_addmv_u*(self: Tensor, mat: Tensor, vec: Tensor, beta: float = 1, alpha: float = 1): Tensor = self.dynamicCppCall("_addmv_", mat, vec, beta, alpha).to(Tensor)
template u_addr_out*(aresult: Tensor, self: Tensor, vec1: Tensor, vec2: Tensor, beta: float = 1, alpha: float = 1): Tensor = dynamicCCall("at::_addr_out", aresult, self, vec1, vec2, beta, alpha).to(Tensor)
template u_addr*(self: Tensor, vec1: Tensor, vec2: Tensor, beta: float = 1, alpha: float = 1): Tensor = self.dynamicCppCall("_addr", vec1, vec2, beta, alpha).to(Tensor)
template u_addr_u*(self: Tensor, vec1: Tensor, vec2: Tensor, beta: float = 1, alpha: float = 1): Tensor = self.dynamicCppCall("_addr_", vec1, vec2, beta, alpha).to(Tensor)
template u_ger_out*(aresult: Tensor, self: Tensor, vec2: Tensor): Tensor = dynamicCCall("at::_ger_out", aresult, self, vec2).to(Tensor)
template u_ger*(self: Tensor, vec2: Tensor): Tensor = self.dynamicCppCall("_ger", vec2).to(Tensor)
template u_mv_out*(aresult: Tensor, self: Tensor, vec: Tensor): Tensor = dynamicCCall("at::_mv_out", aresult, self, vec).to(Tensor)
template u_mv*(self: Tensor, vec: Tensor): Tensor = self.dynamicCppCall("_mv", vec).to(Tensor)
template u_mm_out*(aresult: Tensor, self: Tensor, mat2: Tensor): Tensor = dynamicCCall("at::_mm_out", aresult, self, mat2).to(Tensor)
template u_mm*(self: Tensor, mat2: Tensor): Tensor = self.dynamicCppCall("_mm", mat2).to(Tensor)
template bmm_out*(aresult: Tensor, self: Tensor, mat2: Tensor): Tensor = dynamicCCall("at::bmm_out", aresult, self, mat2).to(Tensor)
template bmm*(self: Tensor, mat2: Tensor): Tensor = self.dynamicCppCall("bmm", mat2).to(Tensor)
template addbmm_out*(aresult: Tensor, self: Tensor, batch1: Tensor, batch2: Tensor, beta: float = 1, alpha: float = 1): Tensor = dynamicCCall("at::addbmm_out", aresult, self, batch1, batch2, beta, alpha).to(Tensor)
template addbmm*(self: Tensor, batch1: Tensor, batch2: Tensor, beta: float = 1, alpha: float = 1): Tensor = self.dynamicCppCall("addbmm", batch1, batch2, beta, alpha).to(Tensor)
template addbmm_u*(self: Tensor, batch1: Tensor, batch2: Tensor, beta: float = 1, alpha: float = 1): Tensor = self.dynamicCppCall("addbmm_", batch1, batch2, beta, alpha).to(Tensor)
template baddbmm_out*(aresult: Tensor, self: Tensor, batch1: Tensor, batch2: Tensor, beta: float = 1, alpha: float = 1): Tensor = dynamicCCall("at::baddbmm_out", aresult, self, batch1, batch2, beta, alpha).to(Tensor)
template baddbmm*(self: Tensor, batch1: Tensor, batch2: Tensor, beta: float = 1, alpha: float = 1): Tensor = self.dynamicCppCall("baddbmm", batch1, batch2, beta, alpha).to(Tensor)
template baddbmm_u*(self: Tensor, batch1: Tensor, batch2: Tensor, beta: float = 1, alpha: float = 1): Tensor = self.dynamicCppCall("baddbmm_", batch1, batch2, beta, alpha).to(Tensor)
template addcmul_out*(aresult: Tensor, self: Tensor, tensor1: Tensor, tensor2: Tensor, value: float = 1): Tensor = dynamicCCall("at::addcmul_out", aresult, self, tensor1, tensor2, value).to(Tensor)
template addcmul*(self: Tensor, tensor1: Tensor, tensor2: Tensor, value: float = 1): Tensor = self.dynamicCppCall("addcmul", tensor1, tensor2, value).to(Tensor)
template addcmul_u*(self: Tensor, tensor1: Tensor, tensor2: Tensor, value: float = 1): Tensor = self.dynamicCppCall("addcmul_", tensor1, tensor2, value).to(Tensor)
template addcdiv_out*(aresult: Tensor, self: Tensor, tensor1: Tensor, tensor2: Tensor, value: float = 1): Tensor = dynamicCCall("at::addcdiv_out", aresult, self, tensor1, tensor2, value).to(Tensor)
template addcdiv*(self: Tensor, tensor1: Tensor, tensor2: Tensor, value: float = 1): Tensor = self.dynamicCppCall("addcdiv", tensor1, tensor2, value).to(Tensor)
template addcdiv_u*(self: Tensor, tensor1: Tensor, tensor2: Tensor, value: float = 1): Tensor = self.dynamicCppCall("addcdiv_", tensor1, tensor2, value).to(Tensor)
template u_gesv_single_out*(solution: Tensor, lu: Tensor, self: Tensor, A: Tensor): (Tensor, Tensor) = dynamicCCall("at::_gesv_single_out", solution, lu, self, A).to(ATensorRTuple2).toNimTensorTuple()
template u_gesv_single*(self: Tensor, A: Tensor): (Tensor, Tensor) = self.dynamicCppCall("_gesv_single", A).to(ATensorTuple2).toNimTensorTuple()
template gels_out*(res1: Tensor, res2: Tensor, self: Tensor, A: Tensor): (Tensor, Tensor) = dynamicCCall("at::gels_out", res1, res2, self, A).to(ATensorRTuple2).toNimTensorTuple()
template gels*(self: Tensor, A: Tensor): (Tensor, Tensor) = self.dynamicCppCall("gels", A).to(ATensorTuple2).toNimTensorTuple()
template trtrs_out*(res1: Tensor, res2: Tensor, self: Tensor, A: Tensor, upper: bool = true, transpose: bool = false, unitriangular: bool = false): (Tensor, Tensor) = dynamicCCall("at::trtrs_out", res1, res2, self, A, upper, transpose, unitriangular).to(ATensorRTuple2).toNimTensorTuple()
template trtrs*(self: Tensor, A: Tensor, upper: bool = true, transpose: bool = false, unitriangular: bool = false): (Tensor, Tensor) = self.dynamicCppCall("trtrs", A, upper, transpose, unitriangular).to(ATensorTuple2).toNimTensorTuple()
template symeig_out*(res1: Tensor, res2: Tensor, self: Tensor, eigenvectors: bool = false, upper: bool = true): (Tensor, Tensor) = dynamicCCall("at::symeig_out", res1, res2, self, eigenvectors, upper).to(ATensorRTuple2).toNimTensorTuple()
template symeig*(self: Tensor, eigenvectors: bool = false, upper: bool = true): (Tensor, Tensor) = self.dynamicCppCall("symeig", eigenvectors, upper).to(ATensorTuple2).toNimTensorTuple()
template eig_out*(res1: Tensor, res2: Tensor, self: Tensor, eigenvectors: bool = false): (Tensor, Tensor) = dynamicCCall("at::eig_out", res1, res2, self, eigenvectors).to(ATensorRTuple2).toNimTensorTuple()
template eig*(self: Tensor, eigenvectors: bool = false): (Tensor, Tensor) = self.dynamicCppCall("eig", eigenvectors).to(ATensorTuple2).toNimTensorTuple()
template svd_out*(res1: Tensor, res2: Tensor, res3: Tensor, self: Tensor, some: bool = true): (Tensor, Tensor, Tensor) = dynamicCCall("at::svd_out", res1, res2, res3, self, some).to(ATensorRTuple3).toNimTensorTuple()
template svd*(self: Tensor, some: bool = true): (Tensor, Tensor, Tensor) = self.dynamicCppCall("svd", some).to(ATensorTuple3).toNimTensorTuple()
template u_getri_out*(output: Tensor, self: Tensor): Tensor = dynamicCCall("at::_getri_out", output, self).to(Tensor)
template u_getri*(self: Tensor): Tensor = self.dynamicCppCall("_getri").to(Tensor)
template potrf_out*(output: Tensor, self: Tensor, upper: bool = true): Tensor = dynamicCCall("at::potrf_out", output, self, upper).to(Tensor)
template potrf*(self: Tensor, upper: bool = true): Tensor = self.dynamicCppCall("potrf", upper).to(Tensor)
template potrs_out*(aresult: Tensor, self: Tensor, input2: Tensor, upper: bool = true): Tensor = dynamicCCall("at::potrs_out", aresult, self, input2, upper).to(Tensor)
template potrs*(self: Tensor, input2: Tensor, upper: bool = true): Tensor = self.dynamicCppCall("potrs", input2, upper).to(Tensor)
template potri_out*(output: Tensor, self: Tensor, upper: bool = true): Tensor = dynamicCCall("at::potri_out", output, self, upper).to(Tensor)
template potri*(self: Tensor, upper: bool = true): Tensor = self.dynamicCppCall("potri", upper).to(Tensor)
template pstrf_out*(res1: Tensor, res2: Tensor, self: Tensor, upper: bool = true, tol: float = -1): (Tensor, Tensor) = dynamicCCall("at::pstrf_out", res1, res2, self, upper, tol).to(ATensorRTuple2).toNimTensorTuple()
template pstrf*(self: Tensor, upper: bool = true, tol: float = -1): (Tensor, Tensor) = self.dynamicCppCall("pstrf", upper, tol).to(ATensorTuple2).toNimTensorTuple()
template qr_out*(res1: Tensor, res2: Tensor, self: Tensor): (Tensor, Tensor) = dynamicCCall("at::qr_out", res1, res2, self).to(ATensorRTuple2).toNimTensorTuple()
template qr*(self: Tensor): (Tensor, Tensor) = self.dynamicCppCall("qr").to(ATensorTuple2).toNimTensorTuple()
template geqrf_out*(res1: Tensor, res2: Tensor, self: Tensor): (Tensor, Tensor) = dynamicCCall("at::geqrf_out", res1, res2, self).to(ATensorRTuple2).toNimTensorTuple()
template geqrf*(self: Tensor): (Tensor, Tensor) = self.dynamicCppCall("geqrf").to(ATensorTuple2).toNimTensorTuple()
template orgqr_out*(aresult: Tensor, self: Tensor, input2: Tensor): Tensor = dynamicCCall("at::orgqr_out", aresult, self, input2).to(Tensor)
template orgqr*(self: Tensor, input2: Tensor): Tensor = self.dynamicCppCall("orgqr", input2).to(Tensor)
template ormqr_out*(aresult: Tensor, self: Tensor, input2: Tensor, input3: Tensor, left: bool = true, transpose: bool = false): Tensor = dynamicCCall("at::ormqr_out", aresult, self, input2, input3, left, transpose).to(Tensor)
template ormqr*(self: Tensor, input2: Tensor, input3: Tensor, left: bool = true, transpose: bool = false): Tensor = self.dynamicCppCall("ormqr", input2, input3, left, transpose).to(Tensor)
template btrifact_out*(aresult: Tensor, pivots: Tensor, self: Tensor, pivot: bool = true): (Tensor, Tensor) = dynamicCCall("at::btrifact_out", aresult, pivots, self, pivot).to(ATensorRTuple2).toNimTensorTuple()
template btrifact*(self: Tensor, pivot: bool = true): (Tensor, Tensor) = self.dynamicCppCall("btrifact", pivot).to(ATensorTuple2).toNimTensorTuple()
template btrifact_with_info_out*(aresult: Tensor, pivots: Tensor, info: Tensor, self: Tensor, pivot: bool = true): (Tensor, Tensor, Tensor) = dynamicCCall("at::btrifact_with_info_out", aresult, pivots, info, self, pivot).to(ATensorRTuple3).toNimTensorTuple()
template btrifact_with_info*(self: Tensor, pivot: bool = true): (Tensor, Tensor, Tensor) = self.dynamicCppCall("btrifact_with_info", pivot).to(ATensorTuple3).toNimTensorTuple()
template btrisolve_out*(aresult: Tensor, self: Tensor, LU_data: Tensor, LU_pivots: Tensor): Tensor = dynamicCCall("at::btrisolve_out", aresult, self, LU_data, LU_pivots).to(Tensor)
template btrisolve*(self: Tensor, LU_data: Tensor, LU_pivots: Tensor): Tensor = self.dynamicCppCall("btrisolve", LU_data, LU_pivots).to(Tensor)
template random_u*(self: Tensor, afrom: int64, ato: int64, generator: pointer = nil): Tensor = self.dynamicCppCall("random_", afrom, ato, generator).to(Tensor)
template random_u*(self: Tensor, ato: int64, generator: pointer = nil): Tensor = self.dynamicCppCall("random_", ato, generator).to(Tensor)
template random_u*(self: Tensor, generator: pointer = nil): Tensor = self.dynamicCppCall("random_", generator).to(Tensor)
template multinomial_out*(aresult: Tensor, self: Tensor, num_samples: int64, replacement: bool = false, generator: pointer = nil): Tensor = dynamicCCall("at::multinomial_out", aresult, self, num_samples, replacement, generator).to(Tensor)
template multinomial*(self: Tensor, num_samples: int64, replacement: bool = false, generator: pointer = nil): Tensor = self.dynamicCppCall("multinomial", num_samples, replacement, generator).to(Tensor)
template uniform_u*(self: Tensor, afrom: float64 = 0, ato: float64 = 1, generator: pointer = nil): Tensor = self.dynamicCppCall("uniform_", afrom, ato, generator).to(Tensor)
template normal_out*(output: Tensor, mean: Tensor, std: float64 = 1, generator: pointer = nil): Tensor = dynamicCCall("at::normal_out", output, mean, std, generator).to(Tensor)
template normal*(mean: Tensor, std: float64 = 1, generator: pointer = nil): Tensor = dynamicCCall("at::normal", mean, std, generator).to(Tensor)
template normal_out*(output: Tensor, mean: float64, std: Tensor, generator: pointer = nil): Tensor = dynamicCCall("at::normal_out", output, mean, std, generator).to(Tensor)
template normal*(mean: float64, std: Tensor, generator: pointer = nil): Tensor = dynamicCCall("at::normal", mean, std, generator).to(Tensor)
template normal_out*(output: Tensor, mean: Tensor, std: Tensor, generator: pointer = nil): Tensor = dynamicCCall("at::normal_out", output, mean, std, generator).to(Tensor)
template normal*(mean: Tensor, std: Tensor, generator: pointer = nil): Tensor = dynamicCCall("at::normal", mean, std, generator).to(Tensor)
template normal_u*(self: Tensor, mean: float64 = 0, std: float64 = 1, generator: pointer = nil): Tensor = self.dynamicCppCall("normal_", mean, std, generator).to(Tensor)
template cauchy_u*(self: Tensor, median: float64 = 0, sigma: float64 = 1, generator: pointer = nil): Tensor = self.dynamicCppCall("cauchy_", median, sigma, generator).to(Tensor)
template log_normal_u*(self: Tensor, mean: float64 = 1, std: float64 = 2, generator: pointer = nil): Tensor = self.dynamicCppCall("log_normal_", mean, std, generator).to(Tensor)
template exponential_u*(self: Tensor, lambd: float64 = 1, generator: pointer = nil): Tensor = self.dynamicCppCall("exponential_", lambd, generator).to(Tensor)
template geometric_u*(self: Tensor, p: float64, generator: pointer = nil): Tensor = self.dynamicCppCall("geometric_", p, generator).to(Tensor)
template u_bernoulli_u*(self: Tensor, p: float64, generator: pointer = nil): Tensor = self.dynamicCppCall("_bernoulli_", p, generator).to(Tensor)
template u_th_bernoulli_out*(output: Tensor, self: Tensor, generator: pointer = nil): Tensor = dynamicCCall("at::_th_bernoulli_out", output, self, generator).to(Tensor)
template u_th_bernoulli*(self: Tensor, generator: pointer = nil): Tensor = self.dynamicCppCall("_th_bernoulli", generator).to(Tensor)
template u_dirichlet_grad_out*(output: Tensor, x: Tensor, alpha: Tensor, total: Tensor): Tensor = dynamicCCall("at::_dirichlet_grad_out", output, x, alpha, total).to(Tensor)
template u_dirichlet_grad*(x: Tensor, alpha: Tensor, total: Tensor): Tensor = dynamicCCall("at::_dirichlet_grad", x, alpha, total).to(Tensor)
template alias*(self: Tensor): Tensor = dynamicCCall("at::alias", self).to(Tensor)
template u_copy_ignoring_overlaps_u*(self: Tensor, src: Tensor): Tensor = self.dynamicCppCall("_copy_ignoring_overlaps_", src).to(Tensor)
template u_cat_out*(self: Tensor, tensors: TensorList, dim: int64 = 0): Tensor = dynamicCCall("at::_cat_out", self, tensors, dim).to(Tensor)
template u_cat*(tensors: TensorList, dim: int64 = 0): Tensor = dynamicCCall("at::_cat", tensors, dim).to(Tensor)
template binary_cross_entropy_out*(output: Tensor, self: Tensor, target: Tensor, weight: Tensor, reduction: int64): Tensor = dynamicCCall("at::binary_cross_entropy_out", output, self, target, weight, reduction).to(Tensor)
template binary_cross_entropy*(self: Tensor, target: Tensor, weight: Tensor, reduction: int64): Tensor = dynamicCCall("at::binary_cross_entropy", self, target, weight, reduction).to(Tensor)
template binary_cross_entropy_forward_out*(output: Tensor, self: Tensor, target: Tensor, weight: Tensor, reduction: int64): Tensor = dynamicCCall("at::binary_cross_entropy_forward_out", output, self, target, weight, reduction).to(Tensor)
template binary_cross_entropy_forward*(self: Tensor, target: Tensor, weight: Tensor, reduction: int64): Tensor = dynamicCCall("at::binary_cross_entropy_forward", self, target, weight, reduction).to(Tensor)
template binary_cross_entropy_backward_out*(grad_input: Tensor, grad_output: Tensor, self: Tensor, target: Tensor, weight: Tensor, reduction: int64): Tensor = dynamicCCall("at::binary_cross_entropy_backward_out", grad_input, grad_output, self, target, weight, reduction).to(Tensor)
template binary_cross_entropy_backward*(grad_output: Tensor, self: Tensor, target: Tensor, weight: Tensor, reduction: int64): Tensor = dynamicCCall("at::binary_cross_entropy_backward", grad_output, self, target, weight, reduction).to(Tensor)
template kl_div_out*(output: Tensor, self: Tensor, target: Tensor, reduction: int64): Tensor = dynamicCCall("at::kl_div_out", output, self, target, reduction).to(Tensor)
template kl_div*(self: Tensor, target: Tensor, reduction: int64): Tensor = dynamicCCall("at::kl_div", self, target, reduction).to(Tensor)
template kl_div_forward_out*(output: Tensor, self: Tensor, target: Tensor, reduction: int64): Tensor = dynamicCCall("at::kl_div_forward_out", output, self, target, reduction).to(Tensor)
template kl_div_forward*(self: Tensor, target: Tensor, reduction: int64): Tensor = dynamicCCall("at::kl_div_forward", self, target, reduction).to(Tensor)
template kl_div_backward_out*(grad_input: Tensor, grad_output: Tensor, self: Tensor, target: Tensor, reduction: int64): Tensor = dynamicCCall("at::kl_div_backward_out", grad_input, grad_output, self, target, reduction).to(Tensor)
template kl_div_backward*(grad_output: Tensor, self: Tensor, target: Tensor, reduction: int64): Tensor = dynamicCCall("at::kl_div_backward", grad_output, self, target, reduction).to(Tensor)
template l1_loss_out*(output: Tensor, self: Tensor, target: Tensor, reduction: int64): Tensor = dynamicCCall("at::l1_loss_out", output, self, target, reduction).to(Tensor)
template l1_loss*(self: Tensor, target: Tensor, reduction: int64): Tensor = dynamicCCall("at::l1_loss", self, target, reduction).to(Tensor)
template l1_loss_forward_out*(output: Tensor, self: Tensor, target: Tensor, reduction: int64): Tensor = dynamicCCall("at::l1_loss_forward_out", output, self, target, reduction).to(Tensor)
template l1_loss_forward*(self: Tensor, target: Tensor, reduction: int64): Tensor = dynamicCCall("at::l1_loss_forward", self, target, reduction).to(Tensor)
template l1_loss_backward_out*(grad_input: Tensor, grad_output: Tensor, self: Tensor, target: Tensor, reduction: int64): Tensor = dynamicCCall("at::l1_loss_backward_out", grad_input, grad_output, self, target, reduction).to(Tensor)
template l1_loss_backward*(grad_output: Tensor, self: Tensor, target: Tensor, reduction: int64): Tensor = dynamicCCall("at::l1_loss_backward", grad_output, self, target, reduction).to(Tensor)
template mse_loss_out*(output: Tensor, self: Tensor, target: Tensor, reduction: int64): Tensor = dynamicCCall("at::mse_loss_out", output, self, target, reduction).to(Tensor)
template mse_loss*(self: Tensor, target: Tensor, reduction: int64): Tensor = dynamicCCall("at::mse_loss", self, target, reduction).to(Tensor)
template mse_loss_forward_out*(output: Tensor, self: Tensor, target: Tensor, reduction: int64): Tensor = dynamicCCall("at::mse_loss_forward_out", output, self, target, reduction).to(Tensor)
template mse_loss_forward*(self: Tensor, target: Tensor, reduction: int64): Tensor = dynamicCCall("at::mse_loss_forward", self, target, reduction).to(Tensor)
template mse_loss_backward_out*(grad_input: Tensor, grad_output: Tensor, self: Tensor, target: Tensor, reduction: int64): Tensor = dynamicCCall("at::mse_loss_backward_out", grad_input, grad_output, self, target, reduction).to(Tensor)
template mse_loss_backward*(grad_output: Tensor, self: Tensor, target: Tensor, reduction: int64): Tensor = dynamicCCall("at::mse_loss_backward", grad_output, self, target, reduction).to(Tensor)
template multi_margin_loss_out*(output: Tensor, self: Tensor, target: Tensor, p: float = 1, margin: float = 1, weight: Tensor, reduction: int64): Tensor = dynamicCCall("at::multi_margin_loss_out", output, self, target, p, margin, weight, reduction).to(Tensor)
template multi_margin_loss*(self: Tensor, target: Tensor, p: float = 1, margin: float = 1, weight: Tensor, reduction: int64): Tensor = dynamicCCall("at::multi_margin_loss", self, target, p, margin, weight, reduction).to(Tensor)
template multi_margin_loss_forward_out*(output: Tensor, self: Tensor, target: Tensor, p: float, margin: float, weight: Tensor, reduction: int64): Tensor = dynamicCCall("at::multi_margin_loss_forward_out", output, self, target, p, margin, weight, reduction).to(Tensor)
template multi_margin_loss_forward*(self: Tensor, target: Tensor, p: float, margin: float, weight: Tensor, reduction: int64): Tensor = dynamicCCall("at::multi_margin_loss_forward", self, target, p, margin, weight, reduction).to(Tensor)
template multi_margin_loss_backward_out*(grad_input: Tensor, grad_output: Tensor, self: Tensor, target: Tensor, p: float, margin: float, weight: Tensor, reduction: int64): Tensor = dynamicCCall("at::multi_margin_loss_backward_out", grad_input, grad_output, self, target, p, margin, weight, reduction).to(Tensor)
template multi_margin_loss_backward*(grad_output: Tensor, self: Tensor, target: Tensor, p: float, margin: float, weight: Tensor, reduction: int64): Tensor = dynamicCCall("at::multi_margin_loss_backward", grad_output, self, target, p, margin, weight, reduction).to(Tensor)
template multilabel_margin_loss_out*(output: Tensor, self: Tensor, target: Tensor, reduction: int64): Tensor = dynamicCCall("at::multilabel_margin_loss_out", output, self, target, reduction).to(Tensor)
template multilabel_margin_loss*(self: Tensor, target: Tensor, reduction: int64): Tensor = dynamicCCall("at::multilabel_margin_loss", self, target, reduction).to(Tensor)
template multilabel_margin_loss_forward_out*(output: Tensor, is_target: Tensor, self: Tensor, target: Tensor, reduction: int64): (Tensor, Tensor) = dynamicCCall("at::multilabel_margin_loss_forward_out", output, is_target, self, target, reduction).to(ATensorRTuple2).toNimTensorTuple()
template multilabel_margin_loss_forward*(self: Tensor, target: Tensor, reduction: int64): (Tensor, Tensor) = dynamicCCall("at::multilabel_margin_loss_forward", self, target, reduction).to(ATensorTuple2).toNimTensorTuple()
template multilabel_margin_loss_backward_out*(grad_input: Tensor, grad_output: Tensor, self: Tensor, target: Tensor, reduction: int64, is_target: Tensor): Tensor = dynamicCCall("at::multilabel_margin_loss_backward_out", grad_input, grad_output, self, target, reduction, is_target).to(Tensor)
template multilabel_margin_loss_backward*(grad_output: Tensor, self: Tensor, target: Tensor, reduction: int64, is_target: Tensor): Tensor = dynamicCCall("at::multilabel_margin_loss_backward", grad_output, self, target, reduction, is_target).to(Tensor)
template nll_loss_out*(output: Tensor, self: Tensor, target: Tensor, weight: Tensor, reduction: int64, ignore_index: int64 = -100): Tensor = dynamicCCall("at::nll_loss_out", output, self, target, weight, reduction, ignore_index).to(Tensor)
template nll_loss*(self: Tensor, target: Tensor, weight: Tensor, reduction: int64, ignore_index: int64 = -100): Tensor = dynamicCCall("at::nll_loss", self, target, weight, reduction, ignore_index).to(Tensor)
template nll_loss_forward_out*(output: Tensor, total_weight: Tensor, self: Tensor, target: Tensor, weight: Tensor, reduction: int64, ignore_index: int64): (Tensor, Tensor) = dynamicCCall("at::nll_loss_forward_out", output, total_weight, self, target, weight, reduction, ignore_index).to(ATensorRTuple2).toNimTensorTuple()
template nll_loss_forward*(self: Tensor, target: Tensor, weight: Tensor, reduction: int64, ignore_index: int64): (Tensor, Tensor) = dynamicCCall("at::nll_loss_forward", self, target, weight, reduction, ignore_index).to(ATensorTuple2).toNimTensorTuple()
template nll_loss_backward_out*(grad_input: Tensor, grad_output: Tensor, self: Tensor, target: Tensor, weight: Tensor, reduction: int64, ignore_index: int64, total_weight: Tensor): Tensor = dynamicCCall("at::nll_loss_backward_out", grad_input, grad_output, self, target, weight, reduction, ignore_index, total_weight).to(Tensor)
template nll_loss_backward*(grad_output: Tensor, self: Tensor, target: Tensor, weight: Tensor, reduction: int64, ignore_index: int64, total_weight: Tensor): Tensor = dynamicCCall("at::nll_loss_backward", grad_output, self, target, weight, reduction, ignore_index, total_weight).to(Tensor)
template nll_loss2d_out*(output: Tensor, self: Tensor, target: Tensor, weight: Tensor, reduction: int64, ignore_index: int64 = -100): Tensor = dynamicCCall("at::nll_loss2d_out", output, self, target, weight, reduction, ignore_index).to(Tensor)
template nll_loss2d*(self: Tensor, target: Tensor, weight: Tensor, reduction: int64, ignore_index: int64 = -100): Tensor = dynamicCCall("at::nll_loss2d", self, target, weight, reduction, ignore_index).to(Tensor)
template nll_loss2d_forward_out*(output: Tensor, total_weight: Tensor, self: Tensor, target: Tensor, weight: Tensor, reduction: int64, ignore_index: int64): (Tensor, Tensor) = dynamicCCall("at::nll_loss2d_forward_out", output, total_weight, self, target, weight, reduction, ignore_index).to(ATensorRTuple2).toNimTensorTuple()
template nll_loss2d_forward*(self: Tensor, target: Tensor, weight: Tensor, reduction: int64, ignore_index: int64): (Tensor, Tensor) = dynamicCCall("at::nll_loss2d_forward", self, target, weight, reduction, ignore_index).to(ATensorTuple2).toNimTensorTuple()
template nll_loss2d_backward_out*(grad_input: Tensor, grad_output: Tensor, self: Tensor, target: Tensor, weight: Tensor, reduction: int64, ignore_index: int64, total_weight: Tensor): Tensor = dynamicCCall("at::nll_loss2d_backward_out", grad_input, grad_output, self, target, weight, reduction, ignore_index, total_weight).to(Tensor)
template nll_loss2d_backward*(grad_output: Tensor, self: Tensor, target: Tensor, weight: Tensor, reduction: int64, ignore_index: int64, total_weight: Tensor): Tensor = dynamicCCall("at::nll_loss2d_backward", grad_output, self, target, weight, reduction, ignore_index, total_weight).to(Tensor)
template smooth_l1_loss_out*(output: Tensor, self: Tensor, target: Tensor, reduction: int64): Tensor = dynamicCCall("at::smooth_l1_loss_out", output, self, target, reduction).to(Tensor)
template smooth_l1_loss*(self: Tensor, target: Tensor, reduction: int64): Tensor = dynamicCCall("at::smooth_l1_loss", self, target, reduction).to(Tensor)
template smooth_l1_loss_forward_out*(output: Tensor, self: Tensor, target: Tensor, reduction: int64): Tensor = dynamicCCall("at::smooth_l1_loss_forward_out", output, self, target, reduction).to(Tensor)
template smooth_l1_loss_forward*(self: Tensor, target: Tensor, reduction: int64): Tensor = dynamicCCall("at::smooth_l1_loss_forward", self, target, reduction).to(Tensor)
template smooth_l1_loss_backward_out*(grad_input: Tensor, grad_output: Tensor, self: Tensor, target: Tensor, reduction: int64): Tensor = dynamicCCall("at::smooth_l1_loss_backward_out", grad_input, grad_output, self, target, reduction).to(Tensor)
template smooth_l1_loss_backward*(grad_output: Tensor, self: Tensor, target: Tensor, reduction: int64): Tensor = dynamicCCall("at::smooth_l1_loss_backward", grad_output, self, target, reduction).to(Tensor)
template soft_margin_loss_out*(output: Tensor, self: Tensor, target: Tensor, reduction: int64): Tensor = dynamicCCall("at::soft_margin_loss_out", output, self, target, reduction).to(Tensor)
template soft_margin_loss*(self: Tensor, target: Tensor, reduction: int64): Tensor = dynamicCCall("at::soft_margin_loss", self, target, reduction).to(Tensor)
template soft_margin_loss_forward_out*(output: Tensor, self: Tensor, target: Tensor, reduction: int64): Tensor = dynamicCCall("at::soft_margin_loss_forward_out", output, self, target, reduction).to(Tensor)
template soft_margin_loss_forward*(self: Tensor, target: Tensor, reduction: int64): Tensor = dynamicCCall("at::soft_margin_loss_forward", self, target, reduction).to(Tensor)
template soft_margin_loss_backward_out*(grad_input: Tensor, grad_output: Tensor, self: Tensor, target: Tensor, reduction: int64): Tensor = dynamicCCall("at::soft_margin_loss_backward_out", grad_input, grad_output, self, target, reduction).to(Tensor)
template soft_margin_loss_backward*(grad_output: Tensor, self: Tensor, target: Tensor, reduction: int64): Tensor = dynamicCCall("at::soft_margin_loss_backward", grad_output, self, target, reduction).to(Tensor)
template elu_out*(output: Tensor, self: Tensor, alpha: float = 1, scale: float = 1, input_scale: float = 1): Tensor = dynamicCCall("at::elu_out", output, self, alpha, scale, input_scale).to(Tensor)
template elu*(self: Tensor, alpha: float = 1, scale: float = 1, input_scale: float = 1): Tensor = dynamicCCall("at::elu", self, alpha, scale, input_scale).to(Tensor)
template elu_forward_out*(output: Tensor, self: Tensor, alpha: float, scale: float, input_scale: float): Tensor = dynamicCCall("at::elu_forward_out", output, self, alpha, scale, input_scale).to(Tensor)
template elu_forward*(self: Tensor, alpha: float, scale: float, input_scale: float): Tensor = dynamicCCall("at::elu_forward", self, alpha, scale, input_scale).to(Tensor)
template elu_backward_out*(grad_input: Tensor, grad_output: Tensor, alpha: float, scale: float, input_scale: float, output: Tensor): Tensor = dynamicCCall("at::elu_backward_out", grad_input, grad_output, alpha, scale, input_scale, output).to(Tensor)
template elu_backward*(grad_output: Tensor, alpha: float, scale: float, input_scale: float, output: Tensor): Tensor = dynamicCCall("at::elu_backward", grad_output, alpha, scale, input_scale, output).to(Tensor)
template elu_u*(self: Tensor, alpha: float = 1, scale: float = 1, input_scale: float = 1): Tensor = dynamicCCall("at::elu_", self, alpha, scale, input_scale).to(Tensor)
template elu_forward_u*(self: Tensor, alpha: float, scale: float, input_scale: float): Tensor = dynamicCCall("at::elu_forward_", self, alpha, scale, input_scale).to(Tensor)
template glu_out*(output: Tensor, self: Tensor, dim: int64 = -1): Tensor = dynamicCCall("at::glu_out", output, self, dim).to(Tensor)
template glu*(self: Tensor, dim: int64 = -1): Tensor = dynamicCCall("at::glu", self, dim).to(Tensor)
template glu_forward_out*(output: Tensor, self: Tensor, dim: int64): Tensor = dynamicCCall("at::glu_forward_out", output, self, dim).to(Tensor)
template glu_forward*(self: Tensor, dim: int64): Tensor = dynamicCCall("at::glu_forward", self, dim).to(Tensor)
template glu_backward_out*(grad_input: Tensor, grad_output: Tensor, self: Tensor, dim: int64): Tensor = dynamicCCall("at::glu_backward_out", grad_input, grad_output, self, dim).to(Tensor)
template glu_backward*(grad_output: Tensor, self: Tensor, dim: int64): Tensor = dynamicCCall("at::glu_backward", grad_output, self, dim).to(Tensor)
template hardtanh_out*(output: Tensor, self: Tensor, min_val: float = -1, max_val: float = 1): Tensor = dynamicCCall("at::hardtanh_out", output, self, min_val, max_val).to(Tensor)
template hardtanh*(self: Tensor, min_val: float = -1, max_val: float = 1): Tensor = dynamicCCall("at::hardtanh", self, min_val, max_val).to(Tensor)
template hardtanh_forward_out*(output: Tensor, self: Tensor, min_val: float, max_val: float): Tensor = dynamicCCall("at::hardtanh_forward_out", output, self, min_val, max_val).to(Tensor)
template hardtanh_forward*(self: Tensor, min_val: float, max_val: float): Tensor = dynamicCCall("at::hardtanh_forward", self, min_val, max_val).to(Tensor)
template hardtanh_backward_out*(grad_input: Tensor, grad_output: Tensor, self: Tensor, min_val: float, max_val: float): Tensor = dynamicCCall("at::hardtanh_backward_out", grad_input, grad_output, self, min_val, max_val).to(Tensor)
template hardtanh_backward*(grad_output: Tensor, self: Tensor, min_val: float, max_val: float): Tensor = dynamicCCall("at::hardtanh_backward", grad_output, self, min_val, max_val).to(Tensor)
template hardtanh_u*(self: Tensor, min_val: float = -1, max_val: float = 1): Tensor = dynamicCCall("at::hardtanh_", self, min_val, max_val).to(Tensor)
template hardtanh_forward_u*(self: Tensor, min_val: float, max_val: float): Tensor = dynamicCCall("at::hardtanh_forward_", self, min_val, max_val).to(Tensor)
template leaky_relu_out*(output: Tensor, self: Tensor, negative_slope: float): Tensor = dynamicCCall("at::leaky_relu_out", output, self, negative_slope).to(Tensor)
template leaky_relu*(self: Tensor, negative_slope: float): Tensor = dynamicCCall("at::leaky_relu", self, negative_slope).to(Tensor)
template leaky_relu_forward_out*(output: Tensor, self: Tensor, negative_slope: float): Tensor = dynamicCCall("at::leaky_relu_forward_out", output, self, negative_slope).to(Tensor)
template leaky_relu_forward*(self: Tensor, negative_slope: float): Tensor = dynamicCCall("at::leaky_relu_forward", self, negative_slope).to(Tensor)
template leaky_relu_backward_out*(grad_input: Tensor, grad_output: Tensor, self: Tensor, negative_slope: float): Tensor = dynamicCCall("at::leaky_relu_backward_out", grad_input, grad_output, self, negative_slope).to(Tensor)
template leaky_relu_backward*(grad_output: Tensor, self: Tensor, negative_slope: float): Tensor = dynamicCCall("at::leaky_relu_backward", grad_output, self, negative_slope).to(Tensor)
template leaky_relu_u*(self: Tensor, negative_slope: float): Tensor = dynamicCCall("at::leaky_relu_", self, negative_slope).to(Tensor)
template leaky_relu_forward_u*(self: Tensor, negative_slope: float): Tensor = dynamicCCall("at::leaky_relu_forward_", self, negative_slope).to(Tensor)
template log_sigmoid_out*(output: Tensor, self: Tensor): Tensor = dynamicCCall("at::log_sigmoid_out", output, self).to(Tensor)
template log_sigmoid*(self: Tensor): Tensor = dynamicCCall("at::log_sigmoid", self).to(Tensor)
template log_sigmoid_forward_out*(output: Tensor, buffer: Tensor, self: Tensor): (Tensor, Tensor) = dynamicCCall("at::log_sigmoid_forward_out", output, buffer, self).to(ATensorRTuple2).toNimTensorTuple()
template log_sigmoid_forward*(self: Tensor): (Tensor, Tensor) = dynamicCCall("at::log_sigmoid_forward", self).to(ATensorTuple2).toNimTensorTuple()
template log_sigmoid_backward_out*(grad_input: Tensor, grad_output: Tensor, self: Tensor, buffer: Tensor): Tensor = dynamicCCall("at::log_sigmoid_backward_out", grad_input, grad_output, self, buffer).to(Tensor)
template log_sigmoid_backward*(grad_output: Tensor, self: Tensor, buffer: Tensor): Tensor = dynamicCCall("at::log_sigmoid_backward", grad_output, self, buffer).to(Tensor)
template prelu_out*(output: Tensor, self: Tensor, weight: Tensor): Tensor = dynamicCCall("at::prelu_out", output, self, weight).to(Tensor)
template prelu*(self: Tensor, weight: Tensor): Tensor = dynamicCCall("at::prelu", self, weight).to(Tensor)
template prelu_forward_out*(output: Tensor, self: Tensor, weight: Tensor): Tensor = dynamicCCall("at::prelu_forward_out", output, self, weight).to(Tensor)
template prelu_forward*(self: Tensor, weight: Tensor): Tensor = dynamicCCall("at::prelu_forward", self, weight).to(Tensor)
template prelu_backward_out*(grad_input: Tensor, grad_weight: Tensor, grad_output: Tensor, self: Tensor, weight: Tensor): (Tensor, Tensor) = dynamicCCall("at::prelu_backward_out", grad_input, grad_weight, grad_output, self, weight).to(ATensorRTuple2).toNimTensorTuple()
template prelu_backward*(grad_output: Tensor, self: Tensor, weight: Tensor, output_mask: StdArray[bool, 2]): (Tensor, Tensor) = dynamicCCall("at::prelu_backward", grad_output, self, weight, output_mask).to(ATensorTuple2).toNimTensorTuple()
template rrelu_with_noise_out*(output: Tensor, self: Tensor, noise: Tensor, lower: float, upper: float, training: bool = false, generator: pointer = nil): Tensor = dynamicCCall("at::rrelu_with_noise_out", output, self, noise, lower, upper, training, generator).to(Tensor)
template rrelu_with_noise*(self: Tensor, noise: Tensor, lower: float, upper: float, training: bool = false, generator: pointer = nil): Tensor = dynamicCCall("at::rrelu_with_noise", self, noise, lower, upper, training, generator).to(Tensor)
template rrelu_with_noise_forward_out*(output: Tensor, self: Tensor, noise: Tensor, lower: float, upper: float, training: bool, generator: pointer): Tensor = dynamicCCall("at::rrelu_with_noise_forward_out", output, self, noise, lower, upper, training, generator).to(Tensor)
template rrelu_with_noise_forward*(self: Tensor, noise: Tensor, lower: float, upper: float, training: bool, generator: pointer): Tensor = dynamicCCall("at::rrelu_with_noise_forward", self, noise, lower, upper, training, generator).to(Tensor)
template rrelu_with_noise_backward_out*(grad_input: Tensor, grad_output: Tensor, self: Tensor, noise: Tensor, lower: float, upper: float, training: bool): Tensor = dynamicCCall("at::rrelu_with_noise_backward_out", grad_input, grad_output, self, noise, lower, upper, training).to(Tensor)
template rrelu_with_noise_backward*(grad_output: Tensor, self: Tensor, noise: Tensor, lower: float, upper: float, training: bool): Tensor = dynamicCCall("at::rrelu_with_noise_backward", grad_output, self, noise, lower, upper, training).to(Tensor)
template rrelu_with_noise_u*(self: Tensor, noise: Tensor, lower: float, upper: float, training: bool = false, generator: pointer = nil): Tensor = dynamicCCall("at::rrelu_with_noise_", self, noise, lower, upper, training, generator).to(Tensor)
template rrelu_with_noise_forward_u*(self: Tensor, noise: Tensor, lower: float, upper: float, training: bool, generator: pointer): Tensor = dynamicCCall("at::rrelu_with_noise_forward_", self, noise, lower, upper, training, generator).to(Tensor)
template softplus_out*(output: Tensor, self: Tensor, beta: float = 1, threshold: float = 20): Tensor = dynamicCCall("at::softplus_out", output, self, beta, threshold).to(Tensor)
template softplus*(self: Tensor, beta: float = 1, threshold: float = 20): Tensor = dynamicCCall("at::softplus", self, beta, threshold).to(Tensor)
template softplus_forward_out*(output: Tensor, self: Tensor, beta: float, threshold: float): Tensor = dynamicCCall("at::softplus_forward_out", output, self, beta, threshold).to(Tensor)
template softplus_forward*(self: Tensor, beta: float, threshold: float): Tensor = dynamicCCall("at::softplus_forward", self, beta, threshold).to(Tensor)
template softplus_backward_out*(grad_input: Tensor, grad_output: Tensor, self: Tensor, beta: float, threshold: float, output: Tensor): Tensor = dynamicCCall("at::softplus_backward_out", grad_input, grad_output, self, beta, threshold, output).to(Tensor)
template softplus_backward*(grad_output: Tensor, self: Tensor, beta: float, threshold: float, output: Tensor): Tensor = dynamicCCall("at::softplus_backward", grad_output, self, beta, threshold, output).to(Tensor)
template softshrink_out*(output: Tensor, self: Tensor, lambd: float): Tensor = dynamicCCall("at::softshrink_out", output, self, lambd).to(Tensor)
template softshrink*(self: Tensor, lambd: float): Tensor = dynamicCCall("at::softshrink", self, lambd).to(Tensor)
template softshrink_forward_out*(output: Tensor, self: Tensor, lambd: float): Tensor = dynamicCCall("at::softshrink_forward_out", output, self, lambd).to(Tensor)
template softshrink_forward*(self: Tensor, lambd: float): Tensor = dynamicCCall("at::softshrink_forward", self, lambd).to(Tensor)
template softshrink_backward_out*(grad_input: Tensor, grad_output: Tensor, self: Tensor, lambd: float): Tensor = dynamicCCall("at::softshrink_backward_out", grad_input, grad_output, self, lambd).to(Tensor)
template softshrink_backward*(grad_output: Tensor, self: Tensor, lambd: float): Tensor = dynamicCCall("at::softshrink_backward", grad_output, self, lambd).to(Tensor)
template threshold_out*(output: Tensor, self: Tensor, threshold: float, value: float): Tensor = dynamicCCall("at::threshold_out", output, self, threshold, value).to(Tensor)
template threshold*(self: Tensor, threshold: float, value: float): Tensor = dynamicCCall("at::threshold", self, threshold, value).to(Tensor)
template threshold_forward_out*(output: Tensor, self: Tensor, threshold: float, value: float): Tensor = dynamicCCall("at::threshold_forward_out", output, self, threshold, value).to(Tensor)
template threshold_forward*(self: Tensor, threshold: float, value: float): Tensor = dynamicCCall("at::threshold_forward", self, threshold, value).to(Tensor)
template threshold_backward_out*(grad_input: Tensor, grad_output: Tensor, self: Tensor, threshold: float, value: float): Tensor = dynamicCCall("at::threshold_backward_out", grad_input, grad_output, self, threshold, value).to(Tensor)
template threshold_backward*(grad_output: Tensor, self: Tensor, threshold: float, value: float): Tensor = dynamicCCall("at::threshold_backward", grad_output, self, threshold, value).to(Tensor)
template threshold_u*(self: Tensor, threshold: float, value: float): Tensor = dynamicCCall("at::threshold_", self, threshold, value).to(Tensor)
template threshold_forward_u*(self: Tensor, threshold: float, value: float): Tensor = dynamicCCall("at::threshold_forward_", self, threshold, value).to(Tensor)
template adaptive_avg_pool2d_out*(output: Tensor, self: Tensor, output_size: IntList): Tensor = dynamicCCall("at::adaptive_avg_pool2d_out", output, self, output_size).to(Tensor)
template adaptive_avg_pool2d*(self: Tensor, output_size: IntList): Tensor = dynamicCCall("at::adaptive_avg_pool2d", self, output_size).to(Tensor)
template adaptive_avg_pool2d_forward_out*(output: Tensor, self: Tensor, output_size: IntList): Tensor = dynamicCCall("at::adaptive_avg_pool2d_forward_out", output, self, output_size).to(Tensor)
template adaptive_avg_pool2d_forward*(self: Tensor, output_size: IntList): Tensor = dynamicCCall("at::adaptive_avg_pool2d_forward", self, output_size).to(Tensor)
template adaptive_avg_pool2d_backward_out*(grad_input: Tensor, grad_output: Tensor, self: Tensor): Tensor = dynamicCCall("at::adaptive_avg_pool2d_backward_out", grad_input, grad_output, self).to(Tensor)
template adaptive_avg_pool2d_backward*(grad_output: Tensor, self: Tensor): Tensor = dynamicCCall("at::adaptive_avg_pool2d_backward", grad_output, self).to(Tensor)
template adaptive_avg_pool3d_out*(output: Tensor, self: Tensor, output_size: IntList): Tensor = dynamicCCall("at::adaptive_avg_pool3d_out", output, self, output_size).to(Tensor)
template adaptive_avg_pool3d*(self: Tensor, output_size: IntList): Tensor = dynamicCCall("at::adaptive_avg_pool3d", self, output_size).to(Tensor)
template adaptive_avg_pool3d_forward_out*(output: Tensor, self: Tensor, output_size: IntList): Tensor = dynamicCCall("at::adaptive_avg_pool3d_forward_out", output, self, output_size).to(Tensor)
template adaptive_avg_pool3d_forward*(self: Tensor, output_size: IntList): Tensor = dynamicCCall("at::adaptive_avg_pool3d_forward", self, output_size).to(Tensor)
template adaptive_avg_pool3d_backward_out*(grad_input: Tensor, grad_output: Tensor, self: Tensor): Tensor = dynamicCCall("at::adaptive_avg_pool3d_backward_out", grad_input, grad_output, self).to(Tensor)
template adaptive_avg_pool3d_backward*(grad_output: Tensor, self: Tensor): Tensor = dynamicCCall("at::adaptive_avg_pool3d_backward", grad_output, self).to(Tensor)
template adaptive_max_pool2d_out*(output: Tensor, indices: Tensor, self: Tensor, output_size: IntList): (Tensor, Tensor) = dynamicCCall("at::adaptive_max_pool2d_out", output, indices, self, output_size).to(ATensorRTuple2).toNimTensorTuple()
template adaptive_max_pool2d*(self: Tensor, output_size: IntList): (Tensor, Tensor) = dynamicCCall("at::adaptive_max_pool2d", self, output_size).to(ATensorTuple2).toNimTensorTuple()
template adaptive_max_pool2d_forward_out*(output: Tensor, indices: Tensor, self: Tensor, output_size: IntList): (Tensor, Tensor) = dynamicCCall("at::adaptive_max_pool2d_forward_out", output, indices, self, output_size).to(ATensorRTuple2).toNimTensorTuple()
template adaptive_max_pool2d_forward*(self: Tensor, output_size: IntList): (Tensor, Tensor) = dynamicCCall("at::adaptive_max_pool2d_forward", self, output_size).to(ATensorTuple2).toNimTensorTuple()
template adaptive_max_pool2d_backward_out*(grad_input: Tensor, grad_output: Tensor, self: Tensor, indices: Tensor): Tensor = dynamicCCall("at::adaptive_max_pool2d_backward_out", grad_input, grad_output, self, indices).to(Tensor)
template adaptive_max_pool2d_backward*(grad_output: Tensor, self: Tensor, indices: Tensor): Tensor = dynamicCCall("at::adaptive_max_pool2d_backward", grad_output, self, indices).to(Tensor)
template adaptive_max_pool3d_out*(output: Tensor, indices: Tensor, self: Tensor, output_size: IntList): (Tensor, Tensor) = dynamicCCall("at::adaptive_max_pool3d_out", output, indices, self, output_size).to(ATensorRTuple2).toNimTensorTuple()
template adaptive_max_pool3d*(self: Tensor, output_size: IntList): (Tensor, Tensor) = dynamicCCall("at::adaptive_max_pool3d", self, output_size).to(ATensorTuple2).toNimTensorTuple()
template adaptive_max_pool3d_forward_out*(output: Tensor, indices: Tensor, self: Tensor, output_size: IntList): (Tensor, Tensor) = dynamicCCall("at::adaptive_max_pool3d_forward_out", output, indices, self, output_size).to(ATensorRTuple2).toNimTensorTuple()
template adaptive_max_pool3d_forward*(self: Tensor, output_size: IntList): (Tensor, Tensor) = dynamicCCall("at::adaptive_max_pool3d_forward", self, output_size).to(ATensorTuple2).toNimTensorTuple()
template adaptive_max_pool3d_backward_out*(grad_input: Tensor, grad_output: Tensor, self: Tensor, indices: Tensor): Tensor = dynamicCCall("at::adaptive_max_pool3d_backward_out", grad_input, grad_output, self, indices).to(Tensor)
template adaptive_max_pool3d_backward*(grad_output: Tensor, self: Tensor, indices: Tensor): Tensor = dynamicCCall("at::adaptive_max_pool3d_backward", grad_output, self, indices).to(Tensor)
template avg_pool2d_out*(output: Tensor, self: Tensor, kernel_size: IntList, stride: IntList, padding: IntList, ceil_mode: bool = false, count_include_pad: bool = true): Tensor = dynamicCCall("at::avg_pool2d_out", output, self, kernel_size, stride, padding, ceil_mode, count_include_pad).to(Tensor)
template avg_pool2d*(self: Tensor, kernel_size: IntList, stride: IntList, padding: IntList, ceil_mode: bool = false, count_include_pad: bool = true): Tensor = dynamicCCall("at::avg_pool2d", self, kernel_size, stride, padding, ceil_mode, count_include_pad).to(Tensor)
template avg_pool2d_forward_out*(output: Tensor, self: Tensor, kernel_size: IntList, stride: IntList, padding: IntList, ceil_mode: bool, count_include_pad: bool): Tensor = dynamicCCall("at::avg_pool2d_forward_out", output, self, kernel_size, stride, padding, ceil_mode, count_include_pad).to(Tensor)
template avg_pool2d_forward*(self: Tensor, kernel_size: IntList, stride: IntList, padding: IntList, ceil_mode: bool, count_include_pad: bool): Tensor = dynamicCCall("at::avg_pool2d_forward", self, kernel_size, stride, padding, ceil_mode, count_include_pad).to(Tensor)
template avg_pool2d_backward_out*(grad_input: Tensor, grad_output: Tensor, self: Tensor, kernel_size: IntList, stride: IntList, padding: IntList, ceil_mode: bool, count_include_pad: bool): Tensor = dynamicCCall("at::avg_pool2d_backward_out", grad_input, grad_output, self, kernel_size, stride, padding, ceil_mode, count_include_pad).to(Tensor)
template avg_pool2d_backward*(grad_output: Tensor, self: Tensor, kernel_size: IntList, stride: IntList, padding: IntList, ceil_mode: bool, count_include_pad: bool): Tensor = dynamicCCall("at::avg_pool2d_backward", grad_output, self, kernel_size, stride, padding, ceil_mode, count_include_pad).to(Tensor)
template avg_pool3d_out*(output: Tensor, self: Tensor, kernel_size: IntList, stride: IntList, padding: IntList, ceil_mode: bool = false, count_include_pad: bool = true): Tensor = dynamicCCall("at::avg_pool3d_out", output, self, kernel_size, stride, padding, ceil_mode, count_include_pad).to(Tensor)
template avg_pool3d*(self: Tensor, kernel_size: IntList, stride: IntList, padding: IntList, ceil_mode: bool = false, count_include_pad: bool = true): Tensor = dynamicCCall("at::avg_pool3d", self, kernel_size, stride, padding, ceil_mode, count_include_pad).to(Tensor)
template avg_pool3d_forward_out*(output: Tensor, self: Tensor, kernel_size: IntList, stride: IntList, padding: IntList, ceil_mode: bool, count_include_pad: bool): Tensor = dynamicCCall("at::avg_pool3d_forward_out", output, self, kernel_size, stride, padding, ceil_mode, count_include_pad).to(Tensor)
template avg_pool3d_forward*(self: Tensor, kernel_size: IntList, stride: IntList, padding: IntList, ceil_mode: bool, count_include_pad: bool): Tensor = dynamicCCall("at::avg_pool3d_forward", self, kernel_size, stride, padding, ceil_mode, count_include_pad).to(Tensor)
template avg_pool3d_backward_out*(grad_input: Tensor, grad_output: Tensor, self: Tensor, kernel_size: IntList, stride: IntList, padding: IntList, ceil_mode: bool, count_include_pad: bool): Tensor = dynamicCCall("at::avg_pool3d_backward_out", grad_input, grad_output, self, kernel_size, stride, padding, ceil_mode, count_include_pad).to(Tensor)
template avg_pool3d_backward*(grad_output: Tensor, self: Tensor, kernel_size: IntList, stride: IntList, padding: IntList, ceil_mode: bool, count_include_pad: bool): Tensor = dynamicCCall("at::avg_pool3d_backward", grad_output, self, kernel_size, stride, padding, ceil_mode, count_include_pad).to(Tensor)
template fractional_max_pool2d_out*(output: Tensor, indices: Tensor, self: Tensor, kernel_size: IntList, output_size: IntList, random_samples: Tensor): (Tensor, Tensor) = dynamicCCall("at::fractional_max_pool2d_out", output, indices, self, kernel_size, output_size, random_samples).to(ATensorRTuple2).toNimTensorTuple()
template fractional_max_pool2d*(self: Tensor, kernel_size: IntList, output_size: IntList, random_samples: Tensor): (Tensor, Tensor) = dynamicCCall("at::fractional_max_pool2d", self, kernel_size, output_size, random_samples).to(ATensorTuple2).toNimTensorTuple()
template fractional_max_pool2d_forward_out*(output: Tensor, indices: Tensor, self: Tensor, kernel_size: IntList, output_size: IntList, random_samples: Tensor): (Tensor, Tensor) = dynamicCCall("at::fractional_max_pool2d_forward_out", output, indices, self, kernel_size, output_size, random_samples).to(ATensorRTuple2).toNimTensorTuple()
template fractional_max_pool2d_forward*(self: Tensor, kernel_size: IntList, output_size: IntList, random_samples: Tensor): (Tensor, Tensor) = dynamicCCall("at::fractional_max_pool2d_forward", self, kernel_size, output_size, random_samples).to(ATensorTuple2).toNimTensorTuple()
template fractional_max_pool2d_backward_out*(grad_input: Tensor, grad_output: Tensor, self: Tensor, kernel_size: IntList, output_size: IntList, indices: Tensor): Tensor = dynamicCCall("at::fractional_max_pool2d_backward_out", grad_input, grad_output, self, kernel_size, output_size, indices).to(Tensor)
template fractional_max_pool2d_backward*(grad_output: Tensor, self: Tensor, kernel_size: IntList, output_size: IntList, indices: Tensor): Tensor = dynamicCCall("at::fractional_max_pool2d_backward", grad_output, self, kernel_size, output_size, indices).to(Tensor)
template max_pool2d_with_indices_out*(output: Tensor, indices: Tensor, self: Tensor, kernel_size: IntList, stride: IntList, padding: IntList, dilation: IntList, ceil_mode: bool = false): (Tensor, Tensor) = dynamicCCall("at::max_pool2d_with_indices_out", output, indices, self, kernel_size, stride, padding, dilation, ceil_mode).to(ATensorRTuple2).toNimTensorTuple()
template max_pool2d_with_indices*(self: Tensor, kernel_size: IntList, stride: IntList, padding: IntList, dilation: IntList, ceil_mode: bool = false): (Tensor, Tensor) = dynamicCCall("at::max_pool2d_with_indices", self, kernel_size, stride, padding, dilation, ceil_mode).to(ATensorTuple2).toNimTensorTuple()
template max_pool2d_with_indices_forward_out*(output: Tensor, indices: Tensor, self: Tensor, kernel_size: IntList, stride: IntList, padding: IntList, dilation: IntList, ceil_mode: bool): (Tensor, Tensor) = dynamicCCall("at::max_pool2d_with_indices_forward_out", output, indices, self, kernel_size, stride, padding, dilation, ceil_mode).to(ATensorRTuple2).toNimTensorTuple()
template max_pool2d_with_indices_forward*(self: Tensor, kernel_size: IntList, stride: IntList, padding: IntList, dilation: IntList, ceil_mode: bool): (Tensor, Tensor) = dynamicCCall("at::max_pool2d_with_indices_forward", self, kernel_size, stride, padding, dilation, ceil_mode).to(ATensorTuple2).toNimTensorTuple()
template max_pool2d_with_indices_backward_out*(grad_input: Tensor, grad_output: Tensor, self: Tensor, kernel_size: IntList, stride: IntList, padding: IntList, dilation: IntList, ceil_mode: bool, indices: Tensor): Tensor = dynamicCCall("at::max_pool2d_with_indices_backward_out", grad_input, grad_output, self, kernel_size, stride, padding, dilation, ceil_mode, indices).to(Tensor)
template max_pool2d_with_indices_backward*(grad_output: Tensor, self: Tensor, kernel_size: IntList, stride: IntList, padding: IntList, dilation: IntList, ceil_mode: bool, indices: Tensor): Tensor = dynamicCCall("at::max_pool2d_with_indices_backward", grad_output, self, kernel_size, stride, padding, dilation, ceil_mode, indices).to(Tensor)
template max_pool3d_with_indices_out*(output: Tensor, indices: Tensor, self: Tensor, kernel_size: IntList, stride: IntList, padding: IntList, dilation: IntList, ceil_mode: bool = false): (Tensor, Tensor) = dynamicCCall("at::max_pool3d_with_indices_out", output, indices, self, kernel_size, stride, padding, dilation, ceil_mode).to(ATensorRTuple2).toNimTensorTuple()
template max_pool3d_with_indices*(self: Tensor, kernel_size: IntList, stride: IntList, padding: IntList, dilation: IntList, ceil_mode: bool = false): (Tensor, Tensor) = dynamicCCall("at::max_pool3d_with_indices", self, kernel_size, stride, padding, dilation, ceil_mode).to(ATensorTuple2).toNimTensorTuple()
template max_pool3d_with_indices_forward_out*(output: Tensor, indices: Tensor, self: Tensor, kernel_size: IntList, stride: IntList, padding: IntList, dilation: IntList, ceil_mode: bool): (Tensor, Tensor) = dynamicCCall("at::max_pool3d_with_indices_forward_out", output, indices, self, kernel_size, stride, padding, dilation, ceil_mode).to(ATensorRTuple2).toNimTensorTuple()
template max_pool3d_with_indices_forward*(self: Tensor, kernel_size: IntList, stride: IntList, padding: IntList, dilation: IntList, ceil_mode: bool): (Tensor, Tensor) = dynamicCCall("at::max_pool3d_with_indices_forward", self, kernel_size, stride, padding, dilation, ceil_mode).to(ATensorTuple2).toNimTensorTuple()
template max_pool3d_with_indices_backward_out*(grad_input: Tensor, grad_output: Tensor, self: Tensor, kernel_size: IntList, stride: IntList, padding: IntList, dilation: IntList, ceil_mode: bool, indices: Tensor): Tensor = dynamicCCall("at::max_pool3d_with_indices_backward_out", grad_input, grad_output, self, kernel_size, stride, padding, dilation, ceil_mode, indices).to(Tensor)
template max_pool3d_with_indices_backward*(grad_output: Tensor, self: Tensor, kernel_size: IntList, stride: IntList, padding: IntList, dilation: IntList, ceil_mode: bool, indices: Tensor): Tensor = dynamicCCall("at::max_pool3d_with_indices_backward", grad_output, self, kernel_size, stride, padding, dilation, ceil_mode, indices).to(Tensor)
template max_unpool2d_out*(output: Tensor, self: Tensor, indices: Tensor, output_size: IntList): Tensor = dynamicCCall("at::max_unpool2d_out", output, self, indices, output_size).to(Tensor)
template max_unpool2d*(self: Tensor, indices: Tensor, output_size: IntList): Tensor = dynamicCCall("at::max_unpool2d", self, indices, output_size).to(Tensor)
template max_unpool2d_forward_out*(output: Tensor, self: Tensor, indices: Tensor, output_size: IntList): Tensor = dynamicCCall("at::max_unpool2d_forward_out", output, self, indices, output_size).to(Tensor)
template max_unpool2d_forward*(self: Tensor, indices: Tensor, output_size: IntList): Tensor = dynamicCCall("at::max_unpool2d_forward", self, indices, output_size).to(Tensor)
template max_unpool2d_backward_out*(grad_input: Tensor, grad_output: Tensor, self: Tensor, indices: Tensor, output_size: IntList): Tensor = dynamicCCall("at::max_unpool2d_backward_out", grad_input, grad_output, self, indices, output_size).to(Tensor)
template max_unpool2d_backward*(grad_output: Tensor, self: Tensor, indices: Tensor, output_size: IntList): Tensor = dynamicCCall("at::max_unpool2d_backward", grad_output, self, indices, output_size).to(Tensor)
template max_unpool3d_out*(output: Tensor, self: Tensor, indices: Tensor, output_size: IntList, stride: IntList, padding: IntList): Tensor = dynamicCCall("at::max_unpool3d_out", output, self, indices, output_size, stride, padding).to(Tensor)
template max_unpool3d*(self: Tensor, indices: Tensor, output_size: IntList, stride: IntList, padding: IntList): Tensor = dynamicCCall("at::max_unpool3d", self, indices, output_size, stride, padding).to(Tensor)
template max_unpool3d_forward_out*(output: Tensor, self: Tensor, indices: Tensor, output_size: IntList, stride: IntList, padding: IntList): Tensor = dynamicCCall("at::max_unpool3d_forward_out", output, self, indices, output_size, stride, padding).to(Tensor)
template max_unpool3d_forward*(self: Tensor, indices: Tensor, output_size: IntList, stride: IntList, padding: IntList): Tensor = dynamicCCall("at::max_unpool3d_forward", self, indices, output_size, stride, padding).to(Tensor)
template max_unpool3d_backward_out*(grad_input: Tensor, grad_output: Tensor, self: Tensor, indices: Tensor, output_size: IntList, stride: IntList, padding: IntList): Tensor = dynamicCCall("at::max_unpool3d_backward_out", grad_input, grad_output, self, indices, output_size, stride, padding).to(Tensor)
template max_unpool3d_backward*(grad_output: Tensor, self: Tensor, indices: Tensor, output_size: IntList, stride: IntList, padding: IntList): Tensor = dynamicCCall("at::max_unpool3d_backward", grad_output, self, indices, output_size, stride, padding).to(Tensor)
template reflection_pad1d_out*(output: Tensor, self: Tensor, padding: IntList): Tensor = dynamicCCall("at::reflection_pad1d_out", output, self, padding).to(Tensor)
template reflection_pad1d*(self: Tensor, padding: IntList): Tensor = dynamicCCall("at::reflection_pad1d", self, padding).to(Tensor)
template reflection_pad1d_forward_out*(output: Tensor, self: Tensor, padding: IntList): Tensor = dynamicCCall("at::reflection_pad1d_forward_out", output, self, padding).to(Tensor)
template reflection_pad1d_forward*(self: Tensor, padding: IntList): Tensor = dynamicCCall("at::reflection_pad1d_forward", self, padding).to(Tensor)
template reflection_pad1d_backward_out*(grad_input: Tensor, grad_output: Tensor, self: Tensor, padding: IntList): Tensor = dynamicCCall("at::reflection_pad1d_backward_out", grad_input, grad_output, self, padding).to(Tensor)
template reflection_pad1d_backward*(grad_output: Tensor, self: Tensor, padding: IntList): Tensor = dynamicCCall("at::reflection_pad1d_backward", grad_output, self, padding).to(Tensor)
template reflection_pad2d_out*(output: Tensor, self: Tensor, padding: IntList): Tensor = dynamicCCall("at::reflection_pad2d_out", output, self, padding).to(Tensor)
template reflection_pad2d*(self: Tensor, padding: IntList): Tensor = dynamicCCall("at::reflection_pad2d", self, padding).to(Tensor)
template reflection_pad2d_forward_out*(output: Tensor, self: Tensor, padding: IntList): Tensor = dynamicCCall("at::reflection_pad2d_forward_out", output, self, padding).to(Tensor)
template reflection_pad2d_forward*(self: Tensor, padding: IntList): Tensor = dynamicCCall("at::reflection_pad2d_forward", self, padding).to(Tensor)
template reflection_pad2d_backward_out*(grad_input: Tensor, grad_output: Tensor, self: Tensor, padding: IntList): Tensor = dynamicCCall("at::reflection_pad2d_backward_out", grad_input, grad_output, self, padding).to(Tensor)
template reflection_pad2d_backward*(grad_output: Tensor, self: Tensor, padding: IntList): Tensor = dynamicCCall("at::reflection_pad2d_backward", grad_output, self, padding).to(Tensor)
template replication_pad1d_out*(output: Tensor, self: Tensor, padding: IntList): Tensor = dynamicCCall("at::replication_pad1d_out", output, self, padding).to(Tensor)
template replication_pad1d*(self: Tensor, padding: IntList): Tensor = dynamicCCall("at::replication_pad1d", self, padding).to(Tensor)
template replication_pad1d_forward_out*(output: Tensor, self: Tensor, padding: IntList): Tensor = dynamicCCall("at::replication_pad1d_forward_out", output, self, padding).to(Tensor)
template replication_pad1d_forward*(self: Tensor, padding: IntList): Tensor = dynamicCCall("at::replication_pad1d_forward", self, padding).to(Tensor)
template replication_pad1d_backward_out*(grad_input: Tensor, grad_output: Tensor, self: Tensor, padding: IntList): Tensor = dynamicCCall("at::replication_pad1d_backward_out", grad_input, grad_output, self, padding).to(Tensor)
template replication_pad1d_backward*(grad_output: Tensor, self: Tensor, padding: IntList): Tensor = dynamicCCall("at::replication_pad1d_backward", grad_output, self, padding).to(Tensor)
template replication_pad2d_out*(output: Tensor, self: Tensor, padding: IntList): Tensor = dynamicCCall("at::replication_pad2d_out", output, self, padding).to(Tensor)
template replication_pad2d*(self: Tensor, padding: IntList): Tensor = dynamicCCall("at::replication_pad2d", self, padding).to(Tensor)
template replication_pad2d_forward_out*(output: Tensor, self: Tensor, padding: IntList): Tensor = dynamicCCall("at::replication_pad2d_forward_out", output, self, padding).to(Tensor)
template replication_pad2d_forward*(self: Tensor, padding: IntList): Tensor = dynamicCCall("at::replication_pad2d_forward", self, padding).to(Tensor)
template replication_pad2d_backward_out*(grad_input: Tensor, grad_output: Tensor, self: Tensor, padding: IntList): Tensor = dynamicCCall("at::replication_pad2d_backward_out", grad_input, grad_output, self, padding).to(Tensor)
template replication_pad2d_backward*(grad_output: Tensor, self: Tensor, padding: IntList): Tensor = dynamicCCall("at::replication_pad2d_backward", grad_output, self, padding).to(Tensor)
template replication_pad3d_out*(output: Tensor, self: Tensor, padding: IntList): Tensor = dynamicCCall("at::replication_pad3d_out", output, self, padding).to(Tensor)
template replication_pad3d*(self: Tensor, padding: IntList): Tensor = dynamicCCall("at::replication_pad3d", self, padding).to(Tensor)
template replication_pad3d_forward_out*(output: Tensor, self: Tensor, padding: IntList): Tensor = dynamicCCall("at::replication_pad3d_forward_out", output, self, padding).to(Tensor)
template replication_pad3d_forward*(self: Tensor, padding: IntList): Tensor = dynamicCCall("at::replication_pad3d_forward", self, padding).to(Tensor)
template replication_pad3d_backward_out*(grad_input: Tensor, grad_output: Tensor, self: Tensor, padding: IntList): Tensor = dynamicCCall("at::replication_pad3d_backward_out", grad_input, grad_output, self, padding).to(Tensor)
template replication_pad3d_backward*(grad_output: Tensor, self: Tensor, padding: IntList): Tensor = dynamicCCall("at::replication_pad3d_backward", grad_output, self, padding).to(Tensor)
template upsample_linear1d_out*(output: Tensor, self: Tensor, output_size: IntList, align_corners: bool): Tensor = dynamicCCall("at::upsample_linear1d_out", output, self, output_size, align_corners).to(Tensor)
template upsample_linear1d*(self: Tensor, output_size: IntList, align_corners: bool): Tensor = dynamicCCall("at::upsample_linear1d", self, output_size, align_corners).to(Tensor)
template upsample_linear1d_forward_out*(output: Tensor, self: Tensor, output_size: IntList, align_corners: bool): Tensor = dynamicCCall("at::upsample_linear1d_forward_out", output, self, output_size, align_corners).to(Tensor)
template upsample_linear1d_forward*(self: Tensor, output_size: IntList, align_corners: bool): Tensor = dynamicCCall("at::upsample_linear1d_forward", self, output_size, align_corners).to(Tensor)
template upsample_linear1d_backward_out*(grad_input: Tensor, grad_output: Tensor, output_size: IntList, input_size: IntList, align_corners: bool): Tensor = dynamicCCall("at::upsample_linear1d_backward_out", grad_input, grad_output, output_size, input_size, align_corners).to(Tensor)
template upsample_linear1d_backward*(grad_output: Tensor, output_size: IntList, input_size: IntList, align_corners: bool): Tensor = dynamicCCall("at::upsample_linear1d_backward", grad_output, output_size, input_size, align_corners).to(Tensor)
template upsample_bilinear2d_out*(output: Tensor, self: Tensor, output_size: IntList, align_corners: bool): Tensor = dynamicCCall("at::upsample_bilinear2d_out", output, self, output_size, align_corners).to(Tensor)
template upsample_bilinear2d*(self: Tensor, output_size: IntList, align_corners: bool): Tensor = dynamicCCall("at::upsample_bilinear2d", self, output_size, align_corners).to(Tensor)
template upsample_bilinear2d_forward_out*(output: Tensor, self: Tensor, output_size: IntList, align_corners: bool): Tensor = dynamicCCall("at::upsample_bilinear2d_forward_out", output, self, output_size, align_corners).to(Tensor)
template upsample_bilinear2d_forward*(self: Tensor, output_size: IntList, align_corners: bool): Tensor = dynamicCCall("at::upsample_bilinear2d_forward", self, output_size, align_corners).to(Tensor)
template upsample_bilinear2d_backward_out*(grad_input: Tensor, grad_output: Tensor, output_size: IntList, input_size: IntList, align_corners: bool): Tensor = dynamicCCall("at::upsample_bilinear2d_backward_out", grad_input, grad_output, output_size, input_size, align_corners).to(Tensor)
template upsample_bilinear2d_backward*(grad_output: Tensor, output_size: IntList, input_size: IntList, align_corners: bool): Tensor = dynamicCCall("at::upsample_bilinear2d_backward", grad_output, output_size, input_size, align_corners).to(Tensor)
template upsample_trilinear3d_out*(output: Tensor, self: Tensor, output_size: IntList, align_corners: bool): Tensor = dynamicCCall("at::upsample_trilinear3d_out", output, self, output_size, align_corners).to(Tensor)
template upsample_trilinear3d*(self: Tensor, output_size: IntList, align_corners: bool): Tensor = dynamicCCall("at::upsample_trilinear3d", self, output_size, align_corners).to(Tensor)
template upsample_trilinear3d_forward_out*(output: Tensor, self: Tensor, output_size: IntList, align_corners: bool): Tensor = dynamicCCall("at::upsample_trilinear3d_forward_out", output, self, output_size, align_corners).to(Tensor)
template upsample_trilinear3d_forward*(self: Tensor, output_size: IntList, align_corners: bool): Tensor = dynamicCCall("at::upsample_trilinear3d_forward", self, output_size, align_corners).to(Tensor)
template upsample_trilinear3d_backward_out*(grad_input: Tensor, grad_output: Tensor, output_size: IntList, input_size: IntList, align_corners: bool): Tensor = dynamicCCall("at::upsample_trilinear3d_backward_out", grad_input, grad_output, output_size, input_size, align_corners).to(Tensor)
template upsample_trilinear3d_backward*(grad_output: Tensor, output_size: IntList, input_size: IntList, align_corners: bool): Tensor = dynamicCCall("at::upsample_trilinear3d_backward", grad_output, output_size, input_size, align_corners).to(Tensor)
template upsample_nearest1d_out*(output: Tensor, self: Tensor, output_size: IntList): Tensor = dynamicCCall("at::upsample_nearest1d_out", output, self, output_size).to(Tensor)
template upsample_nearest1d*(self: Tensor, output_size: IntList): Tensor = dynamicCCall("at::upsample_nearest1d", self, output_size).to(Tensor)
template upsample_nearest1d_forward_out*(output: Tensor, self: Tensor, output_size: IntList): Tensor = dynamicCCall("at::upsample_nearest1d_forward_out", output, self, output_size).to(Tensor)
template upsample_nearest1d_forward*(self: Tensor, output_size: IntList): Tensor = dynamicCCall("at::upsample_nearest1d_forward", self, output_size).to(Tensor)
template upsample_nearest1d_backward_out*(grad_input: Tensor, grad_output: Tensor, output_size: IntList, input_size: IntList): Tensor = dynamicCCall("at::upsample_nearest1d_backward_out", grad_input, grad_output, output_size, input_size).to(Tensor)
template upsample_nearest1d_backward*(grad_output: Tensor, output_size: IntList, input_size: IntList): Tensor = dynamicCCall("at::upsample_nearest1d_backward", grad_output, output_size, input_size).to(Tensor)
template upsample_nearest2d_out*(output: Tensor, self: Tensor, output_size: IntList): Tensor = dynamicCCall("at::upsample_nearest2d_out", output, self, output_size).to(Tensor)
template upsample_nearest2d*(self: Tensor, output_size: IntList): Tensor = dynamicCCall("at::upsample_nearest2d", self, output_size).to(Tensor)
template upsample_nearest2d_forward_out*(output: Tensor, self: Tensor, output_size: IntList): Tensor = dynamicCCall("at::upsample_nearest2d_forward_out", output, self, output_size).to(Tensor)
template upsample_nearest2d_forward*(self: Tensor, output_size: IntList): Tensor = dynamicCCall("at::upsample_nearest2d_forward", self, output_size).to(Tensor)
template upsample_nearest2d_backward_out*(grad_input: Tensor, grad_output: Tensor, output_size: IntList, input_size: IntList): Tensor = dynamicCCall("at::upsample_nearest2d_backward_out", grad_input, grad_output, output_size, input_size).to(Tensor)
template upsample_nearest2d_backward*(grad_output: Tensor, output_size: IntList, input_size: IntList): Tensor = dynamicCCall("at::upsample_nearest2d_backward", grad_output, output_size, input_size).to(Tensor)
template upsample_nearest3d_out*(output: Tensor, self: Tensor, output_size: IntList): Tensor = dynamicCCall("at::upsample_nearest3d_out", output, self, output_size).to(Tensor)
template upsample_nearest3d*(self: Tensor, output_size: IntList): Tensor = dynamicCCall("at::upsample_nearest3d", self, output_size).to(Tensor)
template upsample_nearest3d_forward_out*(output: Tensor, self: Tensor, output_size: IntList): Tensor = dynamicCCall("at::upsample_nearest3d_forward_out", output, self, output_size).to(Tensor)
template upsample_nearest3d_forward*(self: Tensor, output_size: IntList): Tensor = dynamicCCall("at::upsample_nearest3d_forward", self, output_size).to(Tensor)
template upsample_nearest3d_backward_out*(grad_input: Tensor, grad_output: Tensor, output_size: IntList, input_size: IntList): Tensor = dynamicCCall("at::upsample_nearest3d_backward_out", grad_input, grad_output, output_size, input_size).to(Tensor)
template upsample_nearest3d_backward*(grad_output: Tensor, output_size: IntList, input_size: IntList): Tensor = dynamicCCall("at::upsample_nearest3d_backward", grad_output, output_size, input_size).to(Tensor)
template u_sigmoid_out*(output: Tensor, self: Tensor): Tensor = dynamicCCall("at::_sigmoid_out", output, self).to(Tensor)
template u_sigmoid*(self: Tensor): Tensor = dynamicCCall("at::_sigmoid", self).to(Tensor)
template u_sigmoid_forward_out*(output: Tensor, self: Tensor): Tensor = dynamicCCall("at::_sigmoid_forward_out", output, self).to(Tensor)
template u_sigmoid_forward*(self: Tensor): Tensor = dynamicCCall("at::_sigmoid_forward", self).to(Tensor)
template u_sigmoid_backward_out*(grad_input: Tensor, grad_output: Tensor, output: Tensor): Tensor = dynamicCCall("at::_sigmoid_backward_out", grad_input, grad_output, output).to(Tensor)
template u_sigmoid_backward*(grad_output: Tensor, output: Tensor): Tensor = dynamicCCall("at::_sigmoid_backward", grad_output, output).to(Tensor)
template u_tanh_out*(output: Tensor, self: Tensor): Tensor = dynamicCCall("at::_tanh_out", output, self).to(Tensor)
template u_tanh*(self: Tensor): Tensor = dynamicCCall("at::_tanh", self).to(Tensor)
template u_tanh_forward_out*(output: Tensor, self: Tensor): Tensor = dynamicCCall("at::_tanh_forward_out", output, self).to(Tensor)
template u_tanh_forward*(self: Tensor): Tensor = dynamicCCall("at::_tanh_forward", self).to(Tensor)
template u_tanh_backward_out*(grad_input: Tensor, grad_output: Tensor, output: Tensor): Tensor = dynamicCCall("at::_tanh_backward_out", grad_input, grad_output, output).to(Tensor)
template u_tanh_backward*(grad_output: Tensor, output: Tensor): Tensor = dynamicCCall("at::_tanh_backward", grad_output, output).to(Tensor)
template thnn_batch_norm_out*(output: Tensor, self: Tensor, weight: Tensor, bias: Tensor, running_mean: Tensor, running_var: Tensor, training: bool, momentum: float64, eps: float64): Tensor = dynamicCCall("at::thnn_batch_norm_out", output, self, weight, bias, running_mean, running_var, training, momentum, eps).to(Tensor)
template thnn_batch_norm*(self: Tensor, weight: Tensor, bias: Tensor, running_mean: Tensor, running_var: Tensor, training: bool, momentum: float64, eps: float64): Tensor = dynamicCCall("at::thnn_batch_norm", self, weight, bias, running_mean, running_var, training, momentum, eps).to(Tensor)
template thnn_batch_norm_forward_out*(output: Tensor, save_mean: Tensor, save_std: Tensor, self: Tensor, weight: Tensor, bias: Tensor, running_mean: Tensor, running_var: Tensor, training: bool, momentum: float64, eps: float64): (Tensor, Tensor, Tensor) = dynamicCCall("at::thnn_batch_norm_forward_out", output, save_mean, save_std, self, weight, bias, running_mean, running_var, training, momentum, eps).to(ATensorRTuple3).toNimTensorTuple()
template thnn_batch_norm_forward*(self: Tensor, weight: Tensor, bias: Tensor, running_mean: Tensor, running_var: Tensor, training: bool, momentum: float64, eps: float64): (Tensor, Tensor, Tensor) = dynamicCCall("at::thnn_batch_norm_forward", self, weight, bias, running_mean, running_var, training, momentum, eps).to(ATensorTuple3).toNimTensorTuple()
template thnn_batch_norm_backward_out*(grad_input: Tensor, grad_weight: Tensor, grad_bias: Tensor, grad_output: Tensor, self: Tensor, weight: Tensor, running_mean: Tensor, running_var: Tensor, training: bool, eps: float64, save_mean: Tensor, save_std: Tensor): (Tensor, Tensor, Tensor) = dynamicCCall("at::thnn_batch_norm_backward_out", grad_input, grad_weight, grad_bias, grad_output, self, weight, running_mean, running_var, training, eps, save_mean, save_std).to(ATensorRTuple3).toNimTensorTuple()
template thnn_batch_norm_backward*(grad_output: Tensor, self: Tensor, weight: Tensor, running_mean: Tensor, running_var: Tensor, training: bool, eps: float64, save_mean: Tensor, save_std: Tensor, output_mask: StdArray[bool, 3]): (Tensor, Tensor, Tensor) = dynamicCCall("at::thnn_batch_norm_backward", grad_output, self, weight, running_mean, running_var, training, eps, save_mean, save_std, output_mask).to(ATensorTuple3).toNimTensorTuple()
template thnn_conv_transpose2d_out*(output: Tensor, self: Tensor, weight: Tensor, kernel_size: IntList, bias: Tensor, stride: IntList, padding: IntList, output_padding: IntList, dilation: IntList): Tensor = dynamicCCall("at::thnn_conv_transpose2d_out", output, self, weight, kernel_size, bias, stride, padding, output_padding, dilation).to(Tensor)
template thnn_conv_transpose2d*(self: Tensor, weight: Tensor, kernel_size: IntList, bias: Tensor, stride: IntList, padding: IntList, output_padding: IntList, dilation: IntList): Tensor = dynamicCCall("at::thnn_conv_transpose2d", self, weight, kernel_size, bias, stride, padding, output_padding, dilation).to(Tensor)
template thnn_conv_transpose2d_forward_out*(output: Tensor, columns: Tensor, ones: Tensor, self: Tensor, weight: Tensor, kernel_size: IntList, bias: Tensor, stride: IntList, padding: IntList, output_padding: IntList, dilation: IntList): (Tensor, Tensor, Tensor) = dynamicCCall("at::thnn_conv_transpose2d_forward_out", output, columns, ones, self, weight, kernel_size, bias, stride, padding, output_padding, dilation).to(ATensorRTuple3).toNimTensorTuple()
template thnn_conv_transpose2d_forward*(self: Tensor, weight: Tensor, kernel_size: IntList, bias: Tensor, stride: IntList, padding: IntList, output_padding: IntList, dilation: IntList): (Tensor, Tensor, Tensor) = dynamicCCall("at::thnn_conv_transpose2d_forward", self, weight, kernel_size, bias, stride, padding, output_padding, dilation).to(ATensorTuple3).toNimTensorTuple()
template thnn_conv_transpose2d_backward_out*(grad_input: Tensor, grad_weight: Tensor, grad_bias: Tensor, grad_output: Tensor, self: Tensor, weight: Tensor, kernel_size: IntList, stride: IntList, padding: IntList, output_padding: IntList, dilation: IntList, columns: Tensor, ones: Tensor): (Tensor, Tensor, Tensor) = dynamicCCall("at::thnn_conv_transpose2d_backward_out", grad_input, grad_weight, grad_bias, grad_output, self, weight, kernel_size, stride, padding, output_padding, dilation, columns, ones).to(ATensorRTuple3).toNimTensorTuple()
template thnn_conv_transpose2d_backward*(grad_output: Tensor, self: Tensor, weight: Tensor, kernel_size: IntList, stride: IntList, padding: IntList, output_padding: IntList, dilation: IntList, columns: Tensor, ones: Tensor, output_mask: StdArray[bool, 3]): (Tensor, Tensor, Tensor) = dynamicCCall("at::thnn_conv_transpose2d_backward", grad_output, self, weight, kernel_size, stride, padding, output_padding, dilation, columns, ones, output_mask).to(ATensorTuple3).toNimTensorTuple()
template thnn_conv_transpose3d_out*(output: Tensor, self: Tensor, weight: Tensor, kernel_size: IntList, bias: Tensor, stride: IntList, padding: IntList, output_padding: IntList, dilation: IntList): Tensor = dynamicCCall("at::thnn_conv_transpose3d_out", output, self, weight, kernel_size, bias, stride, padding, output_padding, dilation).to(Tensor)
template thnn_conv_transpose3d*(self: Tensor, weight: Tensor, kernel_size: IntList, bias: Tensor, stride: IntList, padding: IntList, output_padding: IntList, dilation: IntList): Tensor = dynamicCCall("at::thnn_conv_transpose3d", self, weight, kernel_size, bias, stride, padding, output_padding, dilation).to(Tensor)
template thnn_conv_transpose3d_forward_out*(output: Tensor, finput: Tensor, fgrad_input: Tensor, self: Tensor, weight: Tensor, kernel_size: IntList, bias: Tensor, stride: IntList, padding: IntList, output_padding: IntList, dilation: IntList): (Tensor, Tensor, Tensor) = dynamicCCall("at::thnn_conv_transpose3d_forward_out", output, finput, fgrad_input, self, weight, kernel_size, bias, stride, padding, output_padding, dilation).to(ATensorRTuple3).toNimTensorTuple()
template thnn_conv_transpose3d_forward*(self: Tensor, weight: Tensor, kernel_size: IntList, bias: Tensor, stride: IntList, padding: IntList, output_padding: IntList, dilation: IntList): (Tensor, Tensor, Tensor) = dynamicCCall("at::thnn_conv_transpose3d_forward", self, weight, kernel_size, bias, stride, padding, output_padding, dilation).to(ATensorTuple3).toNimTensorTuple()
template thnn_conv_transpose3d_backward_out*(grad_input: Tensor, grad_weight: Tensor, grad_bias: Tensor, grad_output: Tensor, self: Tensor, weight: Tensor, kernel_size: IntList, stride: IntList, padding: IntList, output_padding: IntList, dilation: IntList, finput: Tensor, fgrad_input: Tensor): (Tensor, Tensor, Tensor) = dynamicCCall("at::thnn_conv_transpose3d_backward_out", grad_input, grad_weight, grad_bias, grad_output, self, weight, kernel_size, stride, padding, output_padding, dilation, finput, fgrad_input).to(ATensorRTuple3).toNimTensorTuple()
template thnn_conv_transpose3d_backward*(grad_output: Tensor, self: Tensor, weight: Tensor, kernel_size: IntList, stride: IntList, padding: IntList, output_padding: IntList, dilation: IntList, finput: Tensor, fgrad_input: Tensor, output_mask: StdArray[bool, 3]): (Tensor, Tensor, Tensor) = dynamicCCall("at::thnn_conv_transpose3d_backward", grad_output, self, weight, kernel_size, stride, padding, output_padding, dilation, finput, fgrad_input, output_mask).to(ATensorTuple3).toNimTensorTuple()
template thnn_conv2d_out*(output: Tensor, self: Tensor, weight: Tensor, kernel_size: IntList, bias: Tensor, stride: IntList, padding: IntList): Tensor = dynamicCCall("at::thnn_conv2d_out", output, self, weight, kernel_size, bias, stride, padding).to(Tensor)
template thnn_conv2d*(self: Tensor, weight: Tensor, kernel_size: IntList, bias: Tensor, stride: IntList, padding: IntList): Tensor = dynamicCCall("at::thnn_conv2d", self, weight, kernel_size, bias, stride, padding).to(Tensor)
template thnn_conv2d_forward_out*(output: Tensor, finput: Tensor, fgrad_input: Tensor, self: Tensor, weight: Tensor, kernel_size: IntList, bias: Tensor, stride: IntList, padding: IntList): (Tensor, Tensor, Tensor) = dynamicCCall("at::thnn_conv2d_forward_out", output, finput, fgrad_input, self, weight, kernel_size, bias, stride, padding).to(ATensorRTuple3).toNimTensorTuple()
template thnn_conv2d_forward*(self: Tensor, weight: Tensor, kernel_size: IntList, bias: Tensor, stride: IntList, padding: IntList): (Tensor, Tensor, Tensor) = dynamicCCall("at::thnn_conv2d_forward", self, weight, kernel_size, bias, stride, padding).to(ATensorTuple3).toNimTensorTuple()
template thnn_conv2d_backward_out*(grad_input: Tensor, grad_weight: Tensor, grad_bias: Tensor, grad_output: Tensor, self: Tensor, weight: Tensor, kernel_size: IntList, stride: IntList, padding: IntList, finput: Tensor, fgrad_input: Tensor): (Tensor, Tensor, Tensor) = dynamicCCall("at::thnn_conv2d_backward_out", grad_input, grad_weight, grad_bias, grad_output, self, weight, kernel_size, stride, padding, finput, fgrad_input).to(ATensorRTuple3).toNimTensorTuple()
template thnn_conv2d_backward*(grad_output: Tensor, self: Tensor, weight: Tensor, kernel_size: IntList, stride: IntList, padding: IntList, finput: Tensor, fgrad_input: Tensor, output_mask: StdArray[bool, 3]): (Tensor, Tensor, Tensor) = dynamicCCall("at::thnn_conv2d_backward", grad_output, self, weight, kernel_size, stride, padding, finput, fgrad_input, output_mask).to(ATensorTuple3).toNimTensorTuple()
template thnn_conv_depthwise2d_out*(output: Tensor, self: Tensor, weight: Tensor, kernel_size: IntList, bias: Tensor, stride: IntList, padding: IntList, dilation: IntList): Tensor = dynamicCCall("at::thnn_conv_depthwise2d_out", output, self, weight, kernel_size, bias, stride, padding, dilation).to(Tensor)
template thnn_conv_depthwise2d*(self: Tensor, weight: Tensor, kernel_size: IntList, bias: Tensor, stride: IntList, padding: IntList, dilation: IntList): Tensor = dynamicCCall("at::thnn_conv_depthwise2d", self, weight, kernel_size, bias, stride, padding, dilation).to(Tensor)
template thnn_conv_depthwise2d_forward_out*(output: Tensor, self: Tensor, weight: Tensor, kernel_size: IntList, bias: Tensor, stride: IntList, padding: IntList, dilation: IntList): Tensor = dynamicCCall("at::thnn_conv_depthwise2d_forward_out", output, self, weight, kernel_size, bias, stride, padding, dilation).to(Tensor)
template thnn_conv_depthwise2d_forward*(self: Tensor, weight: Tensor, kernel_size: IntList, bias: Tensor, stride: IntList, padding: IntList, dilation: IntList): Tensor = dynamicCCall("at::thnn_conv_depthwise2d_forward", self, weight, kernel_size, bias, stride, padding, dilation).to(Tensor)
template thnn_conv_depthwise2d_backward_out*(grad_input: Tensor, grad_weight: Tensor, grad_output: Tensor, self: Tensor, weight: Tensor, kernel_size: IntList, stride: IntList, padding: IntList, dilation: IntList): (Tensor, Tensor) = dynamicCCall("at::thnn_conv_depthwise2d_backward_out", grad_input, grad_weight, grad_output, self, weight, kernel_size, stride, padding, dilation).to(ATensorRTuple2).toNimTensorTuple()
template thnn_conv_depthwise2d_backward*(grad_output: Tensor, self: Tensor, weight: Tensor, kernel_size: IntList, stride: IntList, padding: IntList, dilation: IntList, output_mask: StdArray[bool, 2]): (Tensor, Tensor) = dynamicCCall("at::thnn_conv_depthwise2d_backward", grad_output, self, weight, kernel_size, stride, padding, dilation, output_mask).to(ATensorTuple2).toNimTensorTuple()
template thnn_conv3d_out*(output: Tensor, self: Tensor, weight: Tensor, kernel_size: IntList, bias: Tensor, stride: IntList, padding: IntList): Tensor = dynamicCCall("at::thnn_conv3d_out", output, self, weight, kernel_size, bias, stride, padding).to(Tensor)
template thnn_conv3d*(self: Tensor, weight: Tensor, kernel_size: IntList, bias: Tensor, stride: IntList, padding: IntList): Tensor = dynamicCCall("at::thnn_conv3d", self, weight, kernel_size, bias, stride, padding).to(Tensor)
template thnn_conv3d_forward_out*(output: Tensor, finput: Tensor, fgrad_input: Tensor, self: Tensor, weight: Tensor, kernel_size: IntList, bias: Tensor, stride: IntList, padding: IntList): (Tensor, Tensor, Tensor) = dynamicCCall("at::thnn_conv3d_forward_out", output, finput, fgrad_input, self, weight, kernel_size, bias, stride, padding).to(ATensorRTuple3).toNimTensorTuple()
template thnn_conv3d_forward*(self: Tensor, weight: Tensor, kernel_size: IntList, bias: Tensor, stride: IntList, padding: IntList): (Tensor, Tensor, Tensor) = dynamicCCall("at::thnn_conv3d_forward", self, weight, kernel_size, bias, stride, padding).to(ATensorTuple3).toNimTensorTuple()
template thnn_conv3d_backward_out*(grad_input: Tensor, grad_weight: Tensor, grad_bias: Tensor, grad_output: Tensor, self: Tensor, weight: Tensor, kernel_size: IntList, stride: IntList, padding: IntList, finput: Tensor, fgrad_input: Tensor): (Tensor, Tensor, Tensor) = dynamicCCall("at::thnn_conv3d_backward_out", grad_input, grad_weight, grad_bias, grad_output, self, weight, kernel_size, stride, padding, finput, fgrad_input).to(ATensorRTuple3).toNimTensorTuple()
template thnn_conv3d_backward*(grad_output: Tensor, self: Tensor, weight: Tensor, kernel_size: IntList, stride: IntList, padding: IntList, finput: Tensor, fgrad_input: Tensor, output_mask: StdArray[bool, 3]): (Tensor, Tensor, Tensor) = dynamicCCall("at::thnn_conv3d_backward", grad_output, self, weight, kernel_size, stride, padding, finput, fgrad_input, output_mask).to(ATensorTuple3).toNimTensorTuple()
template thnn_conv_dilated2d_out*(output: Tensor, self: Tensor, weight: Tensor, kernel_size: IntList, bias: Tensor, stride: IntList, padding: IntList, dilation: IntList): Tensor = dynamicCCall("at::thnn_conv_dilated2d_out", output, self, weight, kernel_size, bias, stride, padding, dilation).to(Tensor)
template thnn_conv_dilated2d*(self: Tensor, weight: Tensor, kernel_size: IntList, bias: Tensor, stride: IntList, padding: IntList, dilation: IntList): Tensor = dynamicCCall("at::thnn_conv_dilated2d", self, weight, kernel_size, bias, stride, padding, dilation).to(Tensor)
template thnn_conv_dilated2d_forward_out*(output: Tensor, columns: Tensor, ones: Tensor, self: Tensor, weight: Tensor, kernel_size: IntList, bias: Tensor, stride: IntList, padding: IntList, dilation: IntList): (Tensor, Tensor, Tensor) = dynamicCCall("at::thnn_conv_dilated2d_forward_out", output, columns, ones, self, weight, kernel_size, bias, stride, padding, dilation).to(ATensorRTuple3).toNimTensorTuple()
template thnn_conv_dilated2d_forward*(self: Tensor, weight: Tensor, kernel_size: IntList, bias: Tensor, stride: IntList, padding: IntList, dilation: IntList): (Tensor, Tensor, Tensor) = dynamicCCall("at::thnn_conv_dilated2d_forward", self, weight, kernel_size, bias, stride, padding, dilation).to(ATensorTuple3).toNimTensorTuple()
template thnn_conv_dilated2d_backward_out*(grad_input: Tensor, grad_weight: Tensor, grad_bias: Tensor, grad_output: Tensor, self: Tensor, weight: Tensor, kernel_size: IntList, stride: IntList, padding: IntList, dilation: IntList, columns: Tensor, ones: Tensor): (Tensor, Tensor, Tensor) = dynamicCCall("at::thnn_conv_dilated2d_backward_out", grad_input, grad_weight, grad_bias, grad_output, self, weight, kernel_size, stride, padding, dilation, columns, ones).to(ATensorRTuple3).toNimTensorTuple()
template thnn_conv_dilated2d_backward*(grad_output: Tensor, self: Tensor, weight: Tensor, kernel_size: IntList, stride: IntList, padding: IntList, dilation: IntList, columns: Tensor, ones: Tensor, output_mask: StdArray[bool, 3]): (Tensor, Tensor, Tensor) = dynamicCCall("at::thnn_conv_dilated2d_backward", grad_output, self, weight, kernel_size, stride, padding, dilation, columns, ones, output_mask).to(ATensorTuple3).toNimTensorTuple()
template thnn_conv_dilated3d_out*(output: Tensor, self: Tensor, weight: Tensor, kernel_size: IntList, bias: Tensor, stride: IntList, padding: IntList, dilation: IntList): Tensor = dynamicCCall("at::thnn_conv_dilated3d_out", output, self, weight, kernel_size, bias, stride, padding, dilation).to(Tensor)
template thnn_conv_dilated3d*(self: Tensor, weight: Tensor, kernel_size: IntList, bias: Tensor, stride: IntList, padding: IntList, dilation: IntList): Tensor = dynamicCCall("at::thnn_conv_dilated3d", self, weight, kernel_size, bias, stride, padding, dilation).to(Tensor)
template thnn_conv_dilated3d_forward_out*(output: Tensor, columns: Tensor, ones: Tensor, self: Tensor, weight: Tensor, kernel_size: IntList, bias: Tensor, stride: IntList, padding: IntList, dilation: IntList): (Tensor, Tensor, Tensor) = dynamicCCall("at::thnn_conv_dilated3d_forward_out", output, columns, ones, self, weight, kernel_size, bias, stride, padding, dilation).to(ATensorRTuple3).toNimTensorTuple()
template thnn_conv_dilated3d_forward*(self: Tensor, weight: Tensor, kernel_size: IntList, bias: Tensor, stride: IntList, padding: IntList, dilation: IntList): (Tensor, Tensor, Tensor) = dynamicCCall("at::thnn_conv_dilated3d_forward", self, weight, kernel_size, bias, stride, padding, dilation).to(ATensorTuple3).toNimTensorTuple()
template thnn_conv_dilated3d_backward_out*(grad_input: Tensor, grad_weight: Tensor, grad_bias: Tensor, grad_output: Tensor, self: Tensor, weight: Tensor, kernel_size: IntList, stride: IntList, padding: IntList, dilation: IntList, columns: Tensor, ones: Tensor): (Tensor, Tensor, Tensor) = dynamicCCall("at::thnn_conv_dilated3d_backward_out", grad_input, grad_weight, grad_bias, grad_output, self, weight, kernel_size, stride, padding, dilation, columns, ones).to(ATensorRTuple3).toNimTensorTuple()
template thnn_conv_dilated3d_backward*(grad_output: Tensor, self: Tensor, weight: Tensor, kernel_size: IntList, stride: IntList, padding: IntList, dilation: IntList, columns: Tensor, ones: Tensor, output_mask: StdArray[bool, 3]): (Tensor, Tensor, Tensor) = dynamicCCall("at::thnn_conv_dilated3d_backward", grad_output, self, weight, kernel_size, stride, padding, dilation, columns, ones, output_mask).to(ATensorTuple3).toNimTensorTuple()
template u_cast_Byte*(self: Tensor, non_blocking: bool = false): Tensor = self.dynamicCppCall("_cast_Byte", non_blocking).to(Tensor)
template u_cast_Char*(self: Tensor, non_blocking: bool = false): Tensor = self.dynamicCppCall("_cast_Char", non_blocking).to(Tensor)
template u_cast_Double*(self: Tensor, non_blocking: bool = false): Tensor = self.dynamicCppCall("_cast_Double", non_blocking).to(Tensor)
template u_cast_Float*(self: Tensor, non_blocking: bool = false): Tensor = self.dynamicCppCall("_cast_Float", non_blocking).to(Tensor)
template u_cast_Int*(self: Tensor, non_blocking: bool = false): Tensor = self.dynamicCppCall("_cast_Int", non_blocking).to(Tensor)
template u_cast_Long*(self: Tensor, non_blocking: bool = false): Tensor = self.dynamicCppCall("_cast_Long", non_blocking).to(Tensor)
template u_cast_Short*(self: Tensor, non_blocking: bool = false): Tensor = self.dynamicCppCall("_cast_Short", non_blocking).to(Tensor)
template u_cast_Half*(self: Tensor, non_blocking: bool = false): Tensor = self.dynamicCppCall("_cast_Half", non_blocking).to(Tensor)
template u_cudnn_ctc_loss*(log_probs: Tensor, targets: Tensor, input_lengths: IntList, target_lengths: IntList, blank: int64, deterministic: bool): (Tensor, Tensor) = dynamicCCall("at::_cudnn_ctc_loss", log_probs, targets, input_lengths, target_lengths, blank, deterministic).to(ATensorTuple2).toNimTensorTuple()
template u_cudnn_rnn_flatten_weight*(weight_arr: TensorList, weight_stride0: int64, input_size: int64, mode: int64, hidden_size: int64, num_layers: int64, batch_first: bool, bidirectional: bool): Tensor = dynamicCCall("at::_cudnn_rnn_flatten_weight", weight_arr, weight_stride0, input_size, mode, hidden_size, num_layers, batch_first, bidirectional).to(Tensor)
template u_cudnn_rnn*(input: Tensor, weight: TensorList, weight_stride0: int64, weight_buf: Tensor, hx: Tensor, cx: Tensor, mode: int64, hidden_size: int64, num_layers: int64, batch_first: bool, dropout: float64, train: bool, bidirectional: bool, batch_sizes: IntList, dropout_state: Tensor): (Tensor, Tensor, Tensor, Tensor, Tensor) = dynamicCCall("at::_cudnn_rnn", input, weight, weight_stride0, weight_buf, hx, cx, mode, hidden_size, num_layers, batch_first, dropout, train, bidirectional, batch_sizes, dropout_state).to(ATensorTuple5).toNimTensorTuple()
template u_cudnn_rnn_backward*(input: Tensor, weight: TensorList, weight_stride0: int64, weight_buf: Tensor, hx: Tensor, cx: Tensor, output: Tensor, grad_output: Tensor, grad_hy: Tensor, grad_cy: Tensor, mode: int64, hidden_size: int64, num_layers: int64, batch_first: bool, dropout: float64, train: bool, bidirectional: bool, batch_sizes: IntList, dropout_state: Tensor, reserve: Tensor, output_mask: StdArray[bool, 4]): (Tensor, Tensor, Tensor, TensorList) = dynamicCCall("at::_cudnn_rnn_backward", input, weight, weight_stride0, weight_buf, hx, cx, output, grad_output, grad_hy, grad_cy, mode, hidden_size, num_layers, batch_first, dropout, train, bidirectional, batch_sizes, dropout_state, reserve, output_mask).to(ATensorTuple3v1).toNimTensorTuple()
template u_cudnn_init_dropout_state*(self_ty: AType, dropout: float64, train: bool, dropout_seed: int64): Tensor = dynamicCCall("at::_cudnn_init_dropout_state", self_ty, dropout, train, dropout_seed).to(Tensor)
template abs*(self: Tensor): Tensor = self.dynamicCppCall("abs").to(Tensor)
template abs_u*(self: Tensor): Tensor = self.dynamicCppCall("abs_").to(Tensor)
template abs_out*(aresult: Tensor, self: Tensor): Tensor = dynamicCCall("at::abs_out", aresult, self).to(Tensor)
template acos*(self: Tensor): Tensor = self.dynamicCppCall("acos").to(Tensor)
template acos_u*(self: Tensor): Tensor = self.dynamicCppCall("acos_").to(Tensor)
template acos_out*(aresult: Tensor, self: Tensor): Tensor = dynamicCCall("at::acos_out", aresult, self).to(Tensor)
template avg_pool1d*(self: Tensor, kernel_size: IntList, stride: IntList, padding: IntList = @[0], ceil_mode: bool = false, count_include_pad: bool = true): Tensor = dynamicCCall("at::avg_pool1d", self, kernel_size, stride, padding, ceil_mode, count_include_pad).to(Tensor)
template adaptive_avg_pool1d*(self: Tensor, output_size: IntList): Tensor = dynamicCCall("at::adaptive_avg_pool1d", self, output_size).to(Tensor)
template adaptive_max_pool1d*(self: Tensor, output_size: IntList): (Tensor, Tensor) = dynamicCCall("at::adaptive_max_pool1d", self, output_size).to(ATensorTuple2).toNimTensorTuple()
template add*(self: Tensor, other: Tensor, alpha: float = 1): Tensor = self.dynamicCppCall("add", other, alpha).to(Tensor)
template add_u*(self: Tensor, other: Tensor, alpha: float = 1): Tensor = self.dynamicCppCall("add_", other, alpha).to(Tensor)
template add_out*(aresult: Tensor, self: Tensor, other: Tensor, alpha: float = 1): Tensor = dynamicCCall("at::add_out", aresult, self, other, alpha).to(Tensor)
template add*(self: Tensor, other: float, alpha: float = 1): Tensor = self.dynamicCppCall("add", other, alpha).to(Tensor)
template add_u*(self: Tensor, other: float, alpha: float = 1): Tensor = self.dynamicCppCall("add_", other, alpha).to(Tensor)
template addmv*(self: Tensor, mat: Tensor, vec: Tensor, beta: float = 1, alpha: float = 1): Tensor = self.dynamicCppCall("addmv", mat, vec, beta, alpha).to(Tensor)
template addmv_u*(self: Tensor, mat: Tensor, vec: Tensor, beta: float = 1, alpha: float = 1): Tensor = self.dynamicCppCall("addmv_", mat, vec, beta, alpha).to(Tensor)
template addmv_out*(aresult: Tensor, self: Tensor, mat: Tensor, vec: Tensor, beta: float = 1, alpha: float = 1): Tensor = dynamicCCall("at::addmv_out", aresult, self, mat, vec, beta, alpha).to(Tensor)
template addr*(self: Tensor, vec1: Tensor, vec2: Tensor, beta: float = 1, alpha: float = 1): Tensor = self.dynamicCppCall("addr", vec1, vec2, beta, alpha).to(Tensor)
template addr_u*(self: Tensor, vec1: Tensor, vec2: Tensor, beta: float = 1, alpha: float = 1): Tensor = self.dynamicCppCall("addr_", vec1, vec2, beta, alpha).to(Tensor)
template addr_out*(aresult: Tensor, self: Tensor, vec1: Tensor, vec2: Tensor, beta: float = 1, alpha: float = 1): Tensor = dynamicCCall("at::addr_out", aresult, self, vec1, vec2, beta, alpha).to(Tensor)
template all*(self: Tensor, dim: int64, keepdim: bool = false): Tensor = self.dynamicCppCall("all", dim, keepdim).to(Tensor)
template all_out*(aresult: Tensor, self: Tensor, dim: int64, keepdim: bool = false): Tensor = dynamicCCall("at::all_out", aresult, self, dim, keepdim).to(Tensor)
template allclose*(self: Tensor, other: Tensor, rtol: float64, atol: float64, equal_nan: bool = false): bool = self.dynamicCppCall("allclose", other, rtol, atol, equal_nan).to(bool)
template any*(self: Tensor, dim: int64, keepdim: bool = false): Tensor = self.dynamicCppCall("any", dim, keepdim).to(Tensor)
template any_out*(aresult: Tensor, self: Tensor, dim: int64, keepdim: bool = false): Tensor = dynamicCCall("at::any_out", aresult, self, dim, keepdim).to(Tensor)
template arange*(start: float, aend: float, options: ATensorOptions): Tensor = dynamicCCall("at::arange", start, aend, options).to(Tensor)
template arange*(start: float, aend: float, step: float, options: ATensorOptions): Tensor = dynamicCCall("at::arange", start, aend, step, options).to(Tensor)
template arange_out*(aresult: Tensor, start: float, aend: float): Tensor = dynamicCCall("at::arange_out", aresult, start, aend).to(Tensor)
template arange_out*(aresult: Tensor, start: float, aend: float, step: float): Tensor = dynamicCCall("at::arange_out", aresult, start, aend, step).to(Tensor)
template arange*(aend: float, options: ATensorOptions): Tensor = dynamicCCall("at::arange", aend, options).to(Tensor)
template arange_out*(aresult: Tensor, aend: float): Tensor = dynamicCCall("at::arange_out", aresult, aend).to(Tensor)
template arange*(dtype: AType, start: float, aend: float, step: float = 1): Tensor {.deprecated.} = dynamicCCall("at::arange", dtype, start, aend, step).to(Tensor)
template arange*(dtype: AType, aend: float): Tensor {.deprecated.} = dynamicCCall("at::arange", dtype, aend).to(Tensor)
template u_dim_arange*(like: Tensor, dim: int64): Tensor = dynamicCCall("at::_dim_arange", like, dim).to(Tensor)
template argmax*(self: Tensor, dim: int64, keepdim: bool = false): Tensor = self.dynamicCppCall("argmax", dim, keepdim).to(Tensor)
template argmax*(self: Tensor): Tensor = self.dynamicCppCall("argmax").to(Tensor)
template u_argmax*(self: Tensor, dim: int64, keepdim: bool = false): Tensor = self.dynamicCppCall("_argmax", dim, keepdim).to(Tensor)
template argmin*(self: Tensor, dim: int64, keepdim: bool = false): Tensor = self.dynamicCppCall("argmin", dim, keepdim).to(Tensor)
template argmin*(self: Tensor): Tensor = self.dynamicCppCall("argmin").to(Tensor)
template u_argmin*(self: Tensor, dim: int64, keepdim: bool = false): Tensor = self.dynamicCppCall("_argmin", dim, keepdim).to(Tensor)
template as_strided*(self: Tensor, size: IntList, stride: IntList): Tensor = self.dynamicCppCall("as_strided", size, stride).to(Tensor)
template as_strided_u*(self: Tensor, size: IntList, stride: IntList): Tensor = self.dynamicCppCall("as_strided_", size, stride).to(Tensor)
template as_strided*(self: Tensor, size: IntList, stride: IntList, storage_offset: int64): Tensor = self.dynamicCppCall("as_strided", size, stride, storage_offset).to(Tensor)
template as_strided_u*(self: Tensor, size: IntList, stride: IntList, storage_offset: int64): Tensor = self.dynamicCppCall("as_strided_", size, stride, storage_offset).to(Tensor)
template asin*(self: Tensor): Tensor = self.dynamicCppCall("asin").to(Tensor)
template asin_u*(self: Tensor): Tensor = self.dynamicCppCall("asin_").to(Tensor)
template asin_out*(aresult: Tensor, self: Tensor): Tensor = dynamicCCall("at::asin_out", aresult, self).to(Tensor)
template atan*(self: Tensor): Tensor = self.dynamicCppCall("atan").to(Tensor)
template atan_u*(self: Tensor): Tensor = self.dynamicCppCall("atan_").to(Tensor)
template atan_out*(aresult: Tensor, self: Tensor): Tensor = dynamicCCall("at::atan_out", aresult, self).to(Tensor)
template bartlett_window*(window_length: int64, options: ATensorOptions): Tensor = dynamicCCall("at::bartlett_window", window_length, options).to(Tensor)
template bartlett_window*(window_length: int64, periodic: bool, options: ATensorOptions): Tensor = dynamicCCall("at::bartlett_window", window_length, periodic, options).to(Tensor)
template batch_norm*(input: Tensor, weight: Tensor, bias: Tensor, running_mean: Tensor, running_var: Tensor, training: bool, momentum: float64, eps: float64, cudnn_enabled: bool): Tensor = dynamicCCall("at::batch_norm", input, weight, bias, running_mean, running_var, training, momentum, eps, cudnn_enabled).to(Tensor)
template bernoulli*(self: Tensor, p: Tensor, generator: pointer = nil): Tensor = self.dynamicCppCall("bernoulli", p, generator).to(Tensor)
template bernoulli*(self: Tensor, p: float64, generator: pointer = nil): Tensor = self.dynamicCppCall("bernoulli", p, generator).to(Tensor)
template bernoulli*(self: Tensor): Tensor = self.dynamicCppCall("bernoulli").to(Tensor)
template bernoulli_u*(self: Tensor, p: Tensor, generator: pointer = nil): Tensor = self.dynamicCppCall("bernoulli_", p, generator).to(Tensor)
template bernoulli_u*(self: Tensor, p: float64, generator: pointer = nil): Tensor = self.dynamicCppCall("bernoulli_", p, generator).to(Tensor)
template bernoulli_u*(self: Tensor): Tensor = self.dynamicCppCall("bernoulli_").to(Tensor)
template bilinear*(input1: Tensor, input2: Tensor, weight: Tensor, bias: Tensor): Tensor = dynamicCCall("at::bilinear", input1, input2, weight, bias).to(Tensor)
template bincount*(self: Tensor, weights: Tensor, minlength: int64 = 0): Tensor = self.dynamicCppCall("bincount", weights, minlength).to(Tensor)
template blackman_window*(window_length: int64, options: ATensorOptions): Tensor = dynamicCCall("at::blackman_window", window_length, options).to(Tensor)
template blackman_window*(window_length: int64, periodic: bool, options: ATensorOptions): Tensor = dynamicCCall("at::blackman_window", window_length, periodic, options).to(Tensor)
template broadcast_tensors*(tensors: TensorList): TensorList = dynamicCCall("at::broadcast_tensors", tensors).to(TensorList)
template cat*(tensors: TensorList, dim: int64 = 0): Tensor = dynamicCCall("at::cat", tensors, dim).to(Tensor)
template cat_out*(aresult: Tensor, tensors: TensorList, dim: int64 = 0): Tensor = dynamicCCall("at::cat_out", aresult, tensors, dim).to(Tensor)
template ceil*(self: Tensor): Tensor = self.dynamicCppCall("ceil").to(Tensor)
template ceil_u*(self: Tensor): Tensor = self.dynamicCppCall("ceil_").to(Tensor)
template ceil_out*(aresult: Tensor, self: Tensor): Tensor = dynamicCCall("at::ceil_out", aresult, self).to(Tensor)
template chunk*(self: Tensor, chunks: int64, dim: int64 = 0): TensorList = self.dynamicCppCall("chunk", chunks, dim).to(TensorList)
template clamp*(self: Tensor, min: float, max: float): Tensor = self.dynamicCppCall("clamp", min, max).to(Tensor)
template clamp_u*(self: Tensor, min: float, max: float): Tensor = self.dynamicCppCall("clamp_", min, max).to(Tensor)
template clamp_out*(aresult: Tensor, self: Tensor, min: float, max: float): Tensor = dynamicCCall("at::clamp_out", aresult, self, min, max).to(Tensor)
template clamp_max*(self: Tensor, max: float): Tensor = self.dynamicCppCall("clamp_max", max).to(Tensor)
template clamp_max_u*(self: Tensor, max: float): Tensor = self.dynamicCppCall("clamp_max_", max).to(Tensor)
template clamp_max_out*(aresult: Tensor, self: Tensor, max: float): Tensor = dynamicCCall("at::clamp_max_out", aresult, self, max).to(Tensor)
template clamp_min*(self: Tensor, min: float): Tensor = self.dynamicCppCall("clamp_min", min).to(Tensor)
template clamp_min_u*(self: Tensor, min: float): Tensor = self.dynamicCppCall("clamp_min_", min).to(Tensor)
template clamp_min_out*(aresult: Tensor, self: Tensor, min: float): Tensor = dynamicCCall("at::clamp_min_out", aresult, self, min).to(Tensor)
template cudnn_is_acceptable*(self: Tensor): bool = dynamicCCall("at::cudnn_is_acceptable", self).to(bool)
template convolution*(input: Tensor, weight: Tensor, bias: Tensor, stride: IntList, padding: IntList, dilation: IntList, transposed: bool, output_padding: IntList, groups: int64): Tensor = dynamicCCall("at::convolution", input, weight, bias, stride, padding, dilation, transposed, output_padding, groups).to(Tensor)
template u_convolution*(input: Tensor, weight: Tensor, bias: Tensor, stride: IntList, padding: IntList, dilation: IntList, transposed: bool, output_padding: IntList, groups: int64, benchmark: bool, deterministic: bool, cudnn_enabled: bool): Tensor = dynamicCCall("at::_convolution", input, weight, bias, stride, padding, dilation, transposed, output_padding, groups, benchmark, deterministic, cudnn_enabled).to(Tensor)
template u_convolution_nogroup*(input: Tensor, weight: Tensor, bias: Tensor, stride: IntList, padding: IntList, dilation: IntList, transposed: bool, output_padding: IntList): Tensor = dynamicCCall("at::_convolution_nogroup", input, weight, bias, stride, padding, dilation, transposed, output_padding).to(Tensor)
template u_convolution_double_backward*(ggI: Tensor, ggW: Tensor, ggb: Tensor, gO: Tensor, weight: Tensor, self: Tensor, stride: IntList, padding: IntList, dilation: IntList, transposed: bool, output_padding: IntList, groups: int64, benchmark: bool, deterministic: bool, cudnn_enabled: bool, output_mask: StdArray[bool, 3]): (Tensor, Tensor, Tensor) = dynamicCCall("at::_convolution_double_backward", ggI, ggW, ggb, gO, weight, self, stride, padding, dilation, transposed, output_padding, groups, benchmark, deterministic, cudnn_enabled, output_mask).to(ATensorTuple3).toNimTensorTuple()
template conv1d*(input: Tensor, weight: Tensor, bias: Tensor, stride: IntList = @[1], padding: IntList = @[0], dilation: IntList = @[1], groups: int64 = 1): Tensor = dynamicCCall("at::conv1d", input, weight, bias, stride, padding, dilation, groups).to(Tensor)
template conv2d*(input: Tensor, weight: Tensor, bias: Tensor, stride: IntList = @[1], padding: IntList = @[0], dilation: IntList = @[1], groups: int64 = 1): Tensor = dynamicCCall("at::conv2d", input, weight, bias, stride, padding, dilation, groups).to(Tensor)
template conv3d*(input: Tensor, weight: Tensor, bias: Tensor, stride: IntList = @[1], padding: IntList = @[0], dilation: IntList = @[1], groups: int64 = 1): Tensor = dynamicCCall("at::conv3d", input, weight, bias, stride, padding, dilation, groups).to(Tensor)
template conv_tbc*(self: Tensor, weight: Tensor, bias: Tensor, pad: int64): Tensor = self.dynamicCppCall("conv_tbc", weight, bias, pad).to(Tensor)
template conv_tbc_backward*(self: Tensor, input: Tensor, weight: Tensor, bias: Tensor, pad: int64): (Tensor, Tensor, Tensor) = self.dynamicCppCall("conv_tbc_backward", input, weight, bias, pad).to(ATensorTuple3).toNimTensorTuple()
template conv_transpose1d*(input: Tensor, weight: Tensor, bias: Tensor, stride: IntList = @[1], padding: IntList = @[0], output_padding: IntList = @[0], groups: int64 = 1, dilation: IntList = @[1]): Tensor = dynamicCCall("at::conv_transpose1d", input, weight, bias, stride, padding, output_padding, groups, dilation).to(Tensor)
template conv_transpose2d*(input: Tensor, weight: Tensor, bias: Tensor, stride: IntList = @[1], padding: IntList = @[0], output_padding: IntList = @[0], groups: int64 = 1, dilation: IntList = @[1]): Tensor = dynamicCCall("at::conv_transpose2d", input, weight, bias, stride, padding, output_padding, groups, dilation).to(Tensor)
template conv_transpose3d*(input: Tensor, weight: Tensor, bias: Tensor, stride: IntList = @[1], padding: IntList = @[0], output_padding: IntList = @[0], groups: int64 = 1, dilation: IntList = @[1]): Tensor = dynamicCCall("at::conv_transpose3d", input, weight, bias, stride, padding, output_padding, groups, dilation).to(Tensor)
template cos*(self: Tensor): Tensor = self.dynamicCppCall("cos").to(Tensor)
template cos_u*(self: Tensor): Tensor = self.dynamicCppCall("cos_").to(Tensor)
template cos_out*(aresult: Tensor, self: Tensor): Tensor = dynamicCCall("at::cos_out", aresult, self).to(Tensor)
template cosh*(self: Tensor): Tensor = self.dynamicCppCall("cosh").to(Tensor)
template cosh_u*(self: Tensor): Tensor = self.dynamicCppCall("cosh_").to(Tensor)
template cosh_out*(aresult: Tensor, self: Tensor): Tensor = dynamicCCall("at::cosh_out", aresult, self).to(Tensor)
template cosine_embedding_loss*(input1: Tensor, input2: Tensor, target: Tensor, margin: float64, reduction: int64): Tensor = dynamicCCall("at::cosine_embedding_loss", input1, input2, target, margin, reduction).to(Tensor)
template cudnn_affine_grid_generator*(theta: Tensor, N: int64, C: int64, H: int64, W: int64): Tensor = dynamicCCall("at::cudnn_affine_grid_generator", theta, N, C, H, W).to(Tensor)
template cudnn_affine_grid_generator_backward*(grad: Tensor, N: int64, C: int64, H: int64, W: int64): Tensor = dynamicCCall("at::cudnn_affine_grid_generator_backward", grad, N, C, H, W).to(Tensor)
template cudnn_batch_norm*(input: Tensor, weight: Tensor, bias: Tensor, running_mean: Tensor, running_var: Tensor, training: bool, exponential_average_factor: float64, epsilon: float64): (Tensor, Tensor, Tensor) = dynamicCCall("at::cudnn_batch_norm", input, weight, bias, running_mean, running_var, training, exponential_average_factor, epsilon).to(ATensorTuple3).toNimTensorTuple()
template cudnn_batch_norm_backward*(input: Tensor, grad_output: Tensor, weight: Tensor, running_mean: Tensor, running_var: Tensor, save_mean: Tensor, save_var: Tensor, epsilon: float64): (Tensor, Tensor, Tensor) = dynamicCCall("at::cudnn_batch_norm_backward", input, grad_output, weight, running_mean, running_var, save_mean, save_var, epsilon).to(ATensorTuple3).toNimTensorTuple()
template cudnn_convolution*(self: Tensor, weight: Tensor, bias: Tensor, padding: IntList, stride: IntList, dilation: IntList, groups: int64, benchmark: bool, deterministic: bool): Tensor = dynamicCCall("at::cudnn_convolution", self, weight, bias, padding, stride, dilation, groups, benchmark, deterministic).to(Tensor)
template cudnn_convolution_backward_input*(self_size: IntList, grad_output: Tensor, weight: Tensor, padding: IntList, stride: IntList, dilation: IntList, groups: int64, benchmark: bool, deterministic: bool): Tensor = dynamicCCall("at::cudnn_convolution_backward_input", self_size, grad_output, weight, padding, stride, dilation, groups, benchmark, deterministic).to(Tensor)
template cudnn_convolution_backward*(self: Tensor, grad_output: Tensor, weight: Tensor, padding: IntList, stride: IntList, dilation: IntList, groups: int64, benchmark: bool, deterministic: bool, output_mask: StdArray[bool, 3]): (Tensor, Tensor, Tensor) = dynamicCCall("at::cudnn_convolution_backward", self, grad_output, weight, padding, stride, dilation, groups, benchmark, deterministic, output_mask).to(ATensorTuple3).toNimTensorTuple()
template cudnn_convolution_backward_bias*(grad_output: Tensor): Tensor = dynamicCCall("at::cudnn_convolution_backward_bias", grad_output).to(Tensor)
template cudnn_convolution_backward_weight*(weight_size: IntList, grad_output: Tensor, self: Tensor, padding: IntList, stride: IntList, dilation: IntList, groups: int64, benchmark: bool, deterministic: bool): Tensor = dynamicCCall("at::cudnn_convolution_backward_weight", weight_size, grad_output, self, padding, stride, dilation, groups, benchmark, deterministic).to(Tensor)
template cudnn_convolution_transpose*(self: Tensor, weight: Tensor, bias: Tensor, padding: IntList, output_padding: IntList, stride: IntList, dilation: IntList, groups: int64, benchmark: bool, deterministic: bool): Tensor = dynamicCCall("at::cudnn_convolution_transpose", self, weight, bias, padding, output_padding, stride, dilation, groups, benchmark, deterministic).to(Tensor)
template cudnn_convolution_transpose_backward*(self: Tensor, grad_output: Tensor, weight: Tensor, padding: IntList, output_padding: IntList, stride: IntList, dilation: IntList, groups: int64, benchmark: bool, deterministic: bool, output_mask: StdArray[bool, 3]): (Tensor, Tensor, Tensor) = dynamicCCall("at::cudnn_convolution_transpose_backward", self, grad_output, weight, padding, output_padding, stride, dilation, groups, benchmark, deterministic, output_mask).to(ATensorTuple3).toNimTensorTuple()
template cudnn_convolution_transpose_backward_bias*(grad_output: Tensor): Tensor = dynamicCCall("at::cudnn_convolution_transpose_backward_bias", grad_output).to(Tensor)
template cudnn_convolution_transpose_backward_input*(grad_output: Tensor, weight: Tensor, padding: IntList, stride: IntList, dilation: IntList, groups: int64, benchmark: bool, deterministic: bool): Tensor = dynamicCCall("at::cudnn_convolution_transpose_backward_input", grad_output, weight, padding, stride, dilation, groups, benchmark, deterministic).to(Tensor)
template cudnn_convolution_transpose_backward_weight*(weight_size: IntList, grad_output: Tensor, self: Tensor, padding: IntList, stride: IntList, dilation: IntList, groups: int64, benchmark: bool, deterministic: bool): Tensor = dynamicCCall("at::cudnn_convolution_transpose_backward_weight", weight_size, grad_output, self, padding, stride, dilation, groups, benchmark, deterministic).to(Tensor)
template cudnn_grid_sampler*(self: Tensor, grid: Tensor): Tensor = dynamicCCall("at::cudnn_grid_sampler", self, grid).to(Tensor)
template cudnn_grid_sampler_backward*(self: Tensor, grid: Tensor, grad_output: Tensor): (Tensor, Tensor) = dynamicCCall("at::cudnn_grid_sampler_backward", self, grid, grad_output).to(ATensorTuple2).toNimTensorTuple()
template cumsum*(self: Tensor, dim: int64, dtype: AScalarType): Tensor = self.dynamicCppCall("cumsum", dim, dtype).to(Tensor)
template cumsum*(self: Tensor, dim: int64): Tensor = self.dynamicCppCall("cumsum", dim).to(Tensor)
template cumsum_out*(aresult: Tensor, self: Tensor, dim: int64, dtype: AScalarType): Tensor = dynamicCCall("at::cumsum_out", aresult, self, dim, dtype).to(Tensor)
template cumsum_out*(aresult: Tensor, self: Tensor, dim: int64): Tensor = dynamicCCall("at::cumsum_out", aresult, self, dim).to(Tensor)
template cumprod*(self: Tensor, dim: int64, dtype: AScalarType): Tensor = self.dynamicCppCall("cumprod", dim, dtype).to(Tensor)
template cumprod*(self: Tensor, dim: int64): Tensor = self.dynamicCppCall("cumprod", dim).to(Tensor)
template cumprod_out*(aresult: Tensor, self: Tensor, dim: int64, dtype: AScalarType): Tensor = dynamicCCall("at::cumprod_out", aresult, self, dim, dtype).to(Tensor)
template cumprod_out*(aresult: Tensor, self: Tensor, dim: int64): Tensor = dynamicCCall("at::cumprod_out", aresult, self, dim).to(Tensor)
template ctc_loss*(log_probs: Tensor, targets: Tensor, input_lengths: IntList, target_lengths: IntList, blank: int64 = 0, reduction: int64): Tensor = dynamicCCall("at::ctc_loss", log_probs, targets, input_lengths, target_lengths, blank, reduction).to(Tensor)
template ctc_loss*(log_probs: Tensor, targets: Tensor, input_lengths: Tensor, target_lengths: Tensor, blank: int64 = 0, reduction: int64): Tensor = dynamicCCall("at::ctc_loss", log_probs, targets, input_lengths, target_lengths, blank, reduction).to(Tensor)
template u_ctc_loss*(log_probs: Tensor, targets: Tensor, input_lengths: IntList, target_lengths: IntList, blank: int64 = 0): (Tensor, Tensor) = dynamicCCall("at::_ctc_loss", log_probs, targets, input_lengths, target_lengths, blank).to(ATensorTuple2).toNimTensorTuple()
template u_ctc_loss_backward*(grad: Tensor, log_probs: Tensor, targets: Tensor, input_lengths: IntList, target_lengths: IntList, neg_log_likelihood: Tensor, log_alpha: Tensor, blank: int64): Tensor = dynamicCCall("at::_ctc_loss_backward", grad, log_probs, targets, input_lengths, target_lengths, neg_log_likelihood, log_alpha, blank).to(Tensor)
template det*(self: Tensor): Tensor = self.dynamicCppCall("det").to(Tensor)
template diagflat*(self: Tensor, offset: int64 = 0): Tensor = dynamicCCall("at::diagflat", self, offset).to(Tensor)
template diagonal*(self: Tensor, offset: int64 = 0, dim1: int64 = 0, dim2: int64 = 1): Tensor = self.dynamicCppCall("diagonal", offset, dim1, dim2).to(Tensor)
template adiv*(self: Tensor, other: Tensor): Tensor = self.dynamicCppCall("div", other).to(Tensor)
template div_u*(self: Tensor, other: Tensor): Tensor = self.dynamicCppCall("div_", other).to(Tensor)
template div_out*(aresult: Tensor, self: Tensor, other: Tensor): Tensor = dynamicCCall("at::div_out", aresult, self, other).to(Tensor)
template adiv*(self: Tensor, other: float): Tensor = self.dynamicCppCall("div", other).to(Tensor)
template div_u*(self: Tensor, other: float): Tensor = self.dynamicCppCall("div_", other).to(Tensor)
template dot*(self: Tensor, tensor: Tensor): Tensor = self.dynamicCppCall("dot", tensor).to(Tensor)
template dot_out*(aresult: Tensor, self: Tensor, tensor: Tensor): Tensor = dynamicCCall("at::dot_out", aresult, self, tensor).to(Tensor)
template einsum*(equation: StdString, tensors: TensorList): Tensor = dynamicCCall("at::einsum", equation, tensors).to(Tensor)
template embedding*(weight: Tensor, indices: Tensor, padding_idx: int64 = -1, scale_grad_by_freq: bool = false, sparse: bool = false): Tensor = dynamicCCall("at::embedding", weight, indices, padding_idx, scale_grad_by_freq, sparse).to(Tensor)
template embedding_backward*(grad: Tensor, indices: Tensor, num_weights: int64, padding_idx: int64, scale_grad_by_freq: bool, sparse: bool): Tensor = dynamicCCall("at::embedding_backward", grad, indices, num_weights, padding_idx, scale_grad_by_freq, sparse).to(Tensor)
template embedding_dense_backward*(grad: Tensor, indices: Tensor, num_weights: int64, padding_idx: int64, scale_grad_by_freq: bool): Tensor = dynamicCCall("at::embedding_dense_backward", grad, indices, num_weights, padding_idx, scale_grad_by_freq).to(Tensor)
template embedding_renorm_u*(self: Tensor, indices: Tensor, max_norm: float64, norm_type: float64): Tensor = dynamicCCall("at::embedding_renorm_", self, indices, max_norm, norm_type).to(Tensor)
template embedding_sparse_backward*(grad: Tensor, indices: Tensor, num_weights: int64, padding_idx: int64, scale_grad_by_freq: bool): Tensor = dynamicCCall("at::embedding_sparse_backward", grad, indices, num_weights, padding_idx, scale_grad_by_freq).to(Tensor)
template embedding_bag*(weight: Tensor, indices: Tensor, offsets: Tensor, scale_grad_by_freq: bool = false, mode: int64 = 0, sparse: bool = false): (Tensor, Tensor, Tensor, Tensor) = dynamicCCall("at::embedding_bag", weight, indices, offsets, scale_grad_by_freq, mode, sparse).to(ATensorTuple4).toNimTensorTuple()
template u_embedding_bag*(weight: Tensor, indices: Tensor, offsets: Tensor, scale_grad_by_freq: bool = false, mode: int64 = 0, sparse: bool = false): (Tensor, Tensor, Tensor, Tensor) = dynamicCCall("at::_embedding_bag", weight, indices, offsets, scale_grad_by_freq, mode, sparse).to(ATensorTuple4).toNimTensorTuple()
template u_embedding_bag_backward*(grad: Tensor, indices: Tensor, offsets: Tensor, offset2bag: Tensor, bag_size: Tensor, maximum_indices: Tensor, num_weights: int64, scale_grad_by_freq: bool, mode: int64, sparse: bool): Tensor = dynamicCCall("at::_embedding_bag_backward", grad, indices, offsets, offset2bag, bag_size, maximum_indices, num_weights, scale_grad_by_freq, mode, sparse).to(Tensor)
template u_embedding_bag_sparse_backward*(grad: Tensor, indices: Tensor, offsets: Tensor, offset2bag: Tensor, bag_size: Tensor, num_weights: int64, scale_grad_by_freq: bool, mode: int64): Tensor = dynamicCCall("at::_embedding_bag_sparse_backward", grad, indices, offsets, offset2bag, bag_size, num_weights, scale_grad_by_freq, mode).to(Tensor)
template u_embedding_bag_dense_backward*(grad: Tensor, indices: Tensor, offsets: Tensor, offset2bag: Tensor, bag_size: Tensor, maximum_indices: Tensor, num_weights: int64, scale_grad_by_freq: bool, mode: int64): Tensor = dynamicCCall("at::_embedding_bag_dense_backward", grad, indices, offsets, offset2bag, bag_size, maximum_indices, num_weights, scale_grad_by_freq, mode).to(Tensor)
template empty*(size: IntList, options: ATensorOptions): Tensor = dynamicCCall("at::empty", size, options).to(Tensor)
template empty_out*(aresult: Tensor, size: IntList): Tensor = dynamicCCall("at::empty_out", aresult, size).to(Tensor)
template empty_like*(self: Tensor): Tensor = dynamicCCall("at::empty_like", self).to(Tensor)
template empty_like*(self: Tensor, options: ATensorOptions): Tensor = dynamicCCall("at::empty_like", self, options).to(Tensor)
template empty*(dtype: AType, size: IntList): Tensor {.deprecated.} = dynamicCCall("at::empty", dtype, size).to(Tensor)
template erf*(self: Tensor): Tensor = self.dynamicCppCall("erf").to(Tensor)
template erf_u*(self: Tensor): Tensor = self.dynamicCppCall("erf_").to(Tensor)
template erf_out*(aresult: Tensor, self: Tensor): Tensor = dynamicCCall("at::erf_out", aresult, self).to(Tensor)
template erfc*(self: Tensor): Tensor = self.dynamicCppCall("erfc").to(Tensor)
template erfc_u*(self: Tensor): Tensor = self.dynamicCppCall("erfc_").to(Tensor)
template erfc_out*(aresult: Tensor, self: Tensor): Tensor = dynamicCCall("at::erfc_out", aresult, self).to(Tensor)
template exp*(self: Tensor): Tensor = self.dynamicCppCall("exp").to(Tensor)
template exp_u*(self: Tensor): Tensor = self.dynamicCppCall("exp_").to(Tensor)
template exp_out*(aresult: Tensor, self: Tensor): Tensor = dynamicCCall("at::exp_out", aresult, self).to(Tensor)
template expm1*(self: Tensor): Tensor = self.dynamicCppCall("expm1").to(Tensor)
template expm1_u*(self: Tensor): Tensor = self.dynamicCppCall("expm1_").to(Tensor)
template expm1_out*(aresult: Tensor, self: Tensor): Tensor = dynamicCCall("at::expm1_out", aresult, self).to(Tensor)
template expand*(self: Tensor, size: IntList, implicit: bool = false): Tensor = self.dynamicCppCall("expand", size, implicit).to(Tensor)
template expand_as*(self: Tensor, other: Tensor): Tensor = self.dynamicCppCall("expand_as", other).to(Tensor)
template eye*(n: int64, options: ATensorOptions): Tensor = dynamicCCall("at::eye", n, options).to(Tensor)
template eye*(n: int64, m: int64, options: ATensorOptions): Tensor = dynamicCCall("at::eye", n, m, options).to(Tensor)
template eye_out*(aresult: Tensor, n: int64): Tensor = dynamicCCall("at::eye_out", aresult, n).to(Tensor)
template eye_out*(aresult: Tensor, n: int64, m: int64): Tensor = dynamicCCall("at::eye_out", aresult, n, m).to(Tensor)
template eye*(dtype: AType, n: int64, m: int64 = -1): Tensor {.deprecated.} = dynamicCCall("at::eye", dtype, n, m).to(Tensor)
template flatten*(self: Tensor, start_dim: int64 = 0, end_dim: int64 = -1): Tensor = self.dynamicCppCall("flatten", start_dim, end_dim).to(Tensor)
template fill_u*(self: Tensor, value: float): Tensor = self.dynamicCppCall("fill_", value).to(Tensor)
template fill_u*(self: Tensor, value: Tensor): Tensor = self.dynamicCppCall("fill_", value).to(Tensor)
template floor*(self: Tensor): Tensor = self.dynamicCppCall("floor").to(Tensor)
template floor_u*(self: Tensor): Tensor = self.dynamicCppCall("floor_").to(Tensor)
template floor_out*(aresult: Tensor, self: Tensor): Tensor = dynamicCCall("at::floor_out", aresult, self).to(Tensor)
template full*(size: IntList, fill_value: float, options: ATensorOptions): Tensor = dynamicCCall("at::full", size, fill_value, options).to(Tensor)
template full_out*(aresult: Tensor, size: IntList, fill_value: float): Tensor = dynamicCCall("at::full_out", aresult, size, fill_value).to(Tensor)
template full_like*(self: Tensor, fill_value: float): Tensor = dynamicCCall("at::full_like", self, fill_value).to(Tensor)
template full_like*(self: Tensor, fill_value: float, options: ATensorOptions): Tensor = dynamicCCall("at::full_like", self, fill_value, options).to(Tensor)
template full*(dtype: AType, size: IntList, fill_value: float): Tensor {.deprecated.} = dynamicCCall("at::full", dtype, size, fill_value).to(Tensor)
template grid_sampler*(input: Tensor, grid: Tensor, padding_mode: int64): Tensor = dynamicCCall("at::grid_sampler", input, grid, padding_mode).to(Tensor)
template grid_sampler_2d*(input: Tensor, grid: Tensor, interpolation_mode: int64, padding_mode: int64): Tensor = dynamicCCall("at::grid_sampler_2d", input, grid, interpolation_mode, padding_mode).to(Tensor)
template grid_sampler_2d_backward*(grad_output: Tensor, input: Tensor, grid: Tensor, interpolation_mode: int64, padding_mode: int64): (Tensor, Tensor) = dynamicCCall("at::grid_sampler_2d_backward", grad_output, input, grid, interpolation_mode, padding_mode).to(ATensorTuple2).toNimTensorTuple()
template grid_sampler_3d*(input: Tensor, grid: Tensor, interpolation_mode: int64, padding_mode: int64): Tensor = dynamicCCall("at::grid_sampler_3d", input, grid, interpolation_mode, padding_mode).to(Tensor)
template grid_sampler_3d_backward*(grad_output: Tensor, input: Tensor, grid: Tensor, interpolation_mode: int64, padding_mode: int64): (Tensor, Tensor) = dynamicCCall("at::grid_sampler_3d_backward", grad_output, input, grid, interpolation_mode, padding_mode).to(ATensorTuple2).toNimTensorTuple()
template hann_window*(window_length: int64, options: ATensorOptions): Tensor = dynamicCCall("at::hann_window", window_length, options).to(Tensor)
template hann_window*(window_length: int64, periodic: bool, options: ATensorOptions): Tensor = dynamicCCall("at::hann_window", window_length, periodic, options).to(Tensor)
template hamming_window*(window_length: int64, options: ATensorOptions): Tensor = dynamicCCall("at::hamming_window", window_length, options).to(Tensor)
template hamming_window*(window_length: int64, periodic: bool, options: ATensorOptions): Tensor = dynamicCCall("at::hamming_window", window_length, periodic, options).to(Tensor)
template hamming_window*(window_length: int64, periodic: bool, alpha: float64, options: ATensorOptions): Tensor = dynamicCCall("at::hamming_window", window_length, periodic, alpha, options).to(Tensor)
template hamming_window*(window_length: int64, periodic: bool, alpha: float64, beta: float64, options: ATensorOptions): Tensor = dynamicCCall("at::hamming_window", window_length, periodic, alpha, beta, options).to(Tensor)
template hinge_embedding_loss*(self: Tensor, target: Tensor, margin: float64, reduction: int64): Tensor = dynamicCCall("at::hinge_embedding_loss", self, target, margin, reduction).to(Tensor)
template ger*(self: Tensor, vec2: Tensor): Tensor = self.dynamicCppCall("ger", vec2).to(Tensor)
template ger_out*(aresult: Tensor, self: Tensor, vec2: Tensor): Tensor = dynamicCCall("at::ger_out", aresult, self, vec2).to(Tensor)
template gesv*(self: Tensor, A: Tensor): (Tensor, Tensor) = self.dynamicCppCall("gesv", A).to(ATensorTuple2).toNimTensorTuple()
template gesv_out*(solution: Tensor, lu: Tensor, self: Tensor, A: Tensor): (Tensor, Tensor) = dynamicCCall("at::gesv_out", solution, lu, self, A).to(ATensorRTuple2).toNimTensorTuple()
template u_gesv_helper*(self: Tensor, A: Tensor): (Tensor, Tensor) = self.dynamicCppCall("_gesv_helper", A).to(ATensorTuple2).toNimTensorTuple()
template group_norm*(input: Tensor, num_groups: int64, weight: Tensor, bias: Tensor, eps: float64, cudnn_enabled: bool = true): Tensor = dynamicCCall("at::group_norm", input, num_groups, weight, bias, eps, cudnn_enabled).to(Tensor)
template fft*(self: Tensor, signal_ndim: int64, normalized: bool = false): Tensor = self.dynamicCppCall("fft", signal_ndim, normalized).to(Tensor)
template ifft*(self: Tensor, signal_ndim: int64, normalized: bool = false): Tensor = self.dynamicCppCall("ifft", signal_ndim, normalized).to(Tensor)
template rfft*(self: Tensor, signal_ndim: int64, normalized: bool = false, onesided: bool = true): Tensor = self.dynamicCppCall("rfft", signal_ndim, normalized, onesided).to(Tensor)
template irfft*(self: Tensor, signal_ndim: int64, normalized: bool = false, onesided: bool = true, signal_sizes: IntList): Tensor = self.dynamicCppCall("irfft", signal_ndim, normalized, onesided, signal_sizes).to(Tensor)
template u_fft_with_size*(self: Tensor, signal_ndim: int64, complex_input: bool, complex_output: bool, inverse: bool, checked_signal_sizes: IntList, normalized: bool, onesided: bool, output_sizes: IntList): Tensor = self.dynamicCppCall("_fft_with_size", signal_ndim, complex_input, complex_output, inverse, checked_signal_sizes, normalized, onesided, output_sizes).to(Tensor)
template u_cufft_get_plan_cache_size*(): int64 = dynamicCCall("at::_cufft_get_plan_cache_size").to(int64)
template u_cufft_get_plan_cache_max_size*(): int64 = dynamicCCall("at::_cufft_get_plan_cache_max_size").to(int64)
template u_cufft_set_plan_cache_max_size*(max_size: int64): void = dynamicCCall("at::_cufft_set_plan_cache_max_size", max_size).to(void)
template u_cufft_clear_plan_cache*(): void = dynamicCCall("at::_cufft_clear_plan_cache").to(void)
template index*(self: Tensor, indices: TensorList): Tensor = self.dynamicCppCall("index", indices).to(Tensor)
template index_copy_u*(self: Tensor, dim: int64, index: Tensor, source: Tensor): Tensor = self.dynamicCppCall("index_copy_", dim, index, source).to(Tensor)
template index_put*(self: Tensor, indices: TensorList, values: Tensor): Tensor = self.dynamicCppCall("index_put", indices, values).to(Tensor)
template index_put_u*(self: Tensor, indices: TensorList, values: Tensor): Tensor = self.dynamicCppCall("index_put_", indices, values).to(Tensor)
template inverse*(self: Tensor): Tensor = self.dynamicCppCall("inverse").to(Tensor)
template inverse_out*(aresult: Tensor, self: Tensor): Tensor = dynamicCCall("at::inverse_out", aresult, self).to(Tensor)
template isclose*(self: Tensor, other: Tensor, rtol: float64, atol: float64, equal_nan: bool = false): Tensor = self.dynamicCppCall("isclose", other, rtol, atol, equal_nan).to(Tensor)
template is_cuda*(self: Tensor): bool = self.dynamicCppCall("is_cuda").to(bool)
template is_distributed*(self: Tensor): bool = self.dynamicCppCall("is_distributed").to(bool)
template is_floating_point*(self: Tensor): bool = self.dynamicCppCall("is_floating_point").to(bool)
template is_nonzero*(self: Tensor): bool = self.dynamicCppCall("is_nonzero").to(bool)
template is_same_size*(self: Tensor, other: Tensor): bool = self.dynamicCppCall("is_same_size", other).to(bool)
template is_signed*(self: Tensor): bool = self.dynamicCppCall("is_signed").to(bool)
template is_sparse*(self: Tensor): bool = self.dynamicCppCall("is_sparse").to(bool)
template kthvalue*(self: Tensor, k: int64, dim: int64 = -1, keepdim: bool = false): (Tensor, Tensor) = self.dynamicCppCall("kthvalue", k, dim, keepdim).to(ATensorTuple2).toNimTensorTuple()
template kthvalue_out*(values: Tensor, indices: Tensor, self: Tensor, k: int64, dim: int64 = -1, keepdim: bool = false): (Tensor, Tensor) = dynamicCCall("at::kthvalue_out", values, indices, self, k, dim, keepdim).to(ATensorRTuple2).toNimTensorTuple()
template layer_norm*(input: Tensor, normalized_shape: IntList, weight: Tensor, bias: Tensor, eps: float64, cudnn_enable: bool = true): Tensor = dynamicCCall("at::layer_norm", input, normalized_shape, weight, bias, eps, cudnn_enable).to(Tensor)
template linspace*(start: float, aend: float, options: ATensorOptions): Tensor = dynamicCCall("at::linspace", start, aend, options).to(Tensor)
template linspace*(start: float, aend: float, steps: int64, options: ATensorOptions): Tensor = dynamicCCall("at::linspace", start, aend, steps, options).to(Tensor)
template linspace_out*(aresult: Tensor, start: float, aend: float): Tensor = dynamicCCall("at::linspace_out", aresult, start, aend).to(Tensor)
template linspace_out*(aresult: Tensor, start: float, aend: float, steps: int64): Tensor = dynamicCCall("at::linspace_out", aresult, start, aend, steps).to(Tensor)
template linspace*(dtype: AType, start: float, aend: float, steps: int64 = 100): Tensor {.deprecated.} = dynamicCCall("at::linspace", dtype, start, aend, steps).to(Tensor)
template log*(self: Tensor): Tensor = self.dynamicCppCall("log").to(Tensor)
template log_u*(self: Tensor): Tensor = self.dynamicCppCall("log_").to(Tensor)
template log_out*(aresult: Tensor, self: Tensor): Tensor = dynamicCCall("at::log_out", aresult, self).to(Tensor)
template log10*(self: Tensor): Tensor = self.dynamicCppCall("log10").to(Tensor)
template log10_u*(self: Tensor): Tensor = self.dynamicCppCall("log10_").to(Tensor)
template log10_out*(aresult: Tensor, self: Tensor): Tensor = dynamicCCall("at::log10_out", aresult, self).to(Tensor)
template log1p*(self: Tensor): Tensor = self.dynamicCppCall("log1p").to(Tensor)
template log1p_u*(self: Tensor): Tensor = self.dynamicCppCall("log1p_").to(Tensor)
template log1p_out*(aresult: Tensor, self: Tensor): Tensor = dynamicCCall("at::log1p_out", aresult, self).to(Tensor)
template log2*(self: Tensor): Tensor = self.dynamicCppCall("log2").to(Tensor)
template log2_u*(self: Tensor): Tensor = self.dynamicCppCall("log2_").to(Tensor)
template log2_out*(aresult: Tensor, self: Tensor): Tensor = dynamicCCall("at::log2_out", aresult, self).to(Tensor)
template logdet*(self: Tensor): Tensor = self.dynamicCppCall("logdet").to(Tensor)
template logspace*(start: float, aend: float, options: ATensorOptions): Tensor = dynamicCCall("at::logspace", start, aend, options).to(Tensor)
template logspace*(start: float, aend: float, steps: int64, options: ATensorOptions): Tensor = dynamicCCall("at::logspace", start, aend, steps, options).to(Tensor)
template logspace_out*(aresult: Tensor, start: float, aend: float): Tensor = dynamicCCall("at::logspace_out", aresult, start, aend).to(Tensor)
template logspace_out*(aresult: Tensor, start: float, aend: float, steps: int64): Tensor = dynamicCCall("at::logspace_out", aresult, start, aend, steps).to(Tensor)
template logspace*(dtype: AType, start: float, aend: float, steps: int64 = 100): Tensor {.deprecated.} = dynamicCCall("at::logspace", dtype, start, aend, steps).to(Tensor)
template log_softmax*(self: Tensor, dim: int64): Tensor = self.dynamicCppCall("log_softmax", dim).to(Tensor)
template log_softmax_backward_data*(self: Tensor, grad_output: Tensor, output: Tensor, dim: int64): Tensor = self.dynamicCppCall("log_softmax_backward_data", grad_output, output, dim).to(Tensor)
template logsumexp*(self: Tensor, dim: int64, keepdim: bool = false): Tensor = self.dynamicCppCall("logsumexp", dim, keepdim).to(Tensor)
template logsumexp_out*(aresult: Tensor, self: Tensor, dim: int64, keepdim: bool = false): Tensor = dynamicCCall("at::logsumexp_out", aresult, self, dim, keepdim).to(Tensor)
template margin_ranking_loss*(input1: Tensor, input2: Tensor, target: Tensor, margin: float64, reduction: int64): Tensor = dynamicCCall("at::margin_ranking_loss", input1, input2, target, margin, reduction).to(Tensor)
template matmul*(self: Tensor, other: Tensor): Tensor = self.dynamicCppCall("matmul", other).to(Tensor)
template matmul_out*(aresult: Tensor, self: Tensor, other: Tensor): Tensor = dynamicCCall("at::matmul_out", aresult, self, other).to(Tensor)
template max*(self: Tensor, dim: int64, keepdim: bool = false): (Tensor, Tensor) = self.dynamicCppCall("max", dim, keepdim).to(ATensorTuple2).toNimTensorTuple()
template max_out*(max: Tensor, max_values: Tensor, self: Tensor, dim: int64, keepdim: bool = false): (Tensor, Tensor) = dynamicCCall("at::max_out", max, max_values, self, dim, keepdim).to(ATensorRTuple2).toNimTensorTuple()
template max_values*(self: Tensor, dim: int64, keepdim: bool = false): Tensor = self.dynamicCppCall("max_values", dim, keepdim).to(Tensor)
template max_pool1d_with_indices*(self: Tensor, kernel_size: IntList, stride: IntList, padding: IntList = @[0], dilation: IntList = @[1], ceil_mode: bool = false): (Tensor, Tensor) = dynamicCCall("at::max_pool1d_with_indices", self, kernel_size, stride, padding, dilation, ceil_mode).to(ATensorTuple2).toNimTensorTuple()
template max_pool1d*(self: Tensor, kernel_size: IntList, stride: IntList, padding: IntList = @[0], dilation: IntList = @[1], ceil_mode: bool = false): Tensor = dynamicCCall("at::max_pool1d", self, kernel_size, stride, padding, dilation, ceil_mode).to(Tensor)
template max_pool2d*(self: Tensor, kernel_size: IntList, stride: IntList, padding: IntList = @[0], dilation: IntList = @[1], ceil_mode: bool = false): Tensor = dynamicCCall("at::max_pool2d", self, kernel_size, stride, padding, dilation, ceil_mode).to(Tensor)
template max_pool3d*(self: Tensor, kernel_size: IntList, stride: IntList, padding: IntList = @[0], dilation: IntList = @[1], ceil_mode: bool = false): Tensor = dynamicCCall("at::max_pool3d", self, kernel_size, stride, padding, dilation, ceil_mode).to(Tensor)
template mean*(self: Tensor, dtype: AScalarType): Tensor = self.dynamicCppCall("mean", dtype).to(Tensor)
template mean*(self: Tensor): Tensor = self.dynamicCppCall("mean").to(Tensor)
template mean*(self: Tensor, dim: int64, keepdim: bool, dtype: AScalarType): Tensor = self.dynamicCppCall("mean", dim, keepdim, dtype).to(Tensor)
template mean*(self: Tensor, dim: int64, keepdim: bool = false): Tensor = self.dynamicCppCall("mean", dim, keepdim).to(Tensor)
template mean*(self: Tensor, dim: int64, dtype: AScalarType): Tensor = self.dynamicCppCall("mean", dim, dtype).to(Tensor)
template mean_out*(aresult: Tensor, self: Tensor, dim: int64, keepdim: bool, dtype: AScalarType): Tensor = dynamicCCall("at::mean_out", aresult, self, dim, keepdim, dtype).to(Tensor)
template mean_out*(aresult: Tensor, self: Tensor, dim: int64, keepdim: bool = false): Tensor = dynamicCCall("at::mean_out", aresult, self, dim, keepdim).to(Tensor)
template mean_out*(aresult: Tensor, self: Tensor, dim: int64, dtype: AScalarType): Tensor = dynamicCCall("at::mean_out", aresult, self, dim, dtype).to(Tensor)
template median*(self: Tensor, dim: int64, keepdim: bool = false): (Tensor, Tensor) = self.dynamicCppCall("median", dim, keepdim).to(ATensorTuple2).toNimTensorTuple()
template median_out*(values: Tensor, indices: Tensor, self: Tensor, dim: int64, keepdim: bool = false): (Tensor, Tensor) = dynamicCCall("at::median_out", values, indices, self, dim, keepdim).to(ATensorRTuple2).toNimTensorTuple()
template min*(self: Tensor, dim: int64, keepdim: bool = false): (Tensor, Tensor) = self.dynamicCppCall("min", dim, keepdim).to(ATensorTuple2).toNimTensorTuple()
template min_out*(min: Tensor, min_indices: Tensor, self: Tensor, dim: int64, keepdim: bool = false): (Tensor, Tensor) = dynamicCCall("at::min_out", min, min_indices, self, dim, keepdim).to(ATensorRTuple2).toNimTensorTuple()
template min_values*(self: Tensor, dim: int64, keepdim: bool = false): Tensor = self.dynamicCppCall("min_values", dim, keepdim).to(Tensor)
template mkldnn_convolution*(self: Tensor, weight: Tensor, bias: Tensor, padding: IntList, stride: IntList, dilation: IntList, groups: int64): Tensor = dynamicCCall("at::mkldnn_convolution", self, weight, bias, padding, stride, dilation, groups).to(Tensor)
template mkldnn_convolution_backward_input*(self_size: IntList, grad_output: Tensor, weight: Tensor, padding: IntList, stride: IntList, dilation: IntList, groups: int64, bias_defined: bool): Tensor = dynamicCCall("at::mkldnn_convolution_backward_input", self_size, grad_output, weight, padding, stride, dilation, groups, bias_defined).to(Tensor)
template mkldnn_convolution_backward_weights*(weight_size: IntList, grad_output: Tensor, self: Tensor, padding: IntList, stride: IntList, dilation: IntList, groups: int64, bias_defined: bool): (Tensor, Tensor) = dynamicCCall("at::mkldnn_convolution_backward_weights", weight_size, grad_output, self, padding, stride, dilation, groups, bias_defined).to(ATensorTuple2).toNimTensorTuple()
template mkldnn_convolution_backward*(self: Tensor, grad_output: Tensor, weight: Tensor, padding: IntList, stride: IntList, dilation: IntList, groups: int64, output_mask: StdArray[bool, 3]): (Tensor, Tensor, Tensor) = dynamicCCall("at::mkldnn_convolution_backward", self, grad_output, weight, padding, stride, dilation, groups, output_mask).to(ATensorTuple3).toNimTensorTuple()
template mm*(self: Tensor, mat2: Tensor): Tensor = self.dynamicCppCall("mm", mat2).to(Tensor)
template mm_out*(aresult: Tensor, self: Tensor, mat2: Tensor): Tensor = dynamicCCall("at::mm_out", aresult, self, mat2).to(Tensor)
template mode*(self: Tensor, dim: int64 = -1, keepdim: bool = false): (Tensor, Tensor) = self.dynamicCppCall("mode", dim, keepdim).to(ATensorTuple2).toNimTensorTuple()
template mode_out*(values: Tensor, indices: Tensor, self: Tensor, dim: int64 = -1, keepdim: bool = false): (Tensor, Tensor) = dynamicCCall("at::mode_out", values, indices, self, dim, keepdim).to(ATensorRTuple2).toNimTensorTuple()
template mul*(self: Tensor, other: Tensor): Tensor = self.dynamicCppCall("mul", other).to(Tensor)
template mul_u*(self: Tensor, other: Tensor): Tensor = self.dynamicCppCall("mul_", other).to(Tensor)
template mul_out*(aresult: Tensor, self: Tensor, other: Tensor): Tensor = dynamicCCall("at::mul_out", aresult, self, other).to(Tensor)
template mul*(self: Tensor, other: float): Tensor = self.dynamicCppCall("mul", other).to(Tensor)
template mul_u*(self: Tensor, other: float): Tensor = self.dynamicCppCall("mul_", other).to(Tensor)
template mv*(self: Tensor, vec: Tensor): Tensor = self.dynamicCppCall("mv", vec).to(Tensor)
template mv_out*(aresult: Tensor, self: Tensor, vec: Tensor): Tensor = dynamicCCall("at::mv_out", aresult, self, vec).to(Tensor)
template mvlgamma*(self: Tensor, p: int64): Tensor = self.dynamicCppCall("mvlgamma", p).to(Tensor)
template mvlgamma_u*(self: Tensor, p: int64): Tensor = self.dynamicCppCall("mvlgamma_", p).to(Tensor)
template narrow*(self: Tensor, dim: int64, start: int64, length: int64): Tensor = self.dynamicCppCall("narrow", dim, start, length).to(Tensor)
template ones*(size: IntList, options: ATensorOptions): Tensor = dynamicCCall("at::ones", size, options).to(Tensor)
template ones_out*(aresult: Tensor, size: IntList): Tensor = dynamicCCall("at::ones_out", aresult, size).to(Tensor)
template ones_like*(self: Tensor): Tensor = dynamicCCall("at::ones_like", self).to(Tensor)
template ones_like*(self: Tensor, options: ATensorOptions): Tensor = dynamicCCall("at::ones_like", self, options).to(Tensor)
template ones*(dtype: AType, size: IntList): Tensor {.deprecated.} = dynamicCCall("at::ones", dtype, size).to(Tensor)
template pairwise_distance*(x1: Tensor, x2: Tensor, p: float64 = 2, eps: float64, keepdim: bool = false): Tensor = dynamicCCall("at::pairwise_distance", x1, x2, p, eps, keepdim).to(Tensor)
template permute*(self: Tensor, dims: IntList): Tensor = self.dynamicCppCall("permute", dims).to(Tensor)
template pin_memory*(self: Tensor): Tensor = self.dynamicCppCall("pin_memory").to(Tensor)
template pinverse*(self: Tensor, rcond: float64): Tensor = self.dynamicCppCall("pinverse", rcond).to(Tensor)
template rand*(size: IntList, options: ATensorOptions): Tensor = dynamicCCall("at::rand", size, options).to(Tensor)
template rand*(size: IntList, generator: pointer, options: ATensorOptions): Tensor = dynamicCCall("at::rand", size, generator, options).to(Tensor)
template rand_out*(aresult: Tensor, size: IntList): Tensor = dynamicCCall("at::rand_out", aresult, size).to(Tensor)
template rand_out*(aresult: Tensor, size: IntList, generator: pointer): Tensor = dynamicCCall("at::rand_out", aresult, size, generator).to(Tensor)
template rand_like*(self: Tensor): Tensor = dynamicCCall("at::rand_like", self).to(Tensor)
template rand_like*(self: Tensor, options: ATensorOptions): Tensor = dynamicCCall("at::rand_like", self, options).to(Tensor)
template rand*(dtype: AType, size: IntList, generator: pointer = nil): Tensor {.deprecated.} = dynamicCCall("at::rand", dtype, size, generator).to(Tensor)
template randint*(high: int64, size: IntList, options: ATensorOptions): Tensor = dynamicCCall("at::randint", high, size, options).to(Tensor)
template randint*(high: int64, size: IntList, generator: pointer, options: ATensorOptions): Tensor = dynamicCCall("at::randint", high, size, generator, options).to(Tensor)
template randint*(low: int64, high: int64, size: IntList, options: ATensorOptions): Tensor = dynamicCCall("at::randint", low, high, size, options).to(Tensor)
template randint*(low: int64, high: int64, size: IntList, generator: pointer, options: ATensorOptions): Tensor = dynamicCCall("at::randint", low, high, size, generator, options).to(Tensor)
template randint*(dtype: AType, high: int64, size: IntList, generator: pointer = nil): Tensor {.deprecated.} = dynamicCCall("at::randint", dtype, high, size, generator).to(Tensor)
template randint*(dtype: AType, low: int64, high: int64, size: IntList, generator: pointer = nil): Tensor {.deprecated.} = dynamicCCall("at::randint", dtype, low, high, size, generator).to(Tensor)
template randint_out*(aresult: Tensor, high: int64, size: IntList): Tensor = dynamicCCall("at::randint_out", aresult, high, size).to(Tensor)
template randint_out*(aresult: Tensor, high: int64, size: IntList, generator: pointer): Tensor = dynamicCCall("at::randint_out", aresult, high, size, generator).to(Tensor)
template randint_out*(aresult: Tensor, low: int64, high: int64, size: IntList): Tensor = dynamicCCall("at::randint_out", aresult, low, high, size).to(Tensor)
template randint_out*(aresult: Tensor, low: int64, high: int64, size: IntList, generator: pointer): Tensor = dynamicCCall("at::randint_out", aresult, low, high, size, generator).to(Tensor)
template randint_like*(self: Tensor, high: int64): Tensor = dynamicCCall("at::randint_like", self, high).to(Tensor)
template randint_like*(self: Tensor, low: int64, high: int64): Tensor = dynamicCCall("at::randint_like", self, low, high).to(Tensor)
template randint_like*(self: Tensor, high: int64, options: ATensorOptions): Tensor = dynamicCCall("at::randint_like", self, high, options).to(Tensor)
template randint_like*(self: Tensor, low: int64, high: int64, options: ATensorOptions): Tensor = dynamicCCall("at::randint_like", self, low, high, options).to(Tensor)
template randn*(size: IntList, options: ATensorOptions): Tensor = dynamicCCall("at::randn", size, options).to(Tensor)
template randn*(size: IntList, generator: pointer, options: ATensorOptions): Tensor = dynamicCCall("at::randn", size, generator, options).to(Tensor)
template randn_out*(aresult: Tensor, size: IntList): Tensor = dynamicCCall("at::randn_out", aresult, size).to(Tensor)
template randn_out*(aresult: Tensor, size: IntList, generator: pointer): Tensor = dynamicCCall("at::randn_out", aresult, size, generator).to(Tensor)
template randn_like*(self: Tensor): Tensor = dynamicCCall("at::randn_like", self).to(Tensor)
template randn_like*(self: Tensor, options: ATensorOptions): Tensor = dynamicCCall("at::randn_like", self, options).to(Tensor)
template randn*(dtype: AType, size: IntList, generator: pointer = nil): Tensor {.deprecated.} = dynamicCCall("at::randn", dtype, size, generator).to(Tensor)
template randperm*(n: int64, options: ATensorOptions): Tensor = dynamicCCall("at::randperm", n, options).to(Tensor)
template randperm*(n: int64, generator: pointer, options: ATensorOptions): Tensor = dynamicCCall("at::randperm", n, generator, options).to(Tensor)
template randperm_out*(aresult: Tensor, n: int64): Tensor = dynamicCCall("at::randperm_out", aresult, n).to(Tensor)
template randperm_out*(aresult: Tensor, n: int64, generator: pointer): Tensor = dynamicCCall("at::randperm_out", aresult, n, generator).to(Tensor)
template randperm*(dtype: AType, n: int64, generator: pointer = nil): Tensor {.deprecated.} = dynamicCCall("at::randperm", dtype, n, generator).to(Tensor)
template range*(start: float, aend: float, options: ATensorOptions): Tensor = dynamicCCall("at::range", start, aend, options).to(Tensor)
template range*(start: float, aend: float, step: float, options: ATensorOptions): Tensor = dynamicCCall("at::range", start, aend, step, options).to(Tensor)
template range_out*(aresult: Tensor, start: float, aend: float): Tensor = dynamicCCall("at::range_out", aresult, start, aend).to(Tensor)
template range_out*(aresult: Tensor, start: float, aend: float, step: float): Tensor = dynamicCCall("at::range_out", aresult, start, aend, step).to(Tensor)
template range*(dtype: AType, start: float, aend: float, step: float = 1): Tensor {.deprecated.} = dynamicCCall("at::range", dtype, start, aend, step).to(Tensor)
template repeat*(self: Tensor, repeats: IntList): Tensor = self.dynamicCppCall("repeat", repeats).to(Tensor)
template reshape*(self: Tensor, shape: IntList): Tensor = self.dynamicCppCall("reshape", shape).to(Tensor)
template reshape_as*(self: Tensor, other: Tensor): Tensor = self.dynamicCppCall("reshape_as", other).to(Tensor)
template RoiPooling2d_forward*(input: Tensor, rois: Tensor, pooledHeight: int64, pooledWidth: int64, spatialScale: float64): (Tensor, Tensor) = dynamicCCall("at::RoiPooling2d_forward", input, rois, pooledHeight, pooledWidth, spatialScale).to(ATensorTuple2).toNimTensorTuple()
template RoiPooling2d_backward*(input: Tensor, rois: Tensor, pooledHeight: int64, pooledWidth: int64, spatialScale: float64, gradOutput: Tensor, argmaxes: Tensor): Tensor = dynamicCCall("at::RoiPooling2d_backward", input, rois, pooledHeight, pooledWidth, spatialScale, gradOutput, argmaxes).to(Tensor)
template round*(self: Tensor): Tensor = self.dynamicCppCall("round").to(Tensor)
template round_u*(self: Tensor): Tensor = self.dynamicCppCall("round_").to(Tensor)
template round_out*(aresult: Tensor, self: Tensor): Tensor = dynamicCCall("at::round_out", aresult, self).to(Tensor)
template rrelu*(self: Tensor, lower: float, upper: float, training: bool = false, generator: pointer = nil): Tensor = dynamicCCall("at::rrelu", self, lower, upper, training, generator).to(Tensor)
template rrelu_u*(self: Tensor, lower: float, upper: float, training: bool = false, generator: pointer = nil): Tensor = dynamicCCall("at::rrelu_", self, lower, upper, training, generator).to(Tensor)
template relu*(self: Tensor): Tensor = self.dynamicCppCall("relu").to(Tensor)
template relu_u*(self: Tensor): Tensor = self.dynamicCppCall("relu_").to(Tensor)
template hardshrink*(self: Tensor, lambd: float): Tensor = self.dynamicCppCall("hardshrink", lambd).to(Tensor)
template hardshrink_backward*(self: Tensor, grad_out: Tensor, lambd: float): Tensor = self.dynamicCppCall("hardshrink_backward", grad_out, lambd).to(Tensor)
template rsqrt*(self: Tensor): Tensor = self.dynamicCppCall("rsqrt").to(Tensor)
template rsqrt_u*(self: Tensor): Tensor = self.dynamicCppCall("rsqrt_").to(Tensor)
template rsqrt_out*(aresult: Tensor, self: Tensor): Tensor = dynamicCCall("at::rsqrt_out", aresult, self).to(Tensor)
template select*(self: Tensor, dim: int64, index: int64): Tensor = self.dynamicCppCall("select", dim, index).to(Tensor)
template selu*(self: Tensor): Tensor = dynamicCCall("at::selu", self).to(Tensor)
template selu_u*(self: Tensor): Tensor = dynamicCCall("at::selu_", self).to(Tensor)
template celu*(self: Tensor, alpha: float): Tensor = dynamicCCall("at::celu", self, alpha).to(Tensor)
template celu_u*(self: Tensor, alpha: float): Tensor = dynamicCCall("at::celu_", self, alpha).to(Tensor)
template sigmoid*(self: Tensor): Tensor = self.dynamicCppCall("sigmoid").to(Tensor)
template sigmoid_u*(self: Tensor): Tensor = self.dynamicCppCall("sigmoid_").to(Tensor)
template sigmoid_out*(aresult: Tensor, self: Tensor): Tensor = dynamicCCall("at::sigmoid_out", aresult, self).to(Tensor)
template sin*(self: Tensor): Tensor = self.dynamicCppCall("sin").to(Tensor)
template sin_u*(self: Tensor): Tensor = self.dynamicCppCall("sin_").to(Tensor)
template sin_out*(aresult: Tensor, self: Tensor): Tensor = dynamicCCall("at::sin_out", aresult, self).to(Tensor)
template sinh*(self: Tensor): Tensor = self.dynamicCppCall("sinh").to(Tensor)
template sinh_u*(self: Tensor): Tensor = self.dynamicCppCall("sinh_").to(Tensor)
template sinh_out*(aresult: Tensor, self: Tensor): Tensor = dynamicCCall("at::sinh_out", aresult, self).to(Tensor)
template size*(self: Tensor, dim: int64): int64 = self.dynamicCppCall("size", dim).to(int64)
template slice*(self: Tensor, dim: int64 = 0, start: int64 = 0, aend: int64 = 9223372036854775807, step: int64 = 1): Tensor = self.dynamicCppCall("slice", dim, start, aend, step).to(Tensor)
template slogdet*(self: Tensor): (Tensor, Tensor) = self.dynamicCppCall("slogdet").to(ATensorTuple2).toNimTensorTuple()
template smm*(self: Tensor, mat2: Tensor): Tensor = self.dynamicCppCall("smm", mat2).to(Tensor)
template softmax*(self: Tensor, dim: int64): Tensor = self.dynamicCppCall("softmax", dim).to(Tensor)
template softmax_backward_data*(self: Tensor, grad_output: Tensor, output: Tensor, dim: int64): Tensor = self.dynamicCppCall("softmax_backward_data", grad_output, output, dim).to(Tensor)
template u_sparse_add_out*(aresult: Tensor, self: Tensor, other: Tensor, alpha: float = 1): Tensor = dynamicCCall("at::_sparse_add_out", aresult, self, other, alpha).to(Tensor)
template u_sparse_dense_add_out*(aresult: Tensor, self: Tensor, other: ASparseTensorRef, alpha: float = 1): Tensor = dynamicCCall("at::_sparse_dense_add_out", aresult, self, other, alpha).to(Tensor)
template u_sparse_div_out*(aresult: Tensor, self: Tensor, other: float): Tensor = dynamicCCall("at::_sparse_div_out", aresult, self, other).to(Tensor)
template u_sparse_mul_out*(aresult: Tensor, self: Tensor, other: Tensor): Tensor = dynamicCCall("at::_sparse_mul_out", aresult, self, other).to(Tensor)
template u_sparse_mul_scalar_out*(aresult: Tensor, self: Tensor, other: float): Tensor = dynamicCCall("at::_sparse_mul_scalar_out", aresult, self, other).to(Tensor)
template split*(self: Tensor, split_size: int64, dim: int64 = 0): TensorList = self.dynamicCppCall("split", split_size, dim).to(TensorList)
template split_with_sizes*(self: Tensor, split_sizes: IntList, dim: int64 = 0): TensorList = self.dynamicCppCall("split_with_sizes", split_sizes, dim).to(TensorList)
template squeeze*(self: Tensor): Tensor = self.dynamicCppCall("squeeze").to(Tensor)
template squeeze*(self: Tensor, dim: int64): Tensor = self.dynamicCppCall("squeeze", dim).to(Tensor)
template squeeze_u*(self: Tensor): Tensor = self.dynamicCppCall("squeeze_").to(Tensor)
template squeeze_u*(self: Tensor, dim: int64): Tensor = self.dynamicCppCall("squeeze_", dim).to(Tensor)
template sspaddmm*(self: Tensor, mat1: Tensor, mat2: Tensor, beta: float = 1, alpha: float = 1): Tensor = self.dynamicCppCall("sspaddmm", mat1, mat2, beta, alpha).to(Tensor)
template sspaddmm_out*(aresult: Tensor, self: Tensor, mat1: Tensor, mat2: Tensor, beta: float = 1, alpha: float = 1): Tensor = dynamicCCall("at::sspaddmm_out", aresult, self, mat1, mat2, beta, alpha).to(Tensor)
template stack*(tensors: TensorList, dim: int64 = 0): Tensor = dynamicCCall("at::stack", tensors, dim).to(Tensor)
template stack_out*(aresult: Tensor, tensors: TensorList, dim: int64 = 0): Tensor = dynamicCCall("at::stack_out", aresult, tensors, dim).to(Tensor)
template stft*(self: Tensor, n_fft: int64, hop_length: int64, win_length: int64, window: Tensor, normalized: bool = false, onesided: bool = true): Tensor = self.dynamicCppCall("stft", n_fft, hop_length, win_length, window, normalized, onesided).to(Tensor)
template stride*(self: Tensor, dim: int64): int64 = self.dynamicCppCall("stride", dim).to(int64)
template sum*(self: Tensor, dtype: AScalarType): Tensor = self.dynamicCppCall("sum", dtype).to(Tensor)
template sum*(self: Tensor): Tensor = self.dynamicCppCall("sum").to(Tensor)
template u_sum*(self: Tensor): Tensor = self.dynamicCppCall("_sum").to(Tensor)
template sum*(self: Tensor, dim: IntList, keepdim: bool, dtype: AScalarType): Tensor = self.dynamicCppCall("sum", dim, keepdim, dtype).to(Tensor)
template sum*(self: Tensor, dim: IntList, keepdim: bool = false): Tensor = self.dynamicCppCall("sum", dim, keepdim).to(Tensor)
template sum*(self: Tensor, dim: IntList, dtype: AScalarType): Tensor = self.dynamicCppCall("sum", dim, dtype).to(Tensor)
template u_sum*(self: Tensor, dim: IntList, keepdim: bool = false): Tensor = self.dynamicCppCall("_sum", dim, keepdim).to(Tensor)
template sum_out*(aresult: Tensor, self: Tensor, dim: IntList, keepdim: bool, dtype: AScalarType): Tensor = dynamicCCall("at::sum_out", aresult, self, dim, keepdim, dtype).to(Tensor)
template sum_out*(aresult: Tensor, self: Tensor, dim: IntList, keepdim: bool = false): Tensor = dynamicCCall("at::sum_out", aresult, self, dim, keepdim).to(Tensor)
template sum_out*(aresult: Tensor, self: Tensor, dim: IntList, dtype: AScalarType): Tensor = dynamicCCall("at::sum_out", aresult, self, dim, dtype).to(Tensor)
template u_sum_out*(aresult: Tensor, self: Tensor, dim: IntList, keepdim: bool = false): Tensor = dynamicCCall("at::_sum_out", aresult, self, dim, keepdim).to(Tensor)
template u_sum_cuda_out*(aresult: Tensor, self: Tensor, dim: int64, keepdim: bool = false): Tensor = dynamicCCall("at::_sum_cuda_out", aresult, self, dim, keepdim).to(Tensor)
template sqrt*(self: Tensor): Tensor = self.dynamicCppCall("sqrt").to(Tensor)
template sqrt_u*(self: Tensor): Tensor = self.dynamicCppCall("sqrt_").to(Tensor)
template sqrt_out*(aresult: Tensor, self: Tensor): Tensor = dynamicCCall("at::sqrt_out", aresult, self).to(Tensor)
template std*(self: Tensor, unbiased: bool = true): Tensor = self.dynamicCppCall("std", unbiased).to(Tensor)
template std*(self: Tensor, dim: int64, unbiased: bool = true, keepdim: bool = false): Tensor = self.dynamicCppCall("std", dim, unbiased, keepdim).to(Tensor)
template std_out*(aresult: Tensor, self: Tensor, dim: int64, unbiased: bool = true, keepdim: bool = false): Tensor = dynamicCCall("at::std_out", aresult, self, dim, unbiased, keepdim).to(Tensor)
template prod*(self: Tensor, dtype: AScalarType): Tensor = self.dynamicCppCall("prod", dtype).to(Tensor)
template prod*(self: Tensor): Tensor = self.dynamicCppCall("prod").to(Tensor)
template u_prod*(self: Tensor): Tensor = self.dynamicCppCall("_prod").to(Tensor)
template prod*(self: Tensor, dim: int64, keepdim: bool, dtype: AScalarType): Tensor = self.dynamicCppCall("prod", dim, keepdim, dtype).to(Tensor)
template prod*(self: Tensor, dim: int64, keepdim: bool = false): Tensor = self.dynamicCppCall("prod", dim, keepdim).to(Tensor)
template prod*(self: Tensor, dim: int64, dtype: AScalarType): Tensor = self.dynamicCppCall("prod", dim, dtype).to(Tensor)
template u_prod*(self: Tensor, dim: int64, keepdim: bool = false): Tensor = self.dynamicCppCall("_prod", dim, keepdim).to(Tensor)
template prod_out*(aresult: Tensor, self: Tensor, dim: int64, keepdim: bool, dtype: AScalarType): Tensor = dynamicCCall("at::prod_out", aresult, self, dim, keepdim, dtype).to(Tensor)
template prod_out*(aresult: Tensor, self: Tensor, dim: int64, keepdim: bool = false): Tensor = dynamicCCall("at::prod_out", aresult, self, dim, keepdim).to(Tensor)
template prod_out*(aresult: Tensor, self: Tensor, dim: int64, dtype: AScalarType): Tensor = dynamicCCall("at::prod_out", aresult, self, dim, dtype).to(Tensor)
template u_prod_out*(aresult: Tensor, self: Tensor, dim: int64, keepdim: bool = false): Tensor = dynamicCCall("at::_prod_out", aresult, self, dim, keepdim).to(Tensor)
template t*(self: Tensor): Tensor = self.dynamicCppCall("t").to(Tensor)
template t_u*(self: Tensor): Tensor = self.dynamicCppCall("t_").to(Tensor)
template tan*(self: Tensor): Tensor = self.dynamicCppCall("tan").to(Tensor)
template tan_u*(self: Tensor): Tensor = self.dynamicCppCall("tan_").to(Tensor)
template tan_out*(aresult: Tensor, self: Tensor): Tensor = dynamicCCall("at::tan_out", aresult, self).to(Tensor)
template tanh*(self: Tensor): Tensor = self.dynamicCppCall("tanh").to(Tensor)
template tanh_u*(self: Tensor): Tensor = self.dynamicCppCall("tanh_").to(Tensor)
template tanh_out*(aresult: Tensor, self: Tensor): Tensor = dynamicCCall("at::tanh_out", aresult, self).to(Tensor)
template transpose*(self: Tensor, dim0: int64, dim1: int64): Tensor = self.dynamicCppCall("transpose", dim0, dim1).to(Tensor)
template transpose_u*(self: Tensor, dim0: int64, dim1: int64): Tensor = self.dynamicCppCall("transpose_", dim0, dim1).to(Tensor)
template flip*(self: Tensor, dims: IntList): Tensor = self.dynamicCppCall("flip", dims).to(Tensor)
template rot90*(self: Tensor, k: int64 = 1, dims: IntList): Tensor = self.dynamicCppCall("rot90", k, dims).to(Tensor)
template u_trilinear*(i1: Tensor, i2: Tensor, i3: Tensor, expand1: IntList, expand2: IntList, expand3: IntList, sumdim: IntList, unroll_dim: int64 = 1): Tensor = dynamicCCall("at::_trilinear", i1, i2, i3, expand1, expand2, expand3, sumdim, unroll_dim).to(Tensor)
template triplet_margin_loss*(anchor: Tensor, positive: Tensor, negative: Tensor, margin: float64, p: float64 = 2, eps: float64, swap: bool = false, reduction: int64): Tensor = dynamicCCall("at::triplet_margin_loss", anchor, positive, negative, margin, p, eps, swap, reduction).to(Tensor)
template trunc*(self: Tensor): Tensor = self.dynamicCppCall("trunc").to(Tensor)
template trunc_u*(self: Tensor): Tensor = self.dynamicCppCall("trunc_").to(Tensor)
template trunc_out*(aresult: Tensor, self: Tensor): Tensor = dynamicCCall("at::trunc_out", aresult, self).to(Tensor)
template type_as*(self: Tensor, other: Tensor): Tensor = self.dynamicCppCall("type_as", other).to(Tensor)
template u_unique*(self: Tensor, sorted: bool = false, return_inverse: bool = false): (Tensor, Tensor) = self.dynamicCppCall("_unique", sorted, return_inverse).to(ATensorTuple2).toNimTensorTuple()
template u_unsafe_view*(self: Tensor, size: IntList): Tensor = dynamicCCall("at::_unsafe_view", self, size).to(Tensor)
template unsqueeze*(self: Tensor, dim: int64): Tensor = self.dynamicCppCall("unsqueeze", dim).to(Tensor)
template unsqueeze_u*(self: Tensor, dim: int64): Tensor = self.dynamicCppCall("unsqueeze_", dim).to(Tensor)
template avar*(self: Tensor, unbiased: bool = true): Tensor = self.dynamicCppCall("var", unbiased).to(Tensor)
template avar*(self: Tensor, dim: int64, unbiased: bool = true, keepdim: bool = false): Tensor = self.dynamicCppCall("var", dim, unbiased, keepdim).to(Tensor)
template var_out*(aresult: Tensor, self: Tensor, dim: int64, unbiased: bool = true, keepdim: bool = false): Tensor = dynamicCCall("at::var_out", aresult, self, dim, unbiased, keepdim).to(Tensor)
template view_as*(self: Tensor, other: Tensor): Tensor = self.dynamicCppCall("view_as", other).to(Tensor)
template where*(self: Tensor, condition: Tensor, other: Tensor): Tensor = self.dynamicCppCall("where", condition, other).to(Tensor)
template u_s_where*(self: Tensor, condition: Tensor, other: Tensor): Tensor = self.dynamicCppCall("_s_where", condition, other).to(Tensor)
template zeros*(size: IntList, options: ATensorOptions): Tensor = dynamicCCall("at::zeros", size, options).to(Tensor)
template zeros_out*(aresult: Tensor, size: IntList): Tensor = dynamicCCall("at::zeros_out", aresult, size).to(Tensor)
template zeros_like*(self: Tensor): Tensor = dynamicCCall("at::zeros_like", self).to(Tensor)
template zeros_like*(self: Tensor, options: ATensorOptions): Tensor = dynamicCCall("at::zeros_like", self, options).to(Tensor)
template zeros*(dtype: AType, size: IntList): Tensor {.deprecated.} = dynamicCCall("at::zeros", dtype, size).to(Tensor)
template u_standard_gamma_grad*(self: Tensor, output: Tensor): Tensor = self.dynamicCppCall("_standard_gamma_grad", output).to(Tensor)
template u_standard_gamma*(self: Tensor, generator: pointer = nil): Tensor = self.dynamicCppCall("_standard_gamma", generator).to(Tensor)
template poisson*(self: Tensor, generator: pointer = nil): Tensor = dynamicCCall("at::poisson", self, generator).to(Tensor)
template native_norm*(self: Tensor, p: float = 2): Tensor = dynamicCCall("at::native_norm", self, p).to(Tensor)
template norm*(self: Tensor, p: float = 2): Tensor = self.dynamicCppCall("norm", p).to(Tensor)
template norm*(self: Tensor, p: float, dim: int64, keepdim: bool = false): Tensor = self.dynamicCppCall("norm", p, dim, keepdim).to(Tensor)
template norm_out*(aresult: Tensor, self: Tensor, p: float, dim: int64, keepdim: bool = false): Tensor = dynamicCCall("at::norm_out", aresult, self, p, dim, keepdim).to(Tensor)
template native_clone*(self: Tensor): Tensor = dynamicCCall("at::native_clone", self).to(Tensor)
template clone*(self: Tensor): Tensor = self.dynamicCppCall("clone").to(Tensor)
template native_resize_as_u*(self: Tensor, the_template: Tensor): Tensor = dynamicCCall("at::native_resize_as_", self, the_template).to(Tensor)
template resize_as_u*(self: Tensor, the_template: Tensor): Tensor = self.dynamicCppCall("resize_as_", the_template).to(Tensor)
template native_pow_out*(aresult: Tensor, self: Tensor, exponent: float): Tensor = dynamicCCall("at::native_pow_out", aresult, self, exponent).to(Tensor)
template native_pow*(self: Tensor, exponent: float): Tensor = dynamicCCall("at::native_pow", self, exponent).to(Tensor)
template pow_out*(aresult: Tensor, self: Tensor, exponent: float): Tensor = dynamicCCall("at::pow_out", aresult, self, exponent).to(Tensor)
template pow*(self: Tensor, exponent: float): Tensor = self.dynamicCppCall("pow", exponent).to(Tensor)
template native_zero_u*(self: Tensor): Tensor = dynamicCCall("at::native_zero_", self).to(Tensor)
template zero_u*(self: Tensor): Tensor = self.dynamicCppCall("zero_").to(Tensor)
template sub_out*(aresult: Tensor, self: Tensor, other: Tensor, alpha: float = 1): Tensor = dynamicCCall("at::sub_out", aresult, self, other, alpha).to(Tensor)
template sub*(self: Tensor, other: Tensor, alpha: float = 1): Tensor = self.dynamicCppCall("sub", other, alpha).to(Tensor)
template sub_u*(self: Tensor, other: Tensor, alpha: float = 1): Tensor = self.dynamicCppCall("sub_", other, alpha).to(Tensor)
template sub*(self: Tensor, other: float, alpha: float = 1): Tensor = self.dynamicCppCall("sub", other, alpha).to(Tensor)
template sub_u*(self: Tensor, other: float, alpha: float = 1): Tensor = self.dynamicCppCall("sub_", other, alpha).to(Tensor)
template s_native_addmm_out*(aresult: Tensor, self: Tensor, mat1: Tensor, mat2: Tensor, beta: float = 1, alpha: float = 1): Tensor = dynamicCCall("at::s_native_addmm_out", aresult, self, mat1, mat2, beta, alpha).to(Tensor)
template s_native_addmm*(self: Tensor, mat1: Tensor, mat2: Tensor, beta: float = 1, alpha: float = 1): Tensor = dynamicCCall("at::s_native_addmm", self, mat1, mat2, beta, alpha).to(Tensor)
template s_native_addmm_u*(self: Tensor, mat1: Tensor, mat2: Tensor, beta: float = 1, alpha: float = 1): Tensor = dynamicCCall("at::s_native_addmm_", self, mat1, mat2, beta, alpha).to(Tensor)
template addmm_out*(aresult: Tensor, self: Tensor, mat1: Tensor, mat2: Tensor, beta: float = 1, alpha: float = 1): Tensor = dynamicCCall("at::addmm_out", aresult, self, mat1, mat2, beta, alpha).to(Tensor)
template addmm*(self: Tensor, mat1: Tensor, mat2: Tensor, beta: float = 1, alpha: float = 1): Tensor = self.dynamicCppCall("addmm", mat1, mat2, beta, alpha).to(Tensor)
template addmm_u*(self: Tensor, mat1: Tensor, mat2: Tensor, beta: float = 1, alpha: float = 1): Tensor = self.dynamicCppCall("addmm_", mat1, mat2, beta, alpha).to(Tensor)
template native_tensor*(self_ty: AType): Tensor = dynamicCCall("at::native_tensor", self_ty).to(Tensor)
template native_tensor*(self_ty: AType, size: IntList): Tensor = dynamicCCall("at::native_tensor", self_ty, size).to(Tensor)
template u_sparse_coo_tensor_unsafe*(indices: Tensor, values: Tensor, size: IntList): Tensor = dynamicCCall("at::_sparse_coo_tensor_unsafe", indices, values, size).to(Tensor)
template sparse_raw_resize_u*(self: Tensor, size: IntList, sparseDims: int64, denseDims: int64): Tensor = self.dynamicCppCall("sparse_raw_resize_", size, sparseDims, denseDims).to(Tensor)
template u_sparse_mask*(self: Tensor, mask: ASparseTensorRef): Tensor = self.dynamicCppCall("_sparse_mask", mask).to(Tensor)
template to_dense*(self: Tensor): Tensor = self.dynamicCppCall("to_dense").to(Tensor)
template u_sparseDims*(self: Tensor): int64 = self.dynamicCppCall("_sparseDims").to(int64)
template u_dimI*(self: Tensor): int64 = self.dynamicCppCall("_dimI").to(int64)
template u_denseDims*(self: Tensor): int64 = self.dynamicCppCall("_denseDims").to(int64)
template u_dimV*(self: Tensor): int64 = self.dynamicCppCall("_dimV").to(int64)
template u_nnz*(self: Tensor): int64 = self.dynamicCppCall("_nnz").to(int64)
template coalesce*(self: Tensor): Tensor = self.dynamicCppCall("coalesce").to(Tensor)
template is_coalesced*(self: Tensor): bool = self.dynamicCppCall("is_coalesced").to(bool)
template u_indices*(self: Tensor): Tensor = self.dynamicCppCall("_indices").to(Tensor)
template u_values*(self: Tensor): Tensor = self.dynamicCppCall("_values").to(Tensor)
template hspmm_out*(aresult: Tensor, mat1: Tensor, mat2: Tensor): Tensor = dynamicCCall("at::hspmm_out", aresult, mat1, mat2).to(Tensor)
template hspmm*(mat1: Tensor, mat2: Tensor): Tensor = dynamicCCall("at::hspmm", mat1, mat2).to(Tensor)
template raw_copy_sparse_u*(self: Tensor, src: Tensor): Tensor = dynamicCCall("at::raw_copy_sparse_", self, src).to(Tensor)
template numel*(self: Tensor): int64 = self.dynamicCppCall("numel").to(int64)
template unbind*(self: Tensor, dim: int64 = 0): TensorList = self.dynamicCppCall("unbind", dim).to(TensorList)
template native_get_device*(self: Tensor): int64 = dynamicCCall("at::native_get_device", self).to(int64)
template get_device*(self: Tensor): int64 = self.dynamicCppCall("get_device").to(int64)
template meshgrid*(tensors: TensorList): TensorList = dynamicCCall("at::meshgrid", tensors).to(TensorList)
template u_local_scalar*(self: Tensor): float = self.dynamicCppCall("_local_scalar").to(float)
template u_local_scalar_dense*(self: Tensor): float = dynamicCCall("at::_local_scalar_dense", self).to(float)
